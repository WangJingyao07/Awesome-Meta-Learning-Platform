{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Written: @Jingyao Wang (UCAS) Awesome-META+ is a software for meta-learning research and practice. Awesome-META+ builds on top of PyTorch and Tensorflow to accelerate three aspects of the meta-learning research cycle: Convenient Learning , complete learning materials are provided for meta learning researchers and newbies Fast prototyping , essential in letting researchers quickly try new ideas Correct reproducibility , ensuring that these ideas are evaluated fairly Awesome-META+ provides multiple meta-learning frameworks, extensive application cases, standardized code modules, comprehensive performance testing, online deployment, etc. to create new algorithms and domains, as well as high-quality implementations of existing algorithms and standardized benchmarks. The basic services and information provided by this platform are as follows. We will upload our whitepaper and more details very soon. Overview Tutorials : Usage of Awesome META+ and various settings for framework deployment Documentation : Models, datasets, benchmarks, optimizers, and standardization Examples : Framework deployment and application in Computer Vision, Reinforcement Learning, and Optimization Papers : Materials for research and learning, including papers, blogs, books, libraries, lecture videos etc. Datasets : Benchmarks of Meta Learning, and performance evaluation on these datasets Community : Developers of this platform, and research institutions that do well in meta-learning Changelog : Version update and maintenance log of Awesome META+ GitHub : Code link GitHub Installation The services provided by this platform will be able to be installed in the form of python libraries through pip after January 10, 2023 . pip install Awesome-META Framework List Computer Vision Reinforcement Learning Optimization Online MAML \u2705 \u2705 \u2705 \u2705 MetaOptNet \u2705 \u2705 Reptile \u2705 \u2705 Prototypical Network \u2705 \u2705 \u2705 Relation Network \u2705 \u2705 \u2705 ANIL \u2705 \u2705 Meta-SGD \u2705 Meta Dropout \u2705 MT-net \u2705 ES-MAML \u2705 \u2705 CNAP \u2705 SNAIL \u2705 Results CV Method Avg rank ILSVRC (test) Omniglot Aircraft Birds Textures QuickDraw Fungi VGG Flower Traffic signs MSCOCO k-NN 13.6 41.03\u00b11.01 (14) 37.07\u00b11.15 (15) 46.81\u00b10.89 (14) 50.13\u00b11.00 (14.5) 66.36\u00b10.75 (12) 32.06\u00b11.08 (15) 36.16\u00b11.02 (12) 83.10\u00b10.68 (11) 44.59\u00b11.19 (14) 30.38\u00b10.99 (14.5) Finetune 9.45 45.78\u00b11.10 (12) 60.85\u00b11.58 (10.5) 68.69\u00b11.26 (4) 57.31\u00b11.26 (13) 69.05\u00b10.90 (8.5) 42.60\u00b11.17 (12.5) 38.20\u00b11.02 (10) 85.51\u00b10.68 (8) 66.79\u00b11.31 (4) 34.86\u00b10.97 (12) Prototypical Network 9.75 50.50\u00b11.08 (9.5) 59.98\u00b11.35 (10.5) 53.10\u00b11.00 (9.5) 68.79\u00b11.01 (7.5) 66.56\u00b10.83 (12) 48.96\u00b11.08 (10) 39.71\u00b11.11 (8) 85.27\u00b10.77 (8) 47.12\u00b11.10 (13) 41.00\u00b11.10 (9.5) MAML 11.25 45.51\u00b11.11 (12) 55.55\u00b11.54 (12) 56.24\u00b11.11 (7.5) 63.61\u00b11.06 (11.5) 68.04\u00b10.81 (8.5) 43.96\u00b11.29 (12.5) 32.10\u00b11.10 (14) 81.74\u00b10.83 (13) 50.93\u00b11.51 (9.5) 35.30\u00b11.23 (12) Relation Network 14.55 34.69\u00b11.01 (15) 45.35\u00b11.36 (14) 40.73\u00b10.83 (15) 49.51\u00b11.05 (14.5) 52.97\u00b10.69 (15) 43.30\u00b11.08 (12.5) 30.55\u00b11.04 (15) 68.76\u00b10.83 (15) 33.67\u00b11.05 (15) 29.15\u00b11.01 (14.5) CNAP 7.75 54.80\u00b11.20 (5) 62.00\u00b11.30 (7.5) 49.20\u00b10.90 (12) 66.50\u00b11.00 (9.5) 71.60\u00b10.70 (4.5) 56.60\u00b11.00 (6) 37.50\u00b11.20 (10) 82.10\u00b10.90 (11) 63.10\u00b11.10 (5.5) 45.80\u00b11.00 (6.5) RL cite from GitHub Changelog A human-readable changelog is available in the Changelog file. Citation Comming soon...... Send Us Feedback! Our library is open source for research purposes, and we want to improve it! So let us know (create a new GitHub issue or pull request, email us, etc.) if you... Find/fix any bug (in functionality or speed) or know how to speed up or improve any part of Awesome META+. Want to add/show some cool functionality/demo/project made on top of Awesome META+. We can add your project link to our Community-based Projects section or even integrate it with Awesome META+! Acknowledgements & Friends Learn2learn is similar library, provides standardized samples and focuses on the simple form of building a meta-learning framework higher is a PyTorch library that enables differentiating through optimization inner-loops. While they monkey-patch nn.Module to be stateless, learn2learn retains the stateful PyTorch look-and-feel. For more information, refer to their ArXiv paper . We are thankful to the following open-source implementations which helped guide the design of Awesome META+: learnables's learn2learn Tristan Deleu's pytorch-maml-rl Maracver's Relation-Networks Kwonjoon Lee's MetaOptNet License Awesome META+ is freely available for free non-commercial use, and may be redistributed under these conditions.","title":"Home"},{"location":"#overview","text":"Tutorials : Usage of Awesome META+ and various settings for framework deployment Documentation : Models, datasets, benchmarks, optimizers, and standardization Examples : Framework deployment and application in Computer Vision, Reinforcement Learning, and Optimization Papers : Materials for research and learning, including papers, blogs, books, libraries, lecture videos etc. Datasets : Benchmarks of Meta Learning, and performance evaluation on these datasets Community : Developers of this platform, and research institutions that do well in meta-learning Changelog : Version update and maintenance log of Awesome META+ GitHub : Code link GitHub","title":"Overview"},{"location":"#installation","text":"The services provided by this platform will be able to be installed in the form of python libraries through pip after January 10, 2023 . pip install Awesome-META","title":"Installation"},{"location":"#framework-list","text":"Computer Vision Reinforcement Learning Optimization Online MAML \u2705 \u2705 \u2705 \u2705 MetaOptNet \u2705 \u2705 Reptile \u2705 \u2705 Prototypical Network \u2705 \u2705 \u2705 Relation Network \u2705 \u2705 \u2705 ANIL \u2705 \u2705 Meta-SGD \u2705 Meta Dropout \u2705 MT-net \u2705 ES-MAML \u2705 \u2705 CNAP \u2705 SNAIL \u2705","title":"Framework List"},{"location":"#results","text":"","title":"Results"},{"location":"#cv","text":"Method Avg rank ILSVRC (test) Omniglot Aircraft Birds Textures QuickDraw Fungi VGG Flower Traffic signs MSCOCO k-NN 13.6 41.03\u00b11.01 (14) 37.07\u00b11.15 (15) 46.81\u00b10.89 (14) 50.13\u00b11.00 (14.5) 66.36\u00b10.75 (12) 32.06\u00b11.08 (15) 36.16\u00b11.02 (12) 83.10\u00b10.68 (11) 44.59\u00b11.19 (14) 30.38\u00b10.99 (14.5) Finetune 9.45 45.78\u00b11.10 (12) 60.85\u00b11.58 (10.5) 68.69\u00b11.26 (4) 57.31\u00b11.26 (13) 69.05\u00b10.90 (8.5) 42.60\u00b11.17 (12.5) 38.20\u00b11.02 (10) 85.51\u00b10.68 (8) 66.79\u00b11.31 (4) 34.86\u00b10.97 (12) Prototypical Network 9.75 50.50\u00b11.08 (9.5) 59.98\u00b11.35 (10.5) 53.10\u00b11.00 (9.5) 68.79\u00b11.01 (7.5) 66.56\u00b10.83 (12) 48.96\u00b11.08 (10) 39.71\u00b11.11 (8) 85.27\u00b10.77 (8) 47.12\u00b11.10 (13) 41.00\u00b11.10 (9.5) MAML 11.25 45.51\u00b11.11 (12) 55.55\u00b11.54 (12) 56.24\u00b11.11 (7.5) 63.61\u00b11.06 (11.5) 68.04\u00b10.81 (8.5) 43.96\u00b11.29 (12.5) 32.10\u00b11.10 (14) 81.74\u00b10.83 (13) 50.93\u00b11.51 (9.5) 35.30\u00b11.23 (12) Relation Network 14.55 34.69\u00b11.01 (15) 45.35\u00b11.36 (14) 40.73\u00b10.83 (15) 49.51\u00b11.05 (14.5) 52.97\u00b10.69 (15) 43.30\u00b11.08 (12.5) 30.55\u00b11.04 (15) 68.76\u00b10.83 (15) 33.67\u00b11.05 (15) 29.15\u00b11.01 (14.5) CNAP 7.75 54.80\u00b11.20 (5) 62.00\u00b11.30 (7.5) 49.20\u00b10.90 (12) 66.50\u00b11.00 (9.5) 71.60\u00b10.70 (4.5) 56.60\u00b11.00 (6) 37.50\u00b11.20 (10) 82.10\u00b10.90 (11) 63.10\u00b11.10 (5.5) 45.80\u00b11.00 (6.5)","title":"CV"},{"location":"#rl","text":"cite from GitHub","title":"RL"},{"location":"#changelog","text":"A human-readable changelog is available in the Changelog file.","title":"Changelog"},{"location":"#citation","text":"Comming soon......","title":"Citation"},{"location":"#send-us-feedback","text":"Our library is open source for research purposes, and we want to improve it! So let us know (create a new GitHub issue or pull request, email us, etc.) if you... Find/fix any bug (in functionality or speed) or know how to speed up or improve any part of Awesome META+. Want to add/show some cool functionality/demo/project made on top of Awesome META+. We can add your project link to our Community-based Projects section or even integrate it with Awesome META+!","title":"Send Us Feedback!"},{"location":"#acknowledgements-friends","text":"Learn2learn is similar library, provides standardized samples and focuses on the simple form of building a meta-learning framework higher is a PyTorch library that enables differentiating through optimization inner-loops. While they monkey-patch nn.Module to be stateless, learn2learn retains the stateful PyTorch look-and-feel. For more information, refer to their ArXiv paper . We are thankful to the following open-source implementations which helped guide the design of Awesome META+: learnables's learn2learn Tristan Deleu's pytorch-maml-rl Maracver's Relation-Networks Kwonjoon Lee's MetaOptNet","title":"Acknowledgements &amp; Friends"},{"location":"#license","text":"Awesome META+ is freely available for free non-commercial use, and may be redistributed under these conditions.","title":"License"},{"location":"1%20Tutorials/getting_started/","text":"Tutorials This section explains how to use the Awesome-META+ platform and provides a description of the application scenarios Getting Started Awesome-META+ is a meta-learning software providing four levels of functionality for users. Many examples using meta-learning algorithms to train on a myriad of datasets/environments A functional interface for several popular meta-learning algorithms as well as a data loader to make it easier to import other data sets Lots of meta-learning related materials for reaserch and learning: papers, blogs, videos, reports, etc. A set of module interfaces for building a meta-learning framework Installing Plan 1 The services provided by this platform will be able to be installed in the form of python libraries through pip after January 10, 2023 . pip install Awesome-META Plan 2 Download from the model port provided in this column: Computer Vision Reinforcement Learning Optimization Online MAML \u2705 \u2705 \u2705 \u2705 MetaOptNet \u2705 \u2705 Reptile \u2705 \u2705 Prototypical Network \u2705 \u2705 \u2705 Relation Network \u2705 \u2705 \u2705 ANIL \u2705 \u2705 Meta-SGD \u2705 Meta Dropout \u2705 MT-net \u2705 ES-MAML \u2705 \u2705 CNAP \u2705 SNAIL \u2705 plan 3 Use Git Create a new folder demo locally as a local code repository. Go to the demo folder, right-click, select git bash here, and open the git bash terminal. Enter the git init command in the git bash terminal to initialize the local repository. git clone https://github.com/WangJingyao07/MetaLearning-Lab.git !!! tip \u200b If you encounter a problem, feel free to an open an issue \u200b and we'll look into it. Examples Compute support and query embeddings embeddings = model(data) support_indices = np.zeros(data.size(0), dtype=bool) selection = np.arange(ways) * (shot + query_num) for offset in range(shot): support_indices[selection + offset] = True query_indices = torch.from_numpy(~support_indices) support_indices = torch.from_numpy(support_indices) support = embeddings[support_indices] support = support.reshape(ways, shot, -1).mean(dim=1) query = embeddings[query_indices] labels = labels[query_indices].long() logits = pairwise_distances_logits(query, support) loss = F.cross_entropy(logits, labels) acc = accuracy(logits, labels) return loss, acc Create a Model maml = Ameta.algorithms.MAML(model, lr=0.1) opt = torch.optim.SGD(maml.parameters(), lr=0.001) for iteration in range(10): opt.zero_grad() task_model = maml.clone() adaptation_loss = compute_loss(task_model) task_model.adapt(adaptation_loss) evaluation_loss = compute_loss(task_model) evaluation_loss.backward() opt.step() More services see Documentation for details. Service Details Framework deployment \ud83c\udf89You can browse the frameworks, models, datasets and other information provided by the platform in the \"Home\", and then locate them according to their needs through two methods: the first is to directly enter keywords in the search bar above the main interface; the second is to enter the keywords in the \"Home\" \"Interface, click to jump to the corresponding framework to understand the deployment method, and obtain specific details in the \"Tutorials\" and other modules, and pull the source code of the meta-learning framework and the deployment details to the local for testing with one click. Learn Meta Learning \u2728You can locate \"Papers\", \"Datasets\", \"Community\" and other modules according to their needs, and obtain the platform learning curve, as well as the download links of related blogs, monographs, papers and other resources. Multi-domain task transfer \ud83d\udc96You can understand the platform usage instructions and provide framework information according to the \"Tutorials\", \"Documentation\", and \"Examples\" modules, the framework details and optimization ideas corresponding to tasks in different fields, and actual cases (such as the performance comparison of each framework in small sample image classification, namely ACC). , AP and other indicators), so as to locate the required target and complete the configuration. Feedback \ud83c\udf81Our library is open source for research purposes, and we want to improve it! So let us know (create a new GitHub issue or pull request, email us, etc.)","title":"Tutorials"},{"location":"1%20Tutorials/getting_started/#tutorials","text":"This section explains how to use the Awesome-META+ platform and provides a description of the application scenarios","title":"Tutorials"},{"location":"1%20Tutorials/getting_started/#getting-started","text":"Awesome-META+ is a meta-learning software providing four levels of functionality for users. Many examples using meta-learning algorithms to train on a myriad of datasets/environments A functional interface for several popular meta-learning algorithms as well as a data loader to make it easier to import other data sets Lots of meta-learning related materials for reaserch and learning: papers, blogs, videos, reports, etc. A set of module interfaces for building a meta-learning framework","title":"Getting Started"},{"location":"1%20Tutorials/getting_started/#installing","text":"","title":"Installing"},{"location":"1%20Tutorials/getting_started/#plan-1","text":"The services provided by this platform will be able to be installed in the form of python libraries through pip after January 10, 2023 . pip install Awesome-META","title":"Plan 1"},{"location":"1%20Tutorials/getting_started/#plan-2","text":"Download from the model port provided in this column: Computer Vision Reinforcement Learning Optimization Online MAML \u2705 \u2705 \u2705 \u2705 MetaOptNet \u2705 \u2705 Reptile \u2705 \u2705 Prototypical Network \u2705 \u2705 \u2705 Relation Network \u2705 \u2705 \u2705 ANIL \u2705 \u2705 Meta-SGD \u2705 Meta Dropout \u2705 MT-net \u2705 ES-MAML \u2705 \u2705 CNAP \u2705 SNAIL \u2705","title":"Plan 2"},{"location":"1%20Tutorials/getting_started/#plan-3","text":"Use Git Create a new folder demo locally as a local code repository. Go to the demo folder, right-click, select git bash here, and open the git bash terminal. Enter the git init command in the git bash terminal to initialize the local repository. git clone https://github.com/WangJingyao07/MetaLearning-Lab.git","title":"plan 3"},{"location":"1%20Tutorials/getting_started/#tip","text":"\u200b If you encounter a problem, feel free to an open an issue \u200b and we'll look into it.","title":"!!! tip"},{"location":"1%20Tutorials/getting_started/#examples","text":"Compute support and query embeddings embeddings = model(data) support_indices = np.zeros(data.size(0), dtype=bool) selection = np.arange(ways) * (shot + query_num) for offset in range(shot): support_indices[selection + offset] = True query_indices = torch.from_numpy(~support_indices) support_indices = torch.from_numpy(support_indices) support = embeddings[support_indices] support = support.reshape(ways, shot, -1).mean(dim=1) query = embeddings[query_indices] labels = labels[query_indices].long() logits = pairwise_distances_logits(query, support) loss = F.cross_entropy(logits, labels) acc = accuracy(logits, labels) return loss, acc Create a Model maml = Ameta.algorithms.MAML(model, lr=0.1) opt = torch.optim.SGD(maml.parameters(), lr=0.001) for iteration in range(10): opt.zero_grad() task_model = maml.clone() adaptation_loss = compute_loss(task_model) task_model.adapt(adaptation_loss) evaluation_loss = compute_loss(task_model) evaluation_loss.backward() opt.step()","title":"Examples"},{"location":"1%20Tutorials/getting_started/#more-services","text":"see Documentation for details. Service Details Framework deployment \ud83c\udf89You can browse the frameworks, models, datasets and other information provided by the platform in the \"Home\", and then locate them according to their needs through two methods: the first is to directly enter keywords in the search bar above the main interface; the second is to enter the keywords in the \"Home\" \"Interface, click to jump to the corresponding framework to understand the deployment method, and obtain specific details in the \"Tutorials\" and other modules, and pull the source code of the meta-learning framework and the deployment details to the local for testing with one click. Learn Meta Learning \u2728You can locate \"Papers\", \"Datasets\", \"Community\" and other modules according to their needs, and obtain the platform learning curve, as well as the download links of related blogs, monographs, papers and other resources. Multi-domain task transfer \ud83d\udc96You can understand the platform usage instructions and provide framework information according to the \"Tutorials\", \"Documentation\", and \"Examples\" modules, the framework details and optimization ideas corresponding to tasks in different fields, and actual cases (such as the performance comparison of each framework in small sample image classification, namely ACC). , AP and other indicators), so as to locate the required target and complete the configuration. Feedback \ud83c\udf81Our library is open source for research purposes, and we want to improve it! So let us know (create a new GitHub issue or pull request, email us, etc.)","title":"More services"},{"location":"2%20Documentation/1%20maml_tutorial/","text":"MAML Paper: Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks (Finn et al., ICML 2017) . It includes code for running the few-shot supervised learning domain experiments, including sinusoid regression, Omniglot classification, and MiniImagenet classification. For the experiments in the RL domain, see this codebase . Overview [Abstract] This is an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. In effect, this method trains the model to be easy to fine-tune. The authors demonstrate that this approach leads to state-of-the-art performance on two fewshot image classification benchmarks, produces good results on few-shot regression, and accelerates fine-tuning for policy gradient reinforcement learning with neural network policies. For Few-Shot Supervised Learning For Reinforcement Learning Results Dependencies This code requires the following: * python 2.* or python 3.* * TensorFlow v1.0+ Data For the Omniglot and MiniImagenet data, see the usage instructions in data/omniglot_resized/resize_images.py and data/miniImagenet/proc_images.py respectively. Usage To run the code, see the usage instructions at the top of main.py We add more datasets, include CIFAR-FS, FC100 etc. Contact \"\"\" Usage Instructions: 10-shot sinusoid: python main.py --datasource=sinusoid --logdir=logs/sine/ --metatrain_iterations=70000 --norm=None --update_batch_size=10 10-shot sinusoid baselines: python main.py --datasource=sinusoid --logdir=logs/sine/ --pretrain_iterations=70000 --metatrain_iterations=0 --norm=None --update_batch_size=10 --baseline=oracle python main.py --datasource=sinusoid --logdir=logs/sine/ --pretrain_iterations=70000 --metatrain_iterations=0 --norm=None --update_batch_size=10 5-way, 1-shot omniglot: python main.py --datasource=omniglot --metatrain_iterations=60000 --meta_batch_size=32 --update_batch_size=1 --update_lr=0.4 --num_updates=1 --logdir=logs/omniglot5way/ 20-way, 1-shot omniglot: python main.py --datasource=omniglot --metatrain_iterations=60000 --meta_batch_size=16 --update_batch_size=1 --num_classes=20 --update_lr=0.1 --num_updates=5 --logdir=logs/omniglot20way/ 5-way 1-shot mini imagenet: python main.py --datasource=miniimagenet --metatrain_iterations=60000 --meta_batch_size=4 --update_batch_size=1 --update_lr=0.01 --num_updates=5 --num_classes=5 --logdir=logs/miniimagenet1shot/ --num_filters=32 --max_pool=True 5-way 5-shot mini imagenet: python main.py --datasource=miniimagenet --metatrain_iterations=60000 --meta_batch_size=4 --update_batch_size=5 --update_lr=0.01 --num_updates=5 --num_classes=5 --logdir=logs/miniimagenet5shot/ --num_filters=32 --max_pool=True To run evaluation, use the '--train=False' flag and the '--test_set=True' flag to use the test set. For omniglot and miniimagenet training, acquire the dataset online, put it in the correspoding data directory, and see the python script instructions in that directory to preprocess the data. Note that better sinusoid results can be achieved by using a larger network. \"\"\" Colab Colab Link","title":"MAML"},{"location":"2%20Documentation/1%20maml_tutorial/#maml","text":"Paper: Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks (Finn et al., ICML 2017) . It includes code for running the few-shot supervised learning domain experiments, including sinusoid regression, Omniglot classification, and MiniImagenet classification. For the experiments in the RL domain, see this codebase .","title":"MAML"},{"location":"2%20Documentation/1%20maml_tutorial/#overview-abstract","text":"This is an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. In effect, this method trains the model to be easy to fine-tune. The authors demonstrate that this approach leads to state-of-the-art performance on two fewshot image classification benchmarks, produces good results on few-shot regression, and accelerates fine-tuning for policy gradient reinforcement learning with neural network policies.","title":"Overview [Abstract]"},{"location":"2%20Documentation/1%20maml_tutorial/#for-few-shot-supervised-learning","text":"","title":"For Few-Shot Supervised Learning"},{"location":"2%20Documentation/1%20maml_tutorial/#for-reinforcement-learning","text":"","title":"For Reinforcement Learning"},{"location":"2%20Documentation/1%20maml_tutorial/#results","text":"","title":"Results"},{"location":"2%20Documentation/1%20maml_tutorial/#dependencies","text":"This code requires the following: * python 2.* or python 3.* * TensorFlow v1.0+","title":"Dependencies"},{"location":"2%20Documentation/1%20maml_tutorial/#data","text":"For the Omniglot and MiniImagenet data, see the usage instructions in data/omniglot_resized/resize_images.py and data/miniImagenet/proc_images.py respectively.","title":"Data"},{"location":"2%20Documentation/1%20maml_tutorial/#usage","text":"To run the code, see the usage instructions at the top of main.py We add more datasets, include CIFAR-FS, FC100 etc.","title":"Usage"},{"location":"2%20Documentation/1%20maml_tutorial/#contact","text":"\"\"\" Usage Instructions: 10-shot sinusoid: python main.py --datasource=sinusoid --logdir=logs/sine/ --metatrain_iterations=70000 --norm=None --update_batch_size=10 10-shot sinusoid baselines: python main.py --datasource=sinusoid --logdir=logs/sine/ --pretrain_iterations=70000 --metatrain_iterations=0 --norm=None --update_batch_size=10 --baseline=oracle python main.py --datasource=sinusoid --logdir=logs/sine/ --pretrain_iterations=70000 --metatrain_iterations=0 --norm=None --update_batch_size=10 5-way, 1-shot omniglot: python main.py --datasource=omniglot --metatrain_iterations=60000 --meta_batch_size=32 --update_batch_size=1 --update_lr=0.4 --num_updates=1 --logdir=logs/omniglot5way/ 20-way, 1-shot omniglot: python main.py --datasource=omniglot --metatrain_iterations=60000 --meta_batch_size=16 --update_batch_size=1 --num_classes=20 --update_lr=0.1 --num_updates=5 --logdir=logs/omniglot20way/ 5-way 1-shot mini imagenet: python main.py --datasource=miniimagenet --metatrain_iterations=60000 --meta_batch_size=4 --update_batch_size=1 --update_lr=0.01 --num_updates=5 --num_classes=5 --logdir=logs/miniimagenet1shot/ --num_filters=32 --max_pool=True 5-way 5-shot mini imagenet: python main.py --datasource=miniimagenet --metatrain_iterations=60000 --meta_batch_size=4 --update_batch_size=5 --update_lr=0.01 --num_updates=5 --num_classes=5 --logdir=logs/miniimagenet5shot/ --num_filters=32 --max_pool=True To run evaluation, use the '--train=False' flag and the '--test_set=True' flag to use the test set. For omniglot and miniimagenet training, acquire the dataset online, put it in the correspoding data directory, and see the python script instructions in that directory to preprocess the data. Note that better sinusoid results can be achieved by using a larger network. \"\"\"","title":"Contact"},{"location":"2%20Documentation/1%20maml_tutorial/#colab","text":"Colab Link","title":"Colab"},{"location":"2%20Documentation/10%20ES-maml_tutorial/","text":"ES-MAML Paper: \"ES-MAML: Simple Hessian-Free Meta Learning\" This was also used in \"Rapidly Adaptable Legged Robots via Evolutionary Meta-Learning\" with associated Google AI Blog Post . Overview[Abstract] We introduce ES-MAML, a new framework for solving the model agnostic meta learning (MAML) problem based on Evolution Strategies (ES). Existing algorithms for MAML are based on policy gradients, and incur significant difficulties when attempting to estimate second derivatives using backpropagation on stochastic policies. We show how ES can be applied to MAML to obtain an algorithm which avoids the problem of estimating second derivatives, and is also conceptually simple and easy to implement. Moreover, ES-MAML can handle new types of non-smooth adaptation operators, and other techniques for improving performance and estimation of ES methods become applicable. We show empirically that ES-MAML is competitive with existing methods and often yields better adaptation with fewer queries. Citation @inproceedings{es_maml, author = {Xingyou Song and Wenbo Gao and Yuxiang Yang and Krzysztof Choromanski and Aldo Pacchiano and Yunhao Tang}, title = {{ES-MAML:} Simple Hessian-Free Meta Learning}, booktitle = {8th International Conference on Learning Representations, {ICLR} 2020, Addis Ababa, Ethiopia, April 26-30, 2020}, year = {2020}, url = {https://openreview.net/forum?id=S1exA2NtDB}, } @article{rapidly, author = {Xingyou Song and Yuxiang Yang and Krzysztof Choromanski and Ken Caluwaerts and Wenbo Gao and Chelsea Finn and Jie Tan}, title = {Rapidly Adaptable Legged Robots via Evolutionary Meta-Learning}, booktitle = {International Conference on Intelligent Robots and Systems, {IROS} 2020}, year = {2020}, url = {https://arxiv.org/abs/2003.01239}, } Usage In order to run the algorithm, you must launch both the binaries es_maml_client (which produces the central 'aggregator') and multiple launches of es_maml_server (which produces the 'workers'). This depends on your particular distributed communication infrastructure, but we by default use GRPC. In order to use the default GRPC method of client-server communication, you must first create the proper pb2.py and pb2_grpc.py libraries from the .proto 's for both zero_order and first_order . This can be done via the commands (see discussion ): $ pip install protobuf $ pip install grpcio-tools==1.32 $ pip install googleapis-common-protos $ python -m grpc_tools.protoc --proto_path=. --python_out=. --grpc_python_out=. first_order.proto $ python -m grpc_tools.protoc --proto_path=. --python_out=. --grpc_python_out=. zero_order.proto Algorithms The hyperparameters are all contained in config.py . There are two algorithms: Zero Order First Order Zero Order : Uses custom adaptation operators, built using blackbox algorithms such as MCBlackboxOptimizer, DPP sampling, and Hill-Climbing. Collects state normalization data from all workers. First Order : Uses local-worker state normalization. Allows Hessian computation.","title":"ES-MAML"},{"location":"2%20Documentation/10%20ES-maml_tutorial/#es-maml","text":"Paper: \"ES-MAML: Simple Hessian-Free Meta Learning\" This was also used in \"Rapidly Adaptable Legged Robots via Evolutionary Meta-Learning\" with associated Google AI Blog Post .","title":"ES-MAML"},{"location":"2%20Documentation/10%20ES-maml_tutorial/#overviewabstract","text":"We introduce ES-MAML, a new framework for solving the model agnostic meta learning (MAML) problem based on Evolution Strategies (ES). Existing algorithms for MAML are based on policy gradients, and incur significant difficulties when attempting to estimate second derivatives using backpropagation on stochastic policies. We show how ES can be applied to MAML to obtain an algorithm which avoids the problem of estimating second derivatives, and is also conceptually simple and easy to implement. Moreover, ES-MAML can handle new types of non-smooth adaptation operators, and other techniques for improving performance and estimation of ES methods become applicable. We show empirically that ES-MAML is competitive with existing methods and often yields better adaptation with fewer queries.","title":"Overview[Abstract]"},{"location":"2%20Documentation/10%20ES-maml_tutorial/#citation","text":"@inproceedings{es_maml, author = {Xingyou Song and Wenbo Gao and Yuxiang Yang and Krzysztof Choromanski and Aldo Pacchiano and Yunhao Tang}, title = {{ES-MAML:} Simple Hessian-Free Meta Learning}, booktitle = {8th International Conference on Learning Representations, {ICLR} 2020, Addis Ababa, Ethiopia, April 26-30, 2020}, year = {2020}, url = {https://openreview.net/forum?id=S1exA2NtDB}, } @article{rapidly, author = {Xingyou Song and Yuxiang Yang and Krzysztof Choromanski and Ken Caluwaerts and Wenbo Gao and Chelsea Finn and Jie Tan}, title = {Rapidly Adaptable Legged Robots via Evolutionary Meta-Learning}, booktitle = {International Conference on Intelligent Robots and Systems, {IROS} 2020}, year = {2020}, url = {https://arxiv.org/abs/2003.01239}, }","title":"Citation"},{"location":"2%20Documentation/10%20ES-maml_tutorial/#usage","text":"In order to run the algorithm, you must launch both the binaries es_maml_client (which produces the central 'aggregator') and multiple launches of es_maml_server (which produces the 'workers'). This depends on your particular distributed communication infrastructure, but we by default use GRPC. In order to use the default GRPC method of client-server communication, you must first create the proper pb2.py and pb2_grpc.py libraries from the .proto 's for both zero_order and first_order . This can be done via the commands (see discussion ): $ pip install protobuf $ pip install grpcio-tools==1.32 $ pip install googleapis-common-protos $ python -m grpc_tools.protoc --proto_path=. --python_out=. --grpc_python_out=. first_order.proto $ python -m grpc_tools.protoc --proto_path=. --python_out=. --grpc_python_out=. zero_order.proto","title":"Usage"},{"location":"2%20Documentation/10%20ES-maml_tutorial/#algorithms","text":"The hyperparameters are all contained in config.py . There are two algorithms: Zero Order First Order Zero Order : Uses custom adaptation operators, built using blackbox algorithms such as MCBlackboxOptimizer, DPP sampling, and Hill-Climbing. Collects state normalization data from all workers. First Order : Uses local-worker state normalization. Allows Hessian computation.","title":"Algorithms"},{"location":"2%20Documentation/11%20CNAP_tutorial/","text":"CNAP Paper: Fast and Flexible Multi-Task Classification Using Conditional Neural Adaptive Processes and TASKNORM: Rethinking Batch Normalization for Meta-Learning . The code has been authored by: John Bronskill, Jonathan Gordon, and James Reqeima. Overview[Abstract] The goal of this paper is to design image classification systems that, after an initial multi-task training phase, can automatically adapt to new tasks encountered at test time. We introduce a conditional neural process based approach to the multi-task classification setting for this purpose, and establish connections to the meta-learning and few-shot learning literature. The resulting approach, called CNAPS, comprises a classifier whose parameters are modulated by an adaptation network that takes the current task\u2019s dataset as input. We demonstrate that CNAPS achieves state-of-theart results on the challenging META-DATASET benchmark indicating high-quality transfer-learning. We show that the approach is robust, avoiding both over-fitting in low-shot regimes and under-fitting in high-shot regimes. Timing experiments reveal that CNAPS is computationally efficient at test-time as it does not involve gradient based adaptation. Finally, we show that trained models are immediately deployable to continual learning and active learning where they can outperform existing approaches that do not leverage transfer learning. Results The FiLM + TaskNorm configuration consistently yields the best results and trains in much less time than the other configurations. A meta-trained FiLM + TaskNorm-i model is included in the models folder which produced the results shown below. The model was trained for 40,000 iterations on two 16GB GPUs. Note that these results differ from those published in our paper as they now fix the shuffle buffer bug described in meta-dataset issue #54 . In particular, the results for the Traffic Signs dataset are considerable worse. However, the results for other datasets are comparable (some slightly better, some slightly worse). Model trained on all datasets Dataset FiLM + TaskNorm ILSVRC 50.8\u00b11.1 Omniglot 91.7\u00b10.5 Aircraft 83.7\u00b10.6 Birds 73.6\u00b10.9 Textures 59.5\u00b10.7 Quick Draw 74.7\u00b10.8 Fungi 50.2\u00b11.1 VGG Flower 88.9\u00b10.5 Traffic Signs 56.5\u00b11.1 MSCOCO 39.4\u00b11.0 MNIST 92.3\u00b10.4 CIFAR10 68.5\u00b10.9 CIFAR100 56.1\u00b11.1 Citation If you use this code, please cite our CNAPs and TaskNorm papers: @incollection{requeima2019cnaps, title = {Fast and Flexible Multi-Task Classification using Conditional Neural Adaptive Processes}, author = {Requeima, James and Gordon, Jonathan and Bronskill, John and Nowozin, Sebastian and Turner, Richard E}, booktitle = {Advances in Neural Information Processing Systems 32}, editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\\' Alch\\'{e}-Buc and E. Fox and R. Garnett}, pages = {7957--7968}, year = {2019}, publisher = {Curran Associates, Inc.}, } @incollection{bronskill2020tasknorm, title = {TaskNorm: Rethinking Batch Normalization for Meta-Learning}, author = {Bronskill, John and Gordon, Jonathan and Requeima, James and Nowozin, Sebastian and Turner, Richard}, booktitle = {Proceedings of the 37th International Conference on Machine Learning}, volume = {119}, series = {Proceedings of Machine Learning Research}, publisher = {PMLR}, year = {2020} } Dependencies This code requires the following: Python 3.5 or greater PyTorch 1.0 or greater TensorFlow 1.15 or greater This code has been recently verified on PyTorch 1.7 and TensorFlow 2.3. GPU Requirements To train or test a CNAPs model with auto-regressive FiLM adaptation on Meta-Dataset, 2 GPUs with 16GB or more memory are required. To train or test a CNAPs model with FiLM only adaptation plus TaskNorm on Meta-Dataset, 2 GPUs with 16GB or more memory are required. It is not currently possible to run a CNAPs model with auto-regressive FiLM adaptation plus TaskNorm on Meta-Dataset (even using 2 GPUs with 16GB of memory). It may be possible (we have not tried) to run this configuration on 2 GPUs with 24GB of memory. The other modes require only a single GPU with at least 16 GB of memory. If you want to run any of the modes on a single GPU, you can train on a single dataset with fixed shot and way. If shot and way are not too large, this configuration will require a single GPU with less than 16GB of memory. An example command line is (though this will not reproduce the meta-dataset results): python run_cnaps.py --feature_adaptation film -i 20000 -lr 0.001 --batch_normalization task_norm-i -- dataset omniglot --way 5 --shot 5 --data_path <path to directory containing Meta-Dataset records> Installation Clone or download this repository. Configure Meta-Dataset: Follow the the \"User instructions\" in the Meta-Dataset repository (https://github.com/google-research/meta-dataset) for \"Installation\" and \"Downloading and converting datasets\". This will take some time. Install additional test datasets (MNIST, CIFAR10, CIFAR100): Change to the $DATASRC directory: cd $DATASRC Download the MNIST test images: wget http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz Download the MNIST test labels: wget http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz Download the CIFAR10 dataset: wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz Extract the CIFAR10 dataset: tar -zxvf cifar-10-python.tar.gz Download the CIFAR100 dataset: wget https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz Extract the CIFAR10 dataset: tar -zxvf cifar-100-python.tar.gz Change to the cnaps/src directory in the repository. Run: python prepare_extra_datasets.py Usage To train and test CNAPs on Meta-Dataset: First run the following two commands. ulimit -n 50000 export META_DATASET_ROOT=<root directory of the cloned or downloaded Meta-Dataset repository> Note the above commands need to be run every time you open a new command shell. Execute the run_cnaps.py script from the src directory following the instructions at the beginning of the file.","title":"CNAP"},{"location":"2%20Documentation/11%20CNAP_tutorial/#cnap","text":"Paper: Fast and Flexible Multi-Task Classification Using Conditional Neural Adaptive Processes and TASKNORM: Rethinking Batch Normalization for Meta-Learning . The code has been authored by: John Bronskill, Jonathan Gordon, and James Reqeima.","title":"CNAP"},{"location":"2%20Documentation/11%20CNAP_tutorial/#overviewabstract","text":"The goal of this paper is to design image classification systems that, after an initial multi-task training phase, can automatically adapt to new tasks encountered at test time. We introduce a conditional neural process based approach to the multi-task classification setting for this purpose, and establish connections to the meta-learning and few-shot learning literature. The resulting approach, called CNAPS, comprises a classifier whose parameters are modulated by an adaptation network that takes the current task\u2019s dataset as input. We demonstrate that CNAPS achieves state-of-theart results on the challenging META-DATASET benchmark indicating high-quality transfer-learning. We show that the approach is robust, avoiding both over-fitting in low-shot regimes and under-fitting in high-shot regimes. Timing experiments reveal that CNAPS is computationally efficient at test-time as it does not involve gradient based adaptation. Finally, we show that trained models are immediately deployable to continual learning and active learning where they can outperform existing approaches that do not leverage transfer learning.","title":"Overview[Abstract]"},{"location":"2%20Documentation/11%20CNAP_tutorial/#results","text":"The FiLM + TaskNorm configuration consistently yields the best results and trains in much less time than the other configurations. A meta-trained FiLM + TaskNorm-i model is included in the models folder which produced the results shown below. The model was trained for 40,000 iterations on two 16GB GPUs. Note that these results differ from those published in our paper as they now fix the shuffle buffer bug described in meta-dataset issue #54 . In particular, the results for the Traffic Signs dataset are considerable worse. However, the results for other datasets are comparable (some slightly better, some slightly worse). Model trained on all datasets Dataset FiLM + TaskNorm ILSVRC 50.8\u00b11.1 Omniglot 91.7\u00b10.5 Aircraft 83.7\u00b10.6 Birds 73.6\u00b10.9 Textures 59.5\u00b10.7 Quick Draw 74.7\u00b10.8 Fungi 50.2\u00b11.1 VGG Flower 88.9\u00b10.5 Traffic Signs 56.5\u00b11.1 MSCOCO 39.4\u00b11.0 MNIST 92.3\u00b10.4 CIFAR10 68.5\u00b10.9 CIFAR100 56.1\u00b11.1","title":"Results"},{"location":"2%20Documentation/11%20CNAP_tutorial/#citation","text":"If you use this code, please cite our CNAPs and TaskNorm papers: @incollection{requeima2019cnaps, title = {Fast and Flexible Multi-Task Classification using Conditional Neural Adaptive Processes}, author = {Requeima, James and Gordon, Jonathan and Bronskill, John and Nowozin, Sebastian and Turner, Richard E}, booktitle = {Advances in Neural Information Processing Systems 32}, editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\\' Alch\\'{e}-Buc and E. Fox and R. Garnett}, pages = {7957--7968}, year = {2019}, publisher = {Curran Associates, Inc.}, } @incollection{bronskill2020tasknorm, title = {TaskNorm: Rethinking Batch Normalization for Meta-Learning}, author = {Bronskill, John and Gordon, Jonathan and Requeima, James and Nowozin, Sebastian and Turner, Richard}, booktitle = {Proceedings of the 37th International Conference on Machine Learning}, volume = {119}, series = {Proceedings of Machine Learning Research}, publisher = {PMLR}, year = {2020} }","title":"Citation"},{"location":"2%20Documentation/11%20CNAP_tutorial/#dependencies","text":"This code requires the following: Python 3.5 or greater PyTorch 1.0 or greater TensorFlow 1.15 or greater This code has been recently verified on PyTorch 1.7 and TensorFlow 2.3.","title":"Dependencies"},{"location":"2%20Documentation/11%20CNAP_tutorial/#gpu-requirements","text":"To train or test a CNAPs model with auto-regressive FiLM adaptation on Meta-Dataset, 2 GPUs with 16GB or more memory are required. To train or test a CNAPs model with FiLM only adaptation plus TaskNorm on Meta-Dataset, 2 GPUs with 16GB or more memory are required. It is not currently possible to run a CNAPs model with auto-regressive FiLM adaptation plus TaskNorm on Meta-Dataset (even using 2 GPUs with 16GB of memory). It may be possible (we have not tried) to run this configuration on 2 GPUs with 24GB of memory. The other modes require only a single GPU with at least 16 GB of memory. If you want to run any of the modes on a single GPU, you can train on a single dataset with fixed shot and way. If shot and way are not too large, this configuration will require a single GPU with less than 16GB of memory. An example command line is (though this will not reproduce the meta-dataset results): python run_cnaps.py --feature_adaptation film -i 20000 -lr 0.001 --batch_normalization task_norm-i -- dataset omniglot --way 5 --shot 5 --data_path <path to directory containing Meta-Dataset records>","title":"GPU Requirements"},{"location":"2%20Documentation/11%20CNAP_tutorial/#installation","text":"Clone or download this repository. Configure Meta-Dataset: Follow the the \"User instructions\" in the Meta-Dataset repository (https://github.com/google-research/meta-dataset) for \"Installation\" and \"Downloading and converting datasets\". This will take some time. Install additional test datasets (MNIST, CIFAR10, CIFAR100): Change to the $DATASRC directory: cd $DATASRC Download the MNIST test images: wget http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz Download the MNIST test labels: wget http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz Download the CIFAR10 dataset: wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz Extract the CIFAR10 dataset: tar -zxvf cifar-10-python.tar.gz Download the CIFAR100 dataset: wget https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz Extract the CIFAR10 dataset: tar -zxvf cifar-100-python.tar.gz Change to the cnaps/src directory in the repository. Run: python prepare_extra_datasets.py","title":"Installation"},{"location":"2%20Documentation/11%20CNAP_tutorial/#usage","text":"To train and test CNAPs on Meta-Dataset: First run the following two commands. ulimit -n 50000 export META_DATASET_ROOT=<root directory of the cloned or downloaded Meta-Dataset repository> Note the above commands need to be run every time you open a new command shell. Execute the run_cnaps.py script from the src directory following the instructions at the beginning of the file.","title":"Usage"},{"location":"2%20Documentation/12%20SNAIL_tutorial/","text":"SNAIL Paper: An implementation of Simple Neural Attentive Meta-Learner (SNAIL) ( paper ) in PyTorch. Much of the boiler plate code for setting up datasets and what not came from a PyTorch implementation of Prototypical Networks . Overview[Abstract] Deep neural networks excel in regimes with large amounts of data, but tend to struggle when data is scarce or when they need to adapt quickly to changes in the task. In response, recent work in meta-learning proposes training a meta-learner on a distribution of similar tasks, in the hopes of generalization to novel but related tasks by learning a high-level strategy that captures the essence of the problem it is asked to solve. However, many recent meta-learning approaches are extensively hand-designed, either using architectures specialized to a particular application, or hard-coding algorithmic components that constrain how the meta-learner solves the task. We propose a class of simple and generic meta-learner architectures that use a novel combination of temporal convolutions and soft attention; the former to aggregate information from past experience and the latter to pinpoint specific pieces of information. In the most extensive set of meta-learning experiments to date, we evaluate the resulting Simple Neural AttentIve Learner (or SNAIL) on several heavily-benchmarked tasks. On all tasks, in both supervised and reinforcement learning, SNAIL attains state-of-the-art performance by significant margins. Results Below are the following attempts to reproduce the results in the reference paper: Omniglot: Model 1-shot (5-way Acc.) 5-shot (5-way Acc.) 1 -shot (20-way Acc.) 5-shot (20-way Acc.) Reference Paper 99.07% 99.78% 97.64% 99.36% This repo 98.31%* 99.26%** 93.75%\u00b0 97.88%\u00b0\u00b0 Data Follow the instructions here: https://github.com/renmengye/few-shot-ssl-public to download the mini-imagenet dataset. Usage * achieved running python train.py --exp omniglot_5way_1shot --cuda * achieved running python train.py --exp omniglot_5way_5shot --num_samples 5 --cuda * achieved running python train.py --exp omniglot_20way_1shot --num_cls 20 --cuda * achieved running python train.py --exp omniglot_20way_5shot --num_cls 20 --num_samples 5 --cuda Mini-Imagenet: In progress. Writing the code for the experiments should be done soon but the main bottleneck in these experiments for me is compute, if someone would be willing to run and report numbers that would be much appreciated. RL: In progress.","title":"SNAIL"},{"location":"2%20Documentation/12%20SNAIL_tutorial/#snail","text":"Paper: An implementation of Simple Neural Attentive Meta-Learner (SNAIL) ( paper ) in PyTorch. Much of the boiler plate code for setting up datasets and what not came from a PyTorch implementation of Prototypical Networks .","title":"SNAIL"},{"location":"2%20Documentation/12%20SNAIL_tutorial/#overviewabstract","text":"Deep neural networks excel in regimes with large amounts of data, but tend to struggle when data is scarce or when they need to adapt quickly to changes in the task. In response, recent work in meta-learning proposes training a meta-learner on a distribution of similar tasks, in the hopes of generalization to novel but related tasks by learning a high-level strategy that captures the essence of the problem it is asked to solve. However, many recent meta-learning approaches are extensively hand-designed, either using architectures specialized to a particular application, or hard-coding algorithmic components that constrain how the meta-learner solves the task. We propose a class of simple and generic meta-learner architectures that use a novel combination of temporal convolutions and soft attention; the former to aggregate information from past experience and the latter to pinpoint specific pieces of information. In the most extensive set of meta-learning experiments to date, we evaluate the resulting Simple Neural AttentIve Learner (or SNAIL) on several heavily-benchmarked tasks. On all tasks, in both supervised and reinforcement learning, SNAIL attains state-of-the-art performance by significant margins.","title":"Overview[Abstract]"},{"location":"2%20Documentation/12%20SNAIL_tutorial/#results","text":"Below are the following attempts to reproduce the results in the reference paper:","title":"Results"},{"location":"2%20Documentation/12%20SNAIL_tutorial/#omniglot","text":"Model 1-shot (5-way Acc.) 5-shot (5-way Acc.) 1 -shot (20-way Acc.) 5-shot (20-way Acc.) Reference Paper 99.07% 99.78% 97.64% 99.36% This repo 98.31%* 99.26%** 93.75%\u00b0 97.88%\u00b0\u00b0","title":"Omniglot:"},{"location":"2%20Documentation/12%20SNAIL_tutorial/#data","text":"Follow the instructions here: https://github.com/renmengye/few-shot-ssl-public to download the mini-imagenet dataset.","title":"Data"},{"location":"2%20Documentation/12%20SNAIL_tutorial/#usage","text":"* achieved running python train.py --exp omniglot_5way_1shot --cuda * achieved running python train.py --exp omniglot_5way_5shot --num_samples 5 --cuda * achieved running python train.py --exp omniglot_20way_1shot --num_cls 20 --cuda * achieved running python train.py --exp omniglot_20way_5shot --num_cls 20 --num_samples 5 --cuda","title":"Usage"},{"location":"2%20Documentation/12%20SNAIL_tutorial/#mini-imagenet","text":"In progress. Writing the code for the experiments should be done soon but the main bottleneck in these experiments for me is compute, if someone would be willing to run and report numbers that would be much appreciated.","title":"Mini-Imagenet:"},{"location":"2%20Documentation/12%20SNAIL_tutorial/#rl","text":"In progress.","title":"RL:"},{"location":"2%20Documentation/2%20MetaOptNet_tutorial/","text":"MetaOptNet Paper: Meta-Learning with Differentiable Convex Optimization Kwonjoon Lee, Subhransu Maji , Avinash Ravichandran, Stefano Soatto CVPR 2019 ( Oral ) Overview [Abstract] Many meta-learning approaches for few-shot learning rely on simple base learners such as nearest-neighbor classifiers. However, even in the few-shot regime, discriminatively trained linear predictors can offer better generalization. They propose to use these predictors as base learners to learn representations for few-shot learning and show they offer better tradeoffs between feature size and performance across a range of few-shot recognition benchmarks. Their objective is to learn feature embeddings that generalize well under a linear classification rule for novel categories. To efficiently solve the objective, the authors exploit two properties of linear classifiers: implicit differentiation of the optimality conditions of the convex problem and the dual formulation of the optimization problem. This allows us to use high-dimensional embeddings with improved generalization at a modest increase in computational overhead. MetaOptNet achieves state-of-the-art performance on miniImageNet, tieredImageNet, CIFAR-FS and FC100 few-shot learning benchmarks. Results Citation @inproceedings{lee2019meta, title={Meta-Learning with Differentiable Convex Optimization}, author={Kwonjoon Lee and Subhransu Maji and Avinash Ravichandran and Stefano Soatto}, booktitle={CVPR}, year={2019} } Dependencies Python 2.7+ (not tested on Python 3) PyTorch 0.4.0+ qpth 0.0.11+ tqdm Usage Installation Download and decompress dataset files: miniImageNet (courtesy of Spyros Gidaris ), tieredImageNet , FC100 , CIFAR-FS Or search the dataset and download it dataset in Datasets For each dataset loader, specify the path to the directory. For example, in MetaOptNet/data/mini_imagenet.py line 30: python _MINI_IMAGENET_DATASET_DIR = 'path/to/miniImageNet' Meta-training To train MetaOptNet-SVM on 5-way miniImageNet benchmark: bash python train.py --gpu 0,1,2,3 --save-path \"./experiments/miniImageNet_MetaOptNet_SVM\" --train-shot 15 \\ --head SVM --network ResNet --dataset miniImageNet --eps 0.1 As shown in Figure 2, it can meta-train the embedding once with a high shot for all meta-testing shots. It don't need to meta-train with all possible meta-test shots unlike in Prototypical Networks. You can experiment with varying base learners by changing '--head' argument to ProtoNet or Ridge. Also, you can change the backbone architecture to vanilla 4-layer conv net by setting '--network' argument to ProtoNet. For other arguments, please see MetaOptNet/train.py from lines 85 to 114. To train MetaOptNet-SVM on 5-way tieredImageNet benchmark: bash python train.py --gpu 0,1,2,3 --save-path \"./experiments/tieredImageNet_MetaOptNet_SVM\" --train-shot 10 \\ --head SVM --network ResNet --dataset tieredImageNet To train MetaOptNet-RR on 5-way CIFAR-FS benchmark: bash python train.py --gpu 0 --save-path \"./experiments/CIFAR_FS_MetaOptNet_RR\" --train-shot 5 \\ --head Ridge --network ResNet --dataset CIFAR_FS To train MetaOptNet-RR on 5-way FC100 benchmark: bash python train.py --gpu 0 --save-path \"./experiments/FC100_MetaOptNet_RR\" --train-shot 15 \\ --head Ridge --network ResNet --dataset FC100 Meta-testing To test MetaOptNet-SVM on 5-way miniImageNet 1-shot benchmark: python test.py --gpu 0,1,2,3 --load ./experiments/miniImageNet_MetaOptNet_SVM/best_model.pth --episode 1000 \\ --way 5 --shot 1 --query 15 --head SVM --network ResNet --dataset miniImageNet Similarly, to test MetaOptNet-SVM on 5-way miniImageNet 5-shot benchmark: python test.py --gpu 0,1,2,3 --load ./experiments/miniImageNet_MetaOptNet_SVM/best_model.pth --episode 1000 \\ --way 5 --shot 5 --query 15 --head SVM --network ResNet --dataset miniImageNet","title":"MetaOptNet"},{"location":"2%20Documentation/2%20MetaOptNet_tutorial/#metaoptnet","text":"Paper: Meta-Learning with Differentiable Convex Optimization Kwonjoon Lee, Subhransu Maji , Avinash Ravichandran, Stefano Soatto CVPR 2019 ( Oral )","title":"MetaOptNet"},{"location":"2%20Documentation/2%20MetaOptNet_tutorial/#overview-abstract","text":"Many meta-learning approaches for few-shot learning rely on simple base learners such as nearest-neighbor classifiers. However, even in the few-shot regime, discriminatively trained linear predictors can offer better generalization. They propose to use these predictors as base learners to learn representations for few-shot learning and show they offer better tradeoffs between feature size and performance across a range of few-shot recognition benchmarks. Their objective is to learn feature embeddings that generalize well under a linear classification rule for novel categories. To efficiently solve the objective, the authors exploit two properties of linear classifiers: implicit differentiation of the optimality conditions of the convex problem and the dual formulation of the optimization problem. This allows us to use high-dimensional embeddings with improved generalization at a modest increase in computational overhead. MetaOptNet achieves state-of-the-art performance on miniImageNet, tieredImageNet, CIFAR-FS and FC100 few-shot learning benchmarks.","title":"Overview [Abstract]"},{"location":"2%20Documentation/2%20MetaOptNet_tutorial/#results","text":"","title":"Results"},{"location":"2%20Documentation/2%20MetaOptNet_tutorial/#citation","text":"@inproceedings{lee2019meta, title={Meta-Learning with Differentiable Convex Optimization}, author={Kwonjoon Lee and Subhransu Maji and Avinash Ravichandran and Stefano Soatto}, booktitle={CVPR}, year={2019} }","title":"Citation"},{"location":"2%20Documentation/2%20MetaOptNet_tutorial/#dependencies","text":"Python 2.7+ (not tested on Python 3) PyTorch 0.4.0+ qpth 0.0.11+ tqdm","title":"Dependencies"},{"location":"2%20Documentation/2%20MetaOptNet_tutorial/#usage","text":"","title":"Usage"},{"location":"2%20Documentation/2%20MetaOptNet_tutorial/#installation","text":"Download and decompress dataset files: miniImageNet (courtesy of Spyros Gidaris ), tieredImageNet , FC100 , CIFAR-FS Or search the dataset and download it dataset in Datasets For each dataset loader, specify the path to the directory. For example, in MetaOptNet/data/mini_imagenet.py line 30: python _MINI_IMAGENET_DATASET_DIR = 'path/to/miniImageNet'","title":"Installation"},{"location":"2%20Documentation/2%20MetaOptNet_tutorial/#meta-training","text":"To train MetaOptNet-SVM on 5-way miniImageNet benchmark: bash python train.py --gpu 0,1,2,3 --save-path \"./experiments/miniImageNet_MetaOptNet_SVM\" --train-shot 15 \\ --head SVM --network ResNet --dataset miniImageNet --eps 0.1 As shown in Figure 2, it can meta-train the embedding once with a high shot for all meta-testing shots. It don't need to meta-train with all possible meta-test shots unlike in Prototypical Networks. You can experiment with varying base learners by changing '--head' argument to ProtoNet or Ridge. Also, you can change the backbone architecture to vanilla 4-layer conv net by setting '--network' argument to ProtoNet. For other arguments, please see MetaOptNet/train.py from lines 85 to 114. To train MetaOptNet-SVM on 5-way tieredImageNet benchmark: bash python train.py --gpu 0,1,2,3 --save-path \"./experiments/tieredImageNet_MetaOptNet_SVM\" --train-shot 10 \\ --head SVM --network ResNet --dataset tieredImageNet To train MetaOptNet-RR on 5-way CIFAR-FS benchmark: bash python train.py --gpu 0 --save-path \"./experiments/CIFAR_FS_MetaOptNet_RR\" --train-shot 5 \\ --head Ridge --network ResNet --dataset CIFAR_FS To train MetaOptNet-RR on 5-way FC100 benchmark: bash python train.py --gpu 0 --save-path \"./experiments/FC100_MetaOptNet_RR\" --train-shot 15 \\ --head Ridge --network ResNet --dataset FC100","title":"Meta-training"},{"location":"2%20Documentation/2%20MetaOptNet_tutorial/#meta-testing","text":"To test MetaOptNet-SVM on 5-way miniImageNet 1-shot benchmark: python test.py --gpu 0,1,2,3 --load ./experiments/miniImageNet_MetaOptNet_SVM/best_model.pth --episode 1000 \\ --way 5 --shot 1 --query 15 --head SVM --network ResNet --dataset miniImageNet Similarly, to test MetaOptNet-SVM on 5-way miniImageNet 5-shot benchmark: python test.py --gpu 0,1,2,3 --load ./experiments/miniImageNet_MetaOptNet_SVM/best_model.pth --episode 1000 \\ --way 5 --shot 5 --query 15 --head SVM --network ResNet --dataset miniImageNet","title":"Meta-testing"},{"location":"2%20Documentation/3%20reptile_tutorial/","text":"Reptile PyTorch implementation of the supervised learning experiments from the paper: Reptile: A Scalable Meta-Learning Algorithm: https://blog.openai.com/reptile/ , which is based on Model-Agnostic Meta-Learning (MAML): https://arxiv.org/abs/1703.03400 Overview [Abstract] This paper considers meta-learning problems, where there is a distribution of tasks, and obtain an agent that performs well (i.e., learns quickly) when presented with a previously unseen task sampled from this distribution. They analyze a family of algorithms for learning a parameter initialization that can be fine-tuned quickly on a new task, using only firstorder derivatives for the meta-learning updates. This family includes and generalizes first-order MAML, an approximation to MAML obtained by ignoring second-order derivatives. It also includes Reptile, a new algorithm that they introduce here, which works by repeatedly sampling a task, training on it, and moving the initialization towards the trained weights on that task. The authors expand on the results from Finn et al. showing that first-order meta-learning algorithms perform well on some well-established benchmarks for few-shot classification, and they provide theoretical analysis aimed at understanding why these algorithms work. Ominiglot change dataset = 'omniglot' in main.py and just run python main.py , the program will download omniglot dataset automatically. modify the value of meta_batchsz to fit your GPU memory size. Results Model Fine Tune 5-way Acc. 20-way Acc 1-shot 5-shot 1-shot 5-shot MANN N 82.8% 94.9% - - Matching Nets N 98.1% 98.9% 93.8% 98.5% Matching Nets Y 97.9% 98.7% 93.5% 98.7% MAML Y 98.7+-0.4% 99.9+-0.1% 95.8+-0.3% 98.9+-0.2% This Code Y 98.62% 99.52% 96.09% 98.24% 5way 1shot episode: 11580*512 finetune acc:0.990234 test acc:0.986250 5way 5shot episode: 27180*128 finetune acc:0.995625 test acc:0.995219 20way 1shot episode: 23160*128 finetune acc:0.960937 test acc:0.960898 20way 5shot episode: 11580*32 finetune acc:0.985938 test acc:0.982437 miniImagenet train mini-imagenet is extremely slow, since the code train task one by one squentially. download mini-imagenet dataset and make it looks like: mini-imagenet/ \u251c\u2500\u2500 images \u251c\u2500\u2500 n0210891500001298.jpg \u251c\u2500\u2500 n0287152500001298.jpg ... \u251c\u2500\u2500 test.csv \u251c\u2500\u2500 val.csv \u2514\u2500\u2500 train.csv MAML-Pytorch/ \u251c\u2500\u2500 main.py \u251c\u2500\u2500 meta.py \u251c\u2500\u2500 Readme.md \u251c\u2500\u2500 naive.md ... change dataset = 'mini-imagenet' in main.py and just run python main.py . Results Model Fine Tune 5-way Acc. 20-way Acc 1-shot 5-shot 1-shot 5-shot Matching Nets N 43.56% 55.31% 17.31% 22.69% Meta-LSTM 43.44% 60.60% 16.70% 26.06% MAML Y 48.7% 63.11% 16.49% 19.29% Ours Y - - - -","title":"Reptile"},{"location":"2%20Documentation/3%20reptile_tutorial/#reptile","text":"PyTorch implementation of the supervised learning experiments from the paper: Reptile: A Scalable Meta-Learning Algorithm: https://blog.openai.com/reptile/ , which is based on Model-Agnostic Meta-Learning (MAML): https://arxiv.org/abs/1703.03400","title":"Reptile"},{"location":"2%20Documentation/3%20reptile_tutorial/#overview-abstract","text":"This paper considers meta-learning problems, where there is a distribution of tasks, and obtain an agent that performs well (i.e., learns quickly) when presented with a previously unseen task sampled from this distribution. They analyze a family of algorithms for learning a parameter initialization that can be fine-tuned quickly on a new task, using only firstorder derivatives for the meta-learning updates. This family includes and generalizes first-order MAML, an approximation to MAML obtained by ignoring second-order derivatives. It also includes Reptile, a new algorithm that they introduce here, which works by repeatedly sampling a task, training on it, and moving the initialization towards the trained weights on that task. The authors expand on the results from Finn et al. showing that first-order meta-learning algorithms perform well on some well-established benchmarks for few-shot classification, and they provide theoretical analysis aimed at understanding why these algorithms work.","title":"Overview [Abstract]"},{"location":"2%20Documentation/3%20reptile_tutorial/#ominiglot","text":"change dataset = 'omniglot' in main.py and just run python main.py , the program will download omniglot dataset automatically. modify the value of meta_batchsz to fit your GPU memory size.","title":"Ominiglot"},{"location":"2%20Documentation/3%20reptile_tutorial/#results","text":"Model Fine Tune 5-way Acc. 20-way Acc 1-shot 5-shot 1-shot 5-shot MANN N 82.8% 94.9% - - Matching Nets N 98.1% 98.9% 93.8% 98.5% Matching Nets Y 97.9% 98.7% 93.5% 98.7% MAML Y 98.7+-0.4% 99.9+-0.1% 95.8+-0.3% 98.9+-0.2% This Code Y 98.62% 99.52% 96.09% 98.24% 5way 1shot episode: 11580*512 finetune acc:0.990234 test acc:0.986250 5way 5shot episode: 27180*128 finetune acc:0.995625 test acc:0.995219 20way 1shot episode: 23160*128 finetune acc:0.960937 test acc:0.960898 20way 5shot episode: 11580*32 finetune acc:0.985938 test acc:0.982437","title":"Results"},{"location":"2%20Documentation/3%20reptile_tutorial/#miniimagenet","text":"train mini-imagenet is extremely slow, since the code train task one by one squentially. download mini-imagenet dataset and make it looks like: mini-imagenet/ \u251c\u2500\u2500 images \u251c\u2500\u2500 n0210891500001298.jpg \u251c\u2500\u2500 n0287152500001298.jpg ... \u251c\u2500\u2500 test.csv \u251c\u2500\u2500 val.csv \u2514\u2500\u2500 train.csv MAML-Pytorch/ \u251c\u2500\u2500 main.py \u251c\u2500\u2500 meta.py \u251c\u2500\u2500 Readme.md \u251c\u2500\u2500 naive.md ... change dataset = 'mini-imagenet' in main.py and just run python main.py .","title":"miniImagenet"},{"location":"2%20Documentation/3%20reptile_tutorial/#results_1","text":"Model Fine Tune 5-way Acc. 20-way Acc 1-shot 5-shot 1-shot 5-shot Matching Nets N 43.56% 55.31% 17.31% 22.69% Meta-LSTM 43.44% 60.60% 16.70% 26.06% MAML Y 48.7% 63.11% 16.49% 19.29% Ours Y - - - -","title":"Results"},{"location":"2%20Documentation/4%20proto_tutorial/","text":"Prototypical Network Paper Prototypical Networks for Few-shot Learning . Overview [Abstract] This paper propose prototypical networks for the problem of few-shot classification, where a classifier must generalize to new classes not seen in the training set, given only a small number of examples of each new class. Prototypical networks learn a metric space in which classification can be performed by computing distances to prototype representations of each class. Compared to recent approaches for few-shot learning, they reflect a simpler inductive bias that is beneficial in this limited-data regime, and achieve excellent results. This paper provide an analysis showing that some simple design decisions can yield substantial improvements over recent approaches involving complicated architectural choices and meta-learning. The authors further extend prototypical networks to zero-shot learning and achieve state-of-theart results on the CU-Birds dataset. Results Citation @inproceedings{snell2017prototypical, title={Prototypical Networks for Few-shot Learning}, author={Snell, Jake and Swersky, Kevin and Zemel, Richard}, booktitle={Advances in Neural Information Processing Systems}, year={2017} } Training a prototypical network Install dependencies This code has been tested on Ubuntu 16.04 with Python 3.6 and PyTorch 0.4. Install PyTorch and torchvision . Install torchnet by running pip install git+https://github.com/pytorch/tnt.git@master . Install the protonets package by running python setup.py install or python setup.py develop . Set up the Omniglot dataset Run sh download_omniglot.sh . Train the model Run python scripts/train/few_shot/run_train.py . This will run training and place the results into results . You can specify a different output directory by passing in the option --log.exp_dir EXP_DIR , where EXP_DIR is your desired output directory. If you are running on a GPU you can pass in the option --data.cuda . Re-run in trainval mode python scripts/train/few_shot/run_trainval.py . This will save your model into results/trainval by default. Evaluate Run evaluation as: python scripts/predict/few_shot/run_eval.py --model.model_path results/trainval/best_model.pt .","title":"Prototypical Network"},{"location":"2%20Documentation/4%20proto_tutorial/#prototypical-network","text":"Paper Prototypical Networks for Few-shot Learning .","title":"Prototypical Network"},{"location":"2%20Documentation/4%20proto_tutorial/#overview-abstract","text":"This paper propose prototypical networks for the problem of few-shot classification, where a classifier must generalize to new classes not seen in the training set, given only a small number of examples of each new class. Prototypical networks learn a metric space in which classification can be performed by computing distances to prototype representations of each class. Compared to recent approaches for few-shot learning, they reflect a simpler inductive bias that is beneficial in this limited-data regime, and achieve excellent results. This paper provide an analysis showing that some simple design decisions can yield substantial improvements over recent approaches involving complicated architectural choices and meta-learning. The authors further extend prototypical networks to zero-shot learning and achieve state-of-theart results on the CU-Birds dataset.","title":"Overview [Abstract]"},{"location":"2%20Documentation/4%20proto_tutorial/#results","text":"","title":"Results"},{"location":"2%20Documentation/4%20proto_tutorial/#citation","text":"@inproceedings{snell2017prototypical, title={Prototypical Networks for Few-shot Learning}, author={Snell, Jake and Swersky, Kevin and Zemel, Richard}, booktitle={Advances in Neural Information Processing Systems}, year={2017} }","title":"Citation"},{"location":"2%20Documentation/4%20proto_tutorial/#training-a-prototypical-network","text":"","title":"Training a prototypical network"},{"location":"2%20Documentation/4%20proto_tutorial/#install-dependencies","text":"This code has been tested on Ubuntu 16.04 with Python 3.6 and PyTorch 0.4. Install PyTorch and torchvision . Install torchnet by running pip install git+https://github.com/pytorch/tnt.git@master . Install the protonets package by running python setup.py install or python setup.py develop .","title":"Install dependencies"},{"location":"2%20Documentation/4%20proto_tutorial/#set-up-the-omniglot-dataset","text":"Run sh download_omniglot.sh .","title":"Set up the Omniglot dataset"},{"location":"2%20Documentation/4%20proto_tutorial/#train-the-model","text":"Run python scripts/train/few_shot/run_train.py . This will run training and place the results into results . You can specify a different output directory by passing in the option --log.exp_dir EXP_DIR , where EXP_DIR is your desired output directory. If you are running on a GPU you can pass in the option --data.cuda . Re-run in trainval mode python scripts/train/few_shot/run_trainval.py . This will save your model into results/trainval by default.","title":"Train the model"},{"location":"2%20Documentation/4%20proto_tutorial/#evaluate","text":"Run evaluation as: python scripts/predict/few_shot/run_eval.py --model.model_path results/trainval/best_model.pt .","title":"Evaluate"},{"location":"2%20Documentation/5%20relation_tutorial/","text":"Relation Network Paper: Learning to Compare: Relation Network for Few-Shot Learning (Few-Shot Learning part) For Zero-Shot Learning part, please visit here . Overview [Abstract] We present a conceptually simple, flexible, and general framework for few-shot learning, where a classifier must learn to recognise new classes given only few examples from each. Our method, called the Relation Network (RN), is trained end-to-end from scratch. During meta-learning, it learns to learn a deep distance metric to compare a small number of images within episodes, each of which is designed to simulate the few-shot setting. Once trained, a RN is able to classify images of new classes by computing relation scores between query images and the few examples of each new class without further updating the network. Besides providing improved performance on few-shot learning, our framework is easily extended to zero-shot learning. Extensive experiments on five benchmarks demonstrate that our simple approach provides a unified and effective approach for both of these two tasks. Results Omniglot miniimagenet Citation If you use this code in your research, please use the following BibTeX entry. @inproceedings{sung2018learning, title={Learning to Compare: Relation Network for Few-Shot Learning}, author={Sung, Flood and Yang, Yongxin and Zhang, Li and Xiang, Tao and Torr, Philip HS and Hospedales, Timothy M}, booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}, year={2018} } Reference MAML MAML-pytorch Requirements Python 2.7 Pytorch 0.3 Data For Omniglot experiments, I directly attach omniglot 28x28 resized images in the git, which is created based on omniglot and maml . For mini-Imagenet experiments, please download mini-Imagenet and put it in ./datas/mini-Imagenet and run proc_image.py to preprocess generate train/val/test datasets. (This process method is based on maml ). Train omniglot 5way 1 shot: python omniglot_train_one_shot.py -w 5 -s 1 -b 19 omniglot 5way 5 shot: python omniglot_train_few_shot.py -w 5 -s 5 -b 15 omniglot 20way 1 shot: python omniglot_train_one_shot.py -w 20 -s 1 -b 10 omniglot 20way 5 shot: python omniglot_train_few_shot.py -w 20 -s 5 -b 5 mini-Imagenet 5 way 1 shot: python miniimagenet_train_one_shot.py -w 5 -s 1 -b 15 mini-Imagenet 5 way 5 shot: python miniimagenet_train_few_shot.py -w 5 -s 5 -b 10 you can change -b parameter based on your GPU memory. Currently It will load my trained model, if you want to train from scratch, you can delete models by yourself. Test omniglot 5way 1 shot: python omniglot_test_one_shot.py -w 5 -s 1 Other experiments' testings are similar.","title":"Relation Network"},{"location":"2%20Documentation/5%20relation_tutorial/#relation-network","text":"Paper: Learning to Compare: Relation Network for Few-Shot Learning (Few-Shot Learning part) For Zero-Shot Learning part, please visit here .","title":"Relation Network"},{"location":"2%20Documentation/5%20relation_tutorial/#overview-abstract","text":"We present a conceptually simple, flexible, and general framework for few-shot learning, where a classifier must learn to recognise new classes given only few examples from each. Our method, called the Relation Network (RN), is trained end-to-end from scratch. During meta-learning, it learns to learn a deep distance metric to compare a small number of images within episodes, each of which is designed to simulate the few-shot setting. Once trained, a RN is able to classify images of new classes by computing relation scores between query images and the few examples of each new class without further updating the network. Besides providing improved performance on few-shot learning, our framework is easily extended to zero-shot learning. Extensive experiments on five benchmarks demonstrate that our simple approach provides a unified and effective approach for both of these two tasks.","title":"Overview [Abstract]"},{"location":"2%20Documentation/5%20relation_tutorial/#results","text":"","title":"Results"},{"location":"2%20Documentation/5%20relation_tutorial/#omniglot","text":"","title":"Omniglot"},{"location":"2%20Documentation/5%20relation_tutorial/#miniimagenet","text":"","title":"miniimagenet"},{"location":"2%20Documentation/5%20relation_tutorial/#citation","text":"If you use this code in your research, please use the following BibTeX entry. @inproceedings{sung2018learning, title={Learning to Compare: Relation Network for Few-Shot Learning}, author={Sung, Flood and Yang, Yongxin and Zhang, Li and Xiang, Tao and Torr, Philip HS and Hospedales, Timothy M}, booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}, year={2018} }","title":"Citation"},{"location":"2%20Documentation/5%20relation_tutorial/#reference","text":"MAML MAML-pytorch","title":"Reference"},{"location":"2%20Documentation/5%20relation_tutorial/#requirements","text":"Python 2.7 Pytorch 0.3","title":"Requirements"},{"location":"2%20Documentation/5%20relation_tutorial/#data","text":"For Omniglot experiments, I directly attach omniglot 28x28 resized images in the git, which is created based on omniglot and maml . For mini-Imagenet experiments, please download mini-Imagenet and put it in ./datas/mini-Imagenet and run proc_image.py to preprocess generate train/val/test datasets. (This process method is based on maml ).","title":"Data"},{"location":"2%20Documentation/5%20relation_tutorial/#train","text":"omniglot 5way 1 shot: python omniglot_train_one_shot.py -w 5 -s 1 -b 19 omniglot 5way 5 shot: python omniglot_train_few_shot.py -w 5 -s 5 -b 15 omniglot 20way 1 shot: python omniglot_train_one_shot.py -w 20 -s 1 -b 10 omniglot 20way 5 shot: python omniglot_train_few_shot.py -w 20 -s 5 -b 5 mini-Imagenet 5 way 1 shot: python miniimagenet_train_one_shot.py -w 5 -s 1 -b 15 mini-Imagenet 5 way 5 shot: python miniimagenet_train_few_shot.py -w 5 -s 5 -b 10 you can change -b parameter based on your GPU memory. Currently It will load my trained model, if you want to train from scratch, you can delete models by yourself.","title":"Train"},{"location":"2%20Documentation/5%20relation_tutorial/#test","text":"omniglot 5way 1 shot: python omniglot_test_one_shot.py -w 5 -s 1 Other experiments' testings are similar.","title":"Test"},{"location":"2%20Documentation/6%20anil_tutorial/","text":"ANIL Paper: ANIL Overview This repository contains code for training and evaluating MAML on the mini-ImageNet and tiered-ImageNet datasets most commonly used for few-shot image classification. To the best of our knowledge, this is the only PyTorch implementation of MAML to date that fully reproduces the results in the original paper without applying tricks such as data augmentation, evaluation on multiple crops, and ensemble of multiple models. Other existing PyTorch implementations typically see a ~3% gap in accuracy for the 5-way-1-shot and 5-way-5-shot classification tasks on mini-ImageNet. Beyond reproducing the results, our implementation comes with a few extra bits that we believe can be helpful for further development of the framework. We highlight the improvements we have built into our code, and discuss our observations that warrent some attention. Implementation Highlights Batch normalization with per-episode running statistics. Our implementation provides flexibility of tracking global and/or per-episode running statistics, hence supporting both transductive and inductive inference. Better data pre-processing. The official implementation does not normalize and augment data. We support data normalization and a variety of data augmentation techniques. We also implement data batching and support/query-set splitting more efficiently. More datasets. We support mini-ImageNet, tiered-ImageNet and more. More options for outer-loop optimization. We support mutiple optimizers and learning-rate schedulers for the outer-loop optimization. More powerful inner-loop optimization. The official implementation uses vanilla gradient descent in the inner loop. We support momentum and weight decay. More options for encoder architecture. We support the standard four-layer ConvNet as well as ResNet-12 and ResNet-18 as the encoder. Easy layer freezing. We provide an interface for layer freezing experiments. One may freeze an arbitrary set of layers or blocks during inner-loop adaptation. Meta-learning with zero-initialized classifier head. The official implementation learns a meta-initialization for both the encoder and the classifier head. This prevents one from varying the number of categories at training or test time. With our implementation, one may opt to learn a meta-initialization for the encoder while initializing the classifier head at zero. Distributed training and gradient checkpointing. MAML is very memory-intensive because it buffers all tensors generated throughout the inner-loop adaptation steps. Gradient checkpointing trades compute for memory, effectively bringing the memory cost from O(N) down to O(1), where N is the number of inner-loop steps. In our experiments, gradient checkpointing saved up to 80% of GPU memory at the cost of running the forward pass more than once (a moderate 20% increase in running time). Transductive or Inductive? The official implementation assumes transductive learning. The batch normalization layers do not track running statistics at training time, and they use mini-batch statistics at test time. The implicit assumption here is that test data come in mini-batches and are perhaps balanced across categories. This is a very restrictive assumption and does not land MAML directly comparable with the vast majority of meta-learning and few-shot learning methods. Unfortunately, this is not immediately obvious from the paper, and our findings suggest that the performance of MAML is hugely overestimated. Accuracy is very sensitive to the size of query set in the transductive setting. For example, the result for 5-way-1-shot classification on miniImageNet from the paper (48.70%) was obtained on five queries, one per category. We found that the accuracy dropped by ~1.5% given five queries per category, and by ~2.5% given 15 queries per category. The paper reports mean accuracy over 600 independently sampled tasks, or trials. We found that 600 trials, again in the transductive setting, are insufficient for an unbiased estimate of model performance . The mean accuracy from 6,000 trials is more stable, and is always ~2% lower than that from the first 600 trials. We conjecture that the distribution of per-trial accuracy is highly skewed towards the high end. We found that MAML performs a lot worse in the inductive setting . Given the same model configuration, inductive accuracy is always much lower (~4%) than the corrected transductive accuracy, which is already a few percentage points behind the reported number. Hence, one should be extremely cautious when comparing MAML with its competitors as is evident from the discussion above. FOMAML and layer freezing Unfortunately, some insights discussed in the original paper and its follow-up works do not appear to hold in the inductive setting. FOMAML (i.e. the first-order approximation of MAML) performs as well as MAML in transductive learning, but fails completely in the inductive setting. Completely freezing the encoder during inner-loop adaption as was done in this work results in dramatic decrease in accuracy. BatchNorm and TaskNorm A recent work proposes TaskNorm, a test-time enhancement of batch normalization, noting that the small batch sizes during training may leave batch normalization less effective. We did not have much success with this method. We observed marginal improvement most of the time, and found that it hurts performance occationally. That said, we do believe that batch normalization is hard to deal with in MAML. TaskNorm attempts to attack the problem of small batch sizes, which we conjecture is just one among the three main causes (i.e., extremely scarse training data, extremely small batch sizes, and extremely small number of inner-loop updates) of the ineffectiveness of batch normalization in MAML. Quick Start 0. Preliminaries Environment Python 3.6.8 (or any Python 3 distribution) PyTorch 1.3.1 (or any PyTorch > 1.0) tensorboardX Datasets Please follow the download links here . Please modify the file names accordingly so that they can be recognized by the data loaders. Configurations Template configuration files as well as those for reproducing the results in the original paper can be found in configs/ . The hyperparameters are self-explanatory. 1. Training MAML Here is the command for single-GPU training of MAML with ConvNet4 backbone for 5-way-1-shot classification on mini-ImageNet to reproduce the result in the original paper. python train.py --config=configs/convnet4/mini-imagenet/train_reproduce.yaml Use -gpu to specify available GPUs for multi-GPU training. For example, python train.py --config=configs/convnet4/mini-imagenet/train_reproduce.yaml --gpu=0,1 Add -efficient to enable gradient checkpointing. This aggressively saves GPU memory while slightly increases running time. python train.py --config=configs/convnet4/mini-imagenet/train_reproduce.yaml --efficient Use -tag to customize the name of the directory where the checkpoints and log files are saved. 2. Testing MAML Here is how one would test MAML for 5-way-1-shot classification on mini-ImageNet to reproduce the result in the original paper. Please confirm the loading path first. python test.py --config=configs/convnet4/mini-imagenet/test_reproduce.yaml The -gpu and -efficient tags function similarly as in training. Citation @misc{pytorch_maml, title={maml in pytorch - re-implementation and beyond}, author={Mu, Fangzhou}, howpublished={\\url{https://github.com/fmu2/PyTorch-MAML}}, year={2020} } Related Code Repositories Our implementation is inspired by the following repositories. maml (the official implementation) https://github.com/cbfinn/maml MAML-Pytorch https://github.com/dragen1860/MAML-Pytorch HowToTrainYourMAMLPytorch https://github.com/AntreasAntoniou/HowToTrainYourMAMLPytorch memory-efficient-maml https://github.com/dbaranchuk/memory-efficient-maml References @inproceedings{finn2017model, title={Model-agnostic meta-learning for fast adaptation of deep networks}, author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey}, booktitle={International Conference on Machine Learning (ICML)}, year={2017} } @inproceedings{raghu2019rapid, title={Rapid learning or feature reuse? towards understanding the effectiveness of maml}, author={Raghu, Aniruddh and Raghu, Maithra and Bengio, Samy and Vinyals, Oriol}, booktitle={International Conference on Learning Representations (ICLR)}, year={2019} } @article{Bronskill2020tasknorm, title={Tasknorm: rethinking batch normalization for meta-learning}, author={Bronskill, John and Gordon, Jonathan and Requeima, James and Nowozin, Sebastian and Turner, Richard E.}, journal={arXiv preprint arXiv:2003.03284}, year={2020} }","title":"ANIL"},{"location":"2%20Documentation/6%20anil_tutorial/#anil","text":"Paper: ANIL","title":"ANIL"},{"location":"2%20Documentation/6%20anil_tutorial/#overview","text":"This repository contains code for training and evaluating MAML on the mini-ImageNet and tiered-ImageNet datasets most commonly used for few-shot image classification. To the best of our knowledge, this is the only PyTorch implementation of MAML to date that fully reproduces the results in the original paper without applying tricks such as data augmentation, evaluation on multiple crops, and ensemble of multiple models. Other existing PyTorch implementations typically see a ~3% gap in accuracy for the 5-way-1-shot and 5-way-5-shot classification tasks on mini-ImageNet. Beyond reproducing the results, our implementation comes with a few extra bits that we believe can be helpful for further development of the framework. We highlight the improvements we have built into our code, and discuss our observations that warrent some attention.","title":"Overview"},{"location":"2%20Documentation/6%20anil_tutorial/#implementation-highlights","text":"Batch normalization with per-episode running statistics. Our implementation provides flexibility of tracking global and/or per-episode running statistics, hence supporting both transductive and inductive inference. Better data pre-processing. The official implementation does not normalize and augment data. We support data normalization and a variety of data augmentation techniques. We also implement data batching and support/query-set splitting more efficiently. More datasets. We support mini-ImageNet, tiered-ImageNet and more. More options for outer-loop optimization. We support mutiple optimizers and learning-rate schedulers for the outer-loop optimization. More powerful inner-loop optimization. The official implementation uses vanilla gradient descent in the inner loop. We support momentum and weight decay. More options for encoder architecture. We support the standard four-layer ConvNet as well as ResNet-12 and ResNet-18 as the encoder. Easy layer freezing. We provide an interface for layer freezing experiments. One may freeze an arbitrary set of layers or blocks during inner-loop adaptation. Meta-learning with zero-initialized classifier head. The official implementation learns a meta-initialization for both the encoder and the classifier head. This prevents one from varying the number of categories at training or test time. With our implementation, one may opt to learn a meta-initialization for the encoder while initializing the classifier head at zero. Distributed training and gradient checkpointing. MAML is very memory-intensive because it buffers all tensors generated throughout the inner-loop adaptation steps. Gradient checkpointing trades compute for memory, effectively bringing the memory cost from O(N) down to O(1), where N is the number of inner-loop steps. In our experiments, gradient checkpointing saved up to 80% of GPU memory at the cost of running the forward pass more than once (a moderate 20% increase in running time).","title":"Implementation Highlights"},{"location":"2%20Documentation/6%20anil_tutorial/#transductive-or-inductive","text":"The official implementation assumes transductive learning. The batch normalization layers do not track running statistics at training time, and they use mini-batch statistics at test time. The implicit assumption here is that test data come in mini-batches and are perhaps balanced across categories. This is a very restrictive assumption and does not land MAML directly comparable with the vast majority of meta-learning and few-shot learning methods. Unfortunately, this is not immediately obvious from the paper, and our findings suggest that the performance of MAML is hugely overestimated. Accuracy is very sensitive to the size of query set in the transductive setting. For example, the result for 5-way-1-shot classification on miniImageNet from the paper (48.70%) was obtained on five queries, one per category. We found that the accuracy dropped by ~1.5% given five queries per category, and by ~2.5% given 15 queries per category. The paper reports mean accuracy over 600 independently sampled tasks, or trials. We found that 600 trials, again in the transductive setting, are insufficient for an unbiased estimate of model performance . The mean accuracy from 6,000 trials is more stable, and is always ~2% lower than that from the first 600 trials. We conjecture that the distribution of per-trial accuracy is highly skewed towards the high end. We found that MAML performs a lot worse in the inductive setting . Given the same model configuration, inductive accuracy is always much lower (~4%) than the corrected transductive accuracy, which is already a few percentage points behind the reported number. Hence, one should be extremely cautious when comparing MAML with its competitors as is evident from the discussion above.","title":"Transductive or Inductive?"},{"location":"2%20Documentation/6%20anil_tutorial/#fomaml-and-layer-freezing","text":"Unfortunately, some insights discussed in the original paper and its follow-up works do not appear to hold in the inductive setting. FOMAML (i.e. the first-order approximation of MAML) performs as well as MAML in transductive learning, but fails completely in the inductive setting. Completely freezing the encoder during inner-loop adaption as was done in this work results in dramatic decrease in accuracy.","title":"FOMAML and layer freezing"},{"location":"2%20Documentation/6%20anil_tutorial/#batchnorm-and-tasknorm","text":"A recent work proposes TaskNorm, a test-time enhancement of batch normalization, noting that the small batch sizes during training may leave batch normalization less effective. We did not have much success with this method. We observed marginal improvement most of the time, and found that it hurts performance occationally. That said, we do believe that batch normalization is hard to deal with in MAML. TaskNorm attempts to attack the problem of small batch sizes, which we conjecture is just one among the three main causes (i.e., extremely scarse training data, extremely small batch sizes, and extremely small number of inner-loop updates) of the ineffectiveness of batch normalization in MAML.","title":"BatchNorm and TaskNorm"},{"location":"2%20Documentation/6%20anil_tutorial/#quick-start","text":"","title":"Quick Start"},{"location":"2%20Documentation/6%20anil_tutorial/#0-preliminaries","text":"Environment Python 3.6.8 (or any Python 3 distribution) PyTorch 1.3.1 (or any PyTorch > 1.0) tensorboardX Datasets Please follow the download links here . Please modify the file names accordingly so that they can be recognized by the data loaders. Configurations Template configuration files as well as those for reproducing the results in the original paper can be found in configs/ . The hyperparameters are self-explanatory.","title":"0. Preliminaries"},{"location":"2%20Documentation/6%20anil_tutorial/#1-training-maml","text":"Here is the command for single-GPU training of MAML with ConvNet4 backbone for 5-way-1-shot classification on mini-ImageNet to reproduce the result in the original paper. python train.py --config=configs/convnet4/mini-imagenet/train_reproduce.yaml Use -gpu to specify available GPUs for multi-GPU training. For example, python train.py --config=configs/convnet4/mini-imagenet/train_reproduce.yaml --gpu=0,1 Add -efficient to enable gradient checkpointing. This aggressively saves GPU memory while slightly increases running time. python train.py --config=configs/convnet4/mini-imagenet/train_reproduce.yaml --efficient Use -tag to customize the name of the directory where the checkpoints and log files are saved.","title":"1. Training MAML"},{"location":"2%20Documentation/6%20anil_tutorial/#2-testing-maml","text":"Here is how one would test MAML for 5-way-1-shot classification on mini-ImageNet to reproduce the result in the original paper. Please confirm the loading path first. python test.py --config=configs/convnet4/mini-imagenet/test_reproduce.yaml The -gpu and -efficient tags function similarly as in training.","title":"2. Testing MAML"},{"location":"2%20Documentation/6%20anil_tutorial/#citation","text":"@misc{pytorch_maml, title={maml in pytorch - re-implementation and beyond}, author={Mu, Fangzhou}, howpublished={\\url{https://github.com/fmu2/PyTorch-MAML}}, year={2020} }","title":"Citation"},{"location":"2%20Documentation/6%20anil_tutorial/#related-code-repositories","text":"Our implementation is inspired by the following repositories. maml (the official implementation) https://github.com/cbfinn/maml MAML-Pytorch https://github.com/dragen1860/MAML-Pytorch HowToTrainYourMAMLPytorch https://github.com/AntreasAntoniou/HowToTrainYourMAMLPytorch memory-efficient-maml https://github.com/dbaranchuk/memory-efficient-maml","title":"Related Code Repositories"},{"location":"2%20Documentation/6%20anil_tutorial/#references","text":"@inproceedings{finn2017model, title={Model-agnostic meta-learning for fast adaptation of deep networks}, author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey}, booktitle={International Conference on Machine Learning (ICML)}, year={2017} } @inproceedings{raghu2019rapid, title={Rapid learning or feature reuse? towards understanding the effectiveness of maml}, author={Raghu, Aniruddh and Raghu, Maithra and Bengio, Samy and Vinyals, Oriol}, booktitle={International Conference on Learning Representations (ICLR)}, year={2019} } @article{Bronskill2020tasknorm, title={Tasknorm: rethinking batch normalization for meta-learning}, author={Bronskill, John and Gordon, Jonathan and Requeima, James and Nowozin, Sebastian and Turner, Richard E.}, journal={arXiv preprint arXiv:2003.03284}, year={2020} }","title":"References"},{"location":"2%20Documentation/7%20metaSGD_tutorial/","text":"Meta-SGD Paper: Meta-SGD: Learning to Learn Quickly for Few Shot Learning(Zhenguo Li et al.) ) Overview[Abstract] An important research direction in machine learning has centered around developing meta-learning algorithms to tackle few-shot learning. An especially successful algorithm has been Model Agnostic Meta-Learning (MAML), a method that consists of two optimization loops, with the outer loop finding a meta-initialization, from which the inner loop can efficiently learn new tasks. Despite MAML's popularity, a fundamental open question remains -- is the effectiveness of MAML due to the meta-initialization being primed for rapid learning (large, efficient changes in the representations) or due to feature reuse, with the meta initialization already containing high quality features? We investigate this question, via ablation studies and analysis of the latent representations, finding that feature reuse is the dominant factor. This leads to the ANIL (Almost No Inner Loop) algorithm, a simplification of MAML where we remove the inner loop for all but the (task-specific) head of a MAML-trained network. ANIL matches MAML's performance on benchmark few-shot image classification and RL and offers computational improvements over MAML. We further study the precise contributions of the head and body of the network, showing that performance on the test tasks is entirely determined by the quality of the learned features, and we can remove even the head of the network (the NIL algorithm). We conclude with a discussion of the rapid learning vs feature reuse question for meta-learning algorithms more broadly. Results all the x label in the figure is iteration step. considering the time cost other than the iteration step: we can see that the convergence speed and performance of metaSGD is better than MAML the result in both iteration and time scale is the same other than MAML, performance of meta-SGD won't get worst in long-term training. Usage python main.py --datasource=omniglot --metatrain_iterations=40000 --meta_batch_size=32 --update_batch_size=1 --update_lr=0.4 --num_updates=1 --logdir=logs/omniglot5way/ python main.py --datasource=omniglot --metatrain_iterations=40000 --meta_batch_size=32 --update_batch_size=1 --update_lr=0.4 --num_updates=1 --logdir=logs/omniglot5way/ --train=False --test_set=True","title":"Meta-SGD"},{"location":"2%20Documentation/7%20metaSGD_tutorial/#meta-sgd","text":"Paper: Meta-SGD: Learning to Learn Quickly for Few Shot Learning(Zhenguo Li et al.) )","title":"Meta-SGD"},{"location":"2%20Documentation/7%20metaSGD_tutorial/#overviewabstract","text":"An important research direction in machine learning has centered around developing meta-learning algorithms to tackle few-shot learning. An especially successful algorithm has been Model Agnostic Meta-Learning (MAML), a method that consists of two optimization loops, with the outer loop finding a meta-initialization, from which the inner loop can efficiently learn new tasks. Despite MAML's popularity, a fundamental open question remains -- is the effectiveness of MAML due to the meta-initialization being primed for rapid learning (large, efficient changes in the representations) or due to feature reuse, with the meta initialization already containing high quality features? We investigate this question, via ablation studies and analysis of the latent representations, finding that feature reuse is the dominant factor. This leads to the ANIL (Almost No Inner Loop) algorithm, a simplification of MAML where we remove the inner loop for all but the (task-specific) head of a MAML-trained network. ANIL matches MAML's performance on benchmark few-shot image classification and RL and offers computational improvements over MAML. We further study the precise contributions of the head and body of the network, showing that performance on the test tasks is entirely determined by the quality of the learned features, and we can remove even the head of the network (the NIL algorithm). We conclude with a discussion of the rapid learning vs feature reuse question for meta-learning algorithms more broadly.","title":"Overview[Abstract]"},{"location":"2%20Documentation/7%20metaSGD_tutorial/#results","text":"all the x label in the figure is iteration step. considering the time cost other than the iteration step: we can see that the convergence speed and performance of metaSGD is better than MAML the result in both iteration and time scale is the same other than MAML, performance of meta-SGD won't get worst in long-term training.","title":"Results"},{"location":"2%20Documentation/7%20metaSGD_tutorial/#usage","text":"python main.py --datasource=omniglot --metatrain_iterations=40000 --meta_batch_size=32 --update_batch_size=1 --update_lr=0.4 --num_updates=1 --logdir=logs/omniglot5way/ python main.py --datasource=omniglot --metatrain_iterations=40000 --meta_batch_size=32 --update_batch_size=1 --update_lr=0.4 --num_updates=1 --logdir=logs/omniglot5way/ --train=False --test_set=True","title":"Usage"},{"location":"2%20Documentation/7%20metaSGD_tutorial/#_1","text":"","title":""},{"location":"2%20Documentation/8%20%20MetaDropout_tutorial/","text":"Meta Dropout Paper: Learning to Perturb Latent Features for Generalization . You can reproduce the results of Table 1 in the main paper. Abstract A machine learning model that generalizes well should obtain low errors on unseen test examples. Thus, if we know how to optimally perturb training examples to account for test examples, we may achieve better generalization performance. However, obtaining such perturbation is not possible in standard machine learning frameworks as the distribution of the test data is unknown. To tackle this challenge, we propose a novel regularization method, meta-dropout, which learns to perturb the latent features of training examples for generalization in a meta-learning framework. Specifically, we meta-learn a noise generator which outputs a multiplicative noise distribution for latent features, to obtain low errors on the test instances in an input-dependent manner. Then, the learned noise generator can perturb the training examples of unseen tasks at the meta-test time for improved generalization. We validate our method on few-shot classification datasets, whose results show that it significantly improves the generalization performance of the base model, and largely outperforms existing regularization methods such as information bottleneck, manifold mixup, and information dropout. Results The results in the main paper (average over 1000 episodes, with a single run): Omni. 1shot Omni. 5shot mImg. 1shot mImg. 5shot MAML 95.23\u00b10.17 98.38\u00b10.07 49.58\u00b10.65 64.55\u00b10.52 Meta-dropout 96.63\u00b10.13 98.73\u00b10.06 51.93\u00b10.67 67.42\u00b10.52 The results from running this repo (average over 1000 episodes, with a single run): Omni. 1shot Omni. 5shot mImg. 1shot mImg. 5shot MAML 94.49\u00b10.16 98.14\u00b10.07 48.73\u00b10.64 65.70\u00b10.52 Meta-dropout 96.24\u00b10.14 98.81\u00b10.06 51.67\u00b10.64 68.12\u00b10.53 Omniglot miniImageNet Adversarial Robustness Lastly, in the main paper, we also performed experiments on adversarial robustness. Our meta-dropout seems to improve both clean and adversarial robustness. Further, meta-dropout seems to improve robustness over various types of attacks at the same time, such as L1, L2, and Linf. Citation If you found the provided code useful, please cite our work. @inproceedings{ lee2020metadrop, title={Meta Dropout: Learning to Perturb Latent Features for Generalization}, author={Hae Beom Lee and Taewook Nam and Eunho Yang and Sung Ju Hwangg}, booktitle={ICLR}, year={2020} } Prerequisites Python 3.5 (Anaconda) Tensorflow 1.12.0 CUDA 9.0 cudnn 7.6.5 If you are not familiar with preparing conda environment, please follow the below instructions: $ conda create --name py35 python=3.5 $ conda activate py35 $ pip install --upgrade pip $ pip install tensorflow-gpu==1.12.0 $ conda install -c anaconda cudatoolkit=9.0 $ conda install -c anaconda cudnn And for data downloading, $ pip install tqdm $ pip install requests Data Preparation $ python get_data.py --dataset omniglot $ python get_data.py --dataset mimgnet It will take some time to download each of the datasets. Usage Run one of the followings. Also, take a look at the folder ./runfiles for how to run MAML models as well. Omniglot 1-shot experiment # Meta-training / Meta-testing $ python main.py --gpu_id 0 --savedir './results/metadrop/omni_1shot' --dataset 'omniglot' --mode 'meta_train' --metabatch 4 --n_steps 5 --inner_lr 0.1 --way 20 --shot 1 --query 15 --n_train_iters 60000 --meta_lr 3e-4 --n_test_mc_samp 1 $ python main.py --gpu_id 0 --savedir './results/metadrop/omni_1shot' --dataset 'omniglot' --mode 'meta_test' --metabatch 1 --n_steps 5 --inner_lr 0.1 --way 20 --shot 1 --query 15 --n_train_iters 60000 --meta_lr 3e-4 --n_test_mc_samp 30 Omniglot 5-shot experiment # Meta-training / Meta-testing $ python main.py --gpu_id 0 --savedir './results/metadrop/omni_5shot' --dataset 'omniglot' --mode 'meta_train' --metabatch 4 --n_steps 5 --inner_lr 0.4 --way 20 --shot 5 --query 15 --n_train_iters 60000 --meta_lr 1e-3 --n_test_mc_samp 1 $ python main.py --gpu_id 0 --savedir './results/metadrop/omni_5shot' --dataset 'omniglot' --mode 'meta_test' --metabatch 1 --n_steps 5 --inner_lr 0.4 --way 20 --shot 5 --query 15 --n_train_iters 60000 --meta_lr 1e-3 --n_test_mc_samp 30 miniImageNet 1-shot experiment # Meta-training / Meta-testing $ python main.py --gpu_id 0 --savedir './results/metadrop/mimgnet_1shot' --dataset 'mimgnet' --mode 'meta_train' --metabatch 4 --inner_lr 0.01 --n_steps 5 --way 5 --shot 1 --query 15 --n_train_iters 60000 --meta_lr 1e-4 --n_test_mc_samp 1 $ python main.py --gpu_id 0 --savedir './results/metadrop/mimgnet_1shot' --dataset 'mimgnet' --mode 'meta_test' --metabatch 1 --inner_lr 0.01 --n_steps 5 --way 5 --shot 1 --query 15 --n_train_iters 60000 --meta_lr 1e-4 --n_test_mc_samp 30 miniImageNet 5-shot experiment # Meta-training / Meta-testing $ python main.py --gpu_id 0 --savedir './results/metadrop/mimgnet_5shot' --dataset 'mimgnet' --mode 'meta_train' --metabatch 4 --inner_lr 0.01 --n_steps 5 --way 5 --shot 5 --query 15 --n_train_iters 60000 --meta_lr 1e-4 --n_test_mc_samp 1 $ python main.py --gpu_id 0 --savedir './results/metadrop/mimgnet_5shot' --dataset 'mimgnet' --mode 'meta_test' --metabatch 1 --inner_lr 0.01 --n_steps 5 --way 5 --shot 5 --query 15 --n_train_iters 60000 --meta_lr 1e-4 --n_test_mc_samp 30 Decision Boundary Visualization Visualization needs the following additional package. $ pip install matplotlib sklearn First, export necessary statistics by changing --mode into export . For example, $ python main.py --gpu_id 0 --savedir './results/metadrop/omni_1shot' --dataset 'omniglot' --mode 'export' --metabatch 1 --n_steps 5 --inner_lr 0.1 --way 20 --shot 1 --query 15 --n_train_iters 60000 --meta_lr 1e-3 --n_test_mc_samp 30 Then, run plot.py with --savedir argument. For example, $ python plot.py --savedir './results/metadrop/omni_1shot' This will generate decision boundary plots under plot directory in the savedir .","title":"Meta Dropout"},{"location":"2%20Documentation/8%20%20MetaDropout_tutorial/#meta-dropout","text":"Paper: Learning to Perturb Latent Features for Generalization . You can reproduce the results of Table 1 in the main paper.","title":"Meta Dropout"},{"location":"2%20Documentation/8%20%20MetaDropout_tutorial/#abstract","text":"A machine learning model that generalizes well should obtain low errors on unseen test examples. Thus, if we know how to optimally perturb training examples to account for test examples, we may achieve better generalization performance. However, obtaining such perturbation is not possible in standard machine learning frameworks as the distribution of the test data is unknown. To tackle this challenge, we propose a novel regularization method, meta-dropout, which learns to perturb the latent features of training examples for generalization in a meta-learning framework. Specifically, we meta-learn a noise generator which outputs a multiplicative noise distribution for latent features, to obtain low errors on the test instances in an input-dependent manner. Then, the learned noise generator can perturb the training examples of unseen tasks at the meta-test time for improved generalization. We validate our method on few-shot classification datasets, whose results show that it significantly improves the generalization performance of the base model, and largely outperforms existing regularization methods such as information bottleneck, manifold mixup, and information dropout.","title":"Abstract"},{"location":"2%20Documentation/8%20%20MetaDropout_tutorial/#results","text":"The results in the main paper (average over 1000 episodes, with a single run): Omni. 1shot Omni. 5shot mImg. 1shot mImg. 5shot MAML 95.23\u00b10.17 98.38\u00b10.07 49.58\u00b10.65 64.55\u00b10.52 Meta-dropout 96.63\u00b10.13 98.73\u00b10.06 51.93\u00b10.67 67.42\u00b10.52 The results from running this repo (average over 1000 episodes, with a single run): Omni. 1shot Omni. 5shot mImg. 1shot mImg. 5shot MAML 94.49\u00b10.16 98.14\u00b10.07 48.73\u00b10.64 65.70\u00b10.52 Meta-dropout 96.24\u00b10.14 98.81\u00b10.06 51.67\u00b10.64 68.12\u00b10.53","title":"Results"},{"location":"2%20Documentation/8%20%20MetaDropout_tutorial/#omniglot","text":"","title":"Omniglot"},{"location":"2%20Documentation/8%20%20MetaDropout_tutorial/#miniimagenet","text":"","title":"miniImageNet"},{"location":"2%20Documentation/8%20%20MetaDropout_tutorial/#adversarial-robustness","text":"Lastly, in the main paper, we also performed experiments on adversarial robustness. Our meta-dropout seems to improve both clean and adversarial robustness. Further, meta-dropout seems to improve robustness over various types of attacks at the same time, such as L1, L2, and Linf.","title":"Adversarial Robustness"},{"location":"2%20Documentation/8%20%20MetaDropout_tutorial/#citation","text":"If you found the provided code useful, please cite our work. @inproceedings{ lee2020metadrop, title={Meta Dropout: Learning to Perturb Latent Features for Generalization}, author={Hae Beom Lee and Taewook Nam and Eunho Yang and Sung Ju Hwangg}, booktitle={ICLR}, year={2020} }","title":"Citation"},{"location":"2%20Documentation/8%20%20MetaDropout_tutorial/#prerequisites","text":"Python 3.5 (Anaconda) Tensorflow 1.12.0 CUDA 9.0 cudnn 7.6.5 If you are not familiar with preparing conda environment, please follow the below instructions: $ conda create --name py35 python=3.5 $ conda activate py35 $ pip install --upgrade pip $ pip install tensorflow-gpu==1.12.0 $ conda install -c anaconda cudatoolkit=9.0 $ conda install -c anaconda cudnn And for data downloading, $ pip install tqdm $ pip install requests","title":"Prerequisites"},{"location":"2%20Documentation/8%20%20MetaDropout_tutorial/#data-preparation","text":"$ python get_data.py --dataset omniglot $ python get_data.py --dataset mimgnet It will take some time to download each of the datasets.","title":"Data Preparation"},{"location":"2%20Documentation/8%20%20MetaDropout_tutorial/#usage","text":"Run one of the followings. Also, take a look at the folder ./runfiles for how to run MAML models as well. Omniglot 1-shot experiment # Meta-training / Meta-testing $ python main.py --gpu_id 0 --savedir './results/metadrop/omni_1shot' --dataset 'omniglot' --mode 'meta_train' --metabatch 4 --n_steps 5 --inner_lr 0.1 --way 20 --shot 1 --query 15 --n_train_iters 60000 --meta_lr 3e-4 --n_test_mc_samp 1 $ python main.py --gpu_id 0 --savedir './results/metadrop/omni_1shot' --dataset 'omniglot' --mode 'meta_test' --metabatch 1 --n_steps 5 --inner_lr 0.1 --way 20 --shot 1 --query 15 --n_train_iters 60000 --meta_lr 3e-4 --n_test_mc_samp 30 Omniglot 5-shot experiment # Meta-training / Meta-testing $ python main.py --gpu_id 0 --savedir './results/metadrop/omni_5shot' --dataset 'omniglot' --mode 'meta_train' --metabatch 4 --n_steps 5 --inner_lr 0.4 --way 20 --shot 5 --query 15 --n_train_iters 60000 --meta_lr 1e-3 --n_test_mc_samp 1 $ python main.py --gpu_id 0 --savedir './results/metadrop/omni_5shot' --dataset 'omniglot' --mode 'meta_test' --metabatch 1 --n_steps 5 --inner_lr 0.4 --way 20 --shot 5 --query 15 --n_train_iters 60000 --meta_lr 1e-3 --n_test_mc_samp 30 miniImageNet 1-shot experiment # Meta-training / Meta-testing $ python main.py --gpu_id 0 --savedir './results/metadrop/mimgnet_1shot' --dataset 'mimgnet' --mode 'meta_train' --metabatch 4 --inner_lr 0.01 --n_steps 5 --way 5 --shot 1 --query 15 --n_train_iters 60000 --meta_lr 1e-4 --n_test_mc_samp 1 $ python main.py --gpu_id 0 --savedir './results/metadrop/mimgnet_1shot' --dataset 'mimgnet' --mode 'meta_test' --metabatch 1 --inner_lr 0.01 --n_steps 5 --way 5 --shot 1 --query 15 --n_train_iters 60000 --meta_lr 1e-4 --n_test_mc_samp 30 miniImageNet 5-shot experiment # Meta-training / Meta-testing $ python main.py --gpu_id 0 --savedir './results/metadrop/mimgnet_5shot' --dataset 'mimgnet' --mode 'meta_train' --metabatch 4 --inner_lr 0.01 --n_steps 5 --way 5 --shot 5 --query 15 --n_train_iters 60000 --meta_lr 1e-4 --n_test_mc_samp 1 $ python main.py --gpu_id 0 --savedir './results/metadrop/mimgnet_5shot' --dataset 'mimgnet' --mode 'meta_test' --metabatch 1 --inner_lr 0.01 --n_steps 5 --way 5 --shot 5 --query 15 --n_train_iters 60000 --meta_lr 1e-4 --n_test_mc_samp 30","title":"Usage"},{"location":"2%20Documentation/8%20%20MetaDropout_tutorial/#decision-boundary-visualization","text":"Visualization needs the following additional package. $ pip install matplotlib sklearn First, export necessary statistics by changing --mode into export . For example, $ python main.py --gpu_id 0 --savedir './results/metadrop/omni_1shot' --dataset 'omniglot' --mode 'export' --metabatch 1 --n_steps 5 --inner_lr 0.1 --way 20 --shot 1 --query 15 --n_train_iters 60000 --meta_lr 1e-3 --n_test_mc_samp 30 Then, run plot.py with --savedir argument. For example, $ python plot.py --savedir './results/metadrop/omni_1shot' This will generate decision boundary plots under plot directory in the savedir .","title":"Decision Boundary Visualization"},{"location":"2%20Documentation/9%20MT-net_tutorial/","text":"MT-net Paper Gradient-Based Meta-Learning with Learned Layerwise Metric and Subspace (Yoonho Lee and Seungjin Choi, ICML 2018) . It includes code for running the experiments in the paper (few-shot sine wave regression, Omniglot and miniImagenet few-shot classification). Abstract Gradient-based meta-learning methods leverage gradient descent to learn the commonalities among various tasks. While previous such methods have been successful in meta-learning tasks, they resort to simple gradient descent during meta-testing. Our primary contribution is the MT-net , which enables the meta-learner to learn on each layer's activation space a subspace that the task-specific learner performs gradient descent on. Additionally, a task-specific learner of an {\\em MT-net} performs gradient descent with respect to a meta-learned distance metric, which warps the activation space to be more sensitive to task identity. We demonstrate that the dimension of this learned subspace reflects the complexity of the task-specific learner's adaptation task, and also that our model is less sensitive to the choice of initial learning rates than previous gradient-based meta-learning methods. Our method achieves state-of-the-art or comparable performance on few-shot classification and regression tasks. Results omniglot Citation If you found the provided code useful, please cite our work. @inproceedings{lee2018gradient, title={Gradient-based meta-learning with learned layerwise metric and subspace}, author={Lee, Yoonho and Choi, Seungjin}, booktitle={International Conference on Machine Learning}, pages={2933--2942}, year={2018} } This codebase is based on the repository for MAML . Data For the Omniglot and MiniImagenet data, see the usage instructions in data/omniglot_resized/resize_images.py and data/miniImagenet/proc_images.py respectively. Usage To run the code, see the usage instructions at the top of main.py . For MT-nets, set use_T , use_M , share_M to True . For T-nets, set use_T to True and use_M to False .","title":"MT-net"},{"location":"2%20Documentation/9%20MT-net_tutorial/#mt-net","text":"Paper Gradient-Based Meta-Learning with Learned Layerwise Metric and Subspace (Yoonho Lee and Seungjin Choi, ICML 2018) . It includes code for running the experiments in the paper (few-shot sine wave regression, Omniglot and miniImagenet few-shot classification).","title":"MT-net"},{"location":"2%20Documentation/9%20MT-net_tutorial/#abstract","text":"Gradient-based meta-learning methods leverage gradient descent to learn the commonalities among various tasks. While previous such methods have been successful in meta-learning tasks, they resort to simple gradient descent during meta-testing. Our primary contribution is the MT-net , which enables the meta-learner to learn on each layer's activation space a subspace that the task-specific learner performs gradient descent on. Additionally, a task-specific learner of an {\\em MT-net} performs gradient descent with respect to a meta-learned distance metric, which warps the activation space to be more sensitive to task identity. We demonstrate that the dimension of this learned subspace reflects the complexity of the task-specific learner's adaptation task, and also that our model is less sensitive to the choice of initial learning rates than previous gradient-based meta-learning methods. Our method achieves state-of-the-art or comparable performance on few-shot classification and regression tasks.","title":"Abstract"},{"location":"2%20Documentation/9%20MT-net_tutorial/#results","text":"omniglot","title":"Results"},{"location":"2%20Documentation/9%20MT-net_tutorial/#citation","text":"If you found the provided code useful, please cite our work. @inproceedings{lee2018gradient, title={Gradient-based meta-learning with learned layerwise metric and subspace}, author={Lee, Yoonho and Choi, Seungjin}, booktitle={International Conference on Machine Learning}, pages={2933--2942}, year={2018} } This codebase is based on the repository for MAML .","title":"Citation"},{"location":"2%20Documentation/9%20MT-net_tutorial/#data","text":"For the Omniglot and MiniImagenet data, see the usage instructions in data/omniglot_resized/resize_images.py and data/miniImagenet/proc_images.py respectively.","title":"Data"},{"location":"2%20Documentation/9%20MT-net_tutorial/#usage","text":"To run the code, see the usage instructions at the top of main.py . For MT-nets, set use_T , use_M , share_M to True . For T-nets, set use_T to True and use_M to False .","title":"Usage"},{"location":"3%20Examples/1%20vision/","text":"Computer Vision This directory contains meta-learning examples and reproductions for common computer vision benchmarks. Results (Our Awesome-META+) MAML MetaOptNet Reptile Prototypical network Relation Network ANIL Example (Usage) MAML The following files reproduce MAML on the Omniglot and mini -ImageNet datasets. The FOMAML results can be obtained by setting first_order=True in the MAML wrapper. On Omniglot, the CNN results can be obtained by swapping OmniglotFC with OmniglotCNN . maml_omniglot.py - MAML on the Omniglot dataset with a fully-connected network. maml_miniimagenet.py - MAML on the mini -ImageNet dataset with the standard convolutional network. maml_cifar.py - MAML on the Cifar-FS dataset with the standard convolutional network. Note that the original MAML paper trains with 5 fast adaptation step, but tests with 10 steps. This implementation only provides the training code. Usage Manually edit the respective files and run: python examples/maml_omniglot.py or python examples/maml_miniimagenet.py or python examples/maml_cifar.py Prototypical Networks The file protonet_miniimagenet.py reproduces Prototypical Networks on the mini -ImageNet dataset. This implementation provides training and testing code. Usage For 1 shot 5 ways: python examples/protonet_miniimagenet.py For 5 shot 5 ways: python examples/protonet_miniimagenet.py --shot 5 --train-way 5 For 1 shot 20 ways: python examples/protonet_miniimagenet.py --shot 1 --train-way 20 For 5 shot 20 ways: python examples/vision/protonet_miniimagenet.py --shot 5 --train-way 20 Reptile Usage Manually edit the above file and run: python examples/vision/reptile_miniimagenet.py ANIL The file anil_fc100.py and anil_cifar.py implements ANIL on the FC100 and Cifar-FS dataset. Usage Manually edit the above file and run: python examples/vision/anil_fc100.py or python examples/vision/anil_cifar.py General situation The pretrained weights can be downloaded using ./models/ . For example LinearBlock class LinearBlock(torch.nn.Module): def __init__(self, input_size, output_size): super(LinearBlock, self).__init__() self.relu = torch.nn.ReLU() self.normalize = torch.nn.BatchNorm1d( output_size, affine=True, momentum=0.999, eps=1e-3, track_running_stats=False, ) self.linear = torch.nn.Linear(input_size, output_size) fc_init_(self.linear) def forward(self, x): x = self.linear(x) x = self.normalize(x) x = self.relu(x) return x class ConvBlock(torch.nn.Module): def __init__(self, in_channels, out_channels, kernel_size, max_pool=True, max_pool_factor=1.0): super(ConvBlock, self).__init__() stride = (int(2 * max_pool_factor), int(2 * max_pool_factor)) if max_pool: self.max_pool = torch.nn.MaxPool2d( kernel_size=stride, stride=stride, ceil_mode=False, ) stride = (1, 1) else: self.max_pool = lambda x: x self.normalize = torch.nn.BatchNorm2d( out_channels, affine=True, # eps=1e-3, # momentum=0.999, # track_running_stats=False, ) torch.nn.init.uniform_(self.normalize.weight) self.relu = torch.nn.ReLU() self.conv = torch.nn.Conv2d( in_channels, out_channels, kernel_size, stride=stride, padding=1, bias=True, ) maml_init_(self.conv) def forward(self, x): x = self.conv(x) x = self.normalize(x) x = self.relu(x) x = self.max_pool(x) return x CNN4 class CNN4(torch.nn.Module): def __init__( self, output_size, hidden_size=64, layers=4, channels=3, max_pool=True, embedding_size=None, ): super(CNN4, self).__init__() if embedding_size is None: embedding_size = 25 * hidden_size self.features = CNN4Backbone( hidden_size=hidden_size, channels=channels, max_pool=max_pool, layers=layers, max_pool_factor=4 // layers, ) self.classifier = torch.nn.Linear( embedding_size, output_size, bias=True, ) maml_init_(self.classifier) self.hidden_size = hidden_size def forward(self, x): x = self.features(x) x = self.classifier(x) return x ResNet12 class ResNet12(torch.nn.Module): def __init__( self, avg_pool=True, # Set to False for 16000-dim embeddings wider=True, # True mimics MetaOptNet, False mimics TADAM embedding_dropout=0.0, # dropout for embedding dropblock_dropout=0.1, # dropout for residual layers dropblock_size=5, channels=3, ): super(ResNet12Backbone, self).__init__() self.inplanes = channels block = BasicBlock if wider: num_filters = [64, 160, 320, 640] else: num_filters = [64, 128, 256, 512] self.layer1 = self._make_layer( block, num_filters[0], stride=2, dropblock_dropout=dropblock_dropout, ) self.layer2 = self._make_layer( block, num_filters[1], stride=2, dropblock_dropout=dropblock_dropout, ) self.layer3 = self._make_layer( block, num_filters[2], stride=2, dropblock_dropout=dropblock_dropout, drop_block=True, block_size=dropblock_size, ) self.layer4 = self._make_layer( block, num_filters[3], stride=2, dropblock_dropout=dropblock_dropout, drop_block=True, block_size=dropblock_size, ) self.avgpool = nn.AvgPool2d(5, stride=1) self.embedding_dropout = embedding_dropout self.keep_avg_pool = avg_pool self.dropout = nn.Dropout(p=self.embedding_dropout, inplace=False) self.dropblock_dropout = dropblock_dropout for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.kaiming_normal_( m.weight, mode='fan_out', nonlinearity='leaky_relu', ) elif isinstance(m, nn.BatchNorm2d): nn.init.constant_(m.weight, 1) nn.init.constant_(m.bias, 0) def _make_layer( self, block, planes, stride=1, dropblock_dropout=0.0, drop_block=False, block_size=1, ): downsample = None if stride != 1 or self.inplanes != planes * block.expansion: downsample = nn.Sequential( nn.Conv2d(self.inplanes, planes * block.expansion, kernel_size=1, stride=1, bias=False), nn.BatchNorm2d(planes * block.expansion), ) layers = [] layers.append(block( self.inplanes, planes, stride, downsample, dropblock_dropout, drop_block, block_size) ) self.inplanes = planes * block.expansion return nn.Sequential(*layers) def forward(self, x): x = self.layer1(x) x = self.layer2(x) x = self.layer3(x) x = self.layer4(x) x = self.avgpool(x) x = self.flatten(x) x = self.dropout(x) return x for more details, please see: https://github.com/WangJingyao07/MetaLearning-Lab","title":"Computer Vision"},{"location":"3%20Examples/1%20vision/#computer-vision","text":"This directory contains meta-learning examples and reproductions for common computer vision benchmarks.","title":"Computer Vision"},{"location":"3%20Examples/1%20vision/#results-our-awesome-meta","text":"MAML MetaOptNet Reptile Prototypical network Relation Network ANIL","title":"Results (Our Awesome-META+)"},{"location":"3%20Examples/1%20vision/#example-usage","text":"","title":"Example (Usage)"},{"location":"3%20Examples/1%20vision/#maml","text":"The following files reproduce MAML on the Omniglot and mini -ImageNet datasets. The FOMAML results can be obtained by setting first_order=True in the MAML wrapper. On Omniglot, the CNN results can be obtained by swapping OmniglotFC with OmniglotCNN . maml_omniglot.py - MAML on the Omniglot dataset with a fully-connected network. maml_miniimagenet.py - MAML on the mini -ImageNet dataset with the standard convolutional network. maml_cifar.py - MAML on the Cifar-FS dataset with the standard convolutional network. Note that the original MAML paper trains with 5 fast adaptation step, but tests with 10 steps. This implementation only provides the training code. Usage Manually edit the respective files and run: python examples/maml_omniglot.py or python examples/maml_miniimagenet.py or python examples/maml_cifar.py","title":"MAML"},{"location":"3%20Examples/1%20vision/#prototypical-networks","text":"The file protonet_miniimagenet.py reproduces Prototypical Networks on the mini -ImageNet dataset. This implementation provides training and testing code. Usage For 1 shot 5 ways: python examples/protonet_miniimagenet.py For 5 shot 5 ways: python examples/protonet_miniimagenet.py --shot 5 --train-way 5 For 1 shot 20 ways: python examples/protonet_miniimagenet.py --shot 1 --train-way 20 For 5 shot 20 ways: python examples/vision/protonet_miniimagenet.py --shot 5 --train-way 20","title":"Prototypical Networks"},{"location":"3%20Examples/1%20vision/#reptile","text":"Usage Manually edit the above file and run: python examples/vision/reptile_miniimagenet.py","title":"Reptile"},{"location":"3%20Examples/1%20vision/#anil","text":"The file anil_fc100.py and anil_cifar.py implements ANIL on the FC100 and Cifar-FS dataset. Usage Manually edit the above file and run: python examples/vision/anil_fc100.py or python examples/vision/anil_cifar.py","title":"ANIL"},{"location":"3%20Examples/1%20vision/#general-situation","text":"The pretrained weights can be downloaded using ./models/ .","title":"General situation"},{"location":"3%20Examples/1%20vision/#for-example","text":"LinearBlock class LinearBlock(torch.nn.Module): def __init__(self, input_size, output_size): super(LinearBlock, self).__init__() self.relu = torch.nn.ReLU() self.normalize = torch.nn.BatchNorm1d( output_size, affine=True, momentum=0.999, eps=1e-3, track_running_stats=False, ) self.linear = torch.nn.Linear(input_size, output_size) fc_init_(self.linear) def forward(self, x): x = self.linear(x) x = self.normalize(x) x = self.relu(x) return x class ConvBlock(torch.nn.Module): def __init__(self, in_channels, out_channels, kernel_size, max_pool=True, max_pool_factor=1.0): super(ConvBlock, self).__init__() stride = (int(2 * max_pool_factor), int(2 * max_pool_factor)) if max_pool: self.max_pool = torch.nn.MaxPool2d( kernel_size=stride, stride=stride, ceil_mode=False, ) stride = (1, 1) else: self.max_pool = lambda x: x self.normalize = torch.nn.BatchNorm2d( out_channels, affine=True, # eps=1e-3, # momentum=0.999, # track_running_stats=False, ) torch.nn.init.uniform_(self.normalize.weight) self.relu = torch.nn.ReLU() self.conv = torch.nn.Conv2d( in_channels, out_channels, kernel_size, stride=stride, padding=1, bias=True, ) maml_init_(self.conv) def forward(self, x): x = self.conv(x) x = self.normalize(x) x = self.relu(x) x = self.max_pool(x) return x CNN4 class CNN4(torch.nn.Module): def __init__( self, output_size, hidden_size=64, layers=4, channels=3, max_pool=True, embedding_size=None, ): super(CNN4, self).__init__() if embedding_size is None: embedding_size = 25 * hidden_size self.features = CNN4Backbone( hidden_size=hidden_size, channels=channels, max_pool=max_pool, layers=layers, max_pool_factor=4 // layers, ) self.classifier = torch.nn.Linear( embedding_size, output_size, bias=True, ) maml_init_(self.classifier) self.hidden_size = hidden_size def forward(self, x): x = self.features(x) x = self.classifier(x) return x ResNet12 class ResNet12(torch.nn.Module): def __init__( self, avg_pool=True, # Set to False for 16000-dim embeddings wider=True, # True mimics MetaOptNet, False mimics TADAM embedding_dropout=0.0, # dropout for embedding dropblock_dropout=0.1, # dropout for residual layers dropblock_size=5, channels=3, ): super(ResNet12Backbone, self).__init__() self.inplanes = channels block = BasicBlock if wider: num_filters = [64, 160, 320, 640] else: num_filters = [64, 128, 256, 512] self.layer1 = self._make_layer( block, num_filters[0], stride=2, dropblock_dropout=dropblock_dropout, ) self.layer2 = self._make_layer( block, num_filters[1], stride=2, dropblock_dropout=dropblock_dropout, ) self.layer3 = self._make_layer( block, num_filters[2], stride=2, dropblock_dropout=dropblock_dropout, drop_block=True, block_size=dropblock_size, ) self.layer4 = self._make_layer( block, num_filters[3], stride=2, dropblock_dropout=dropblock_dropout, drop_block=True, block_size=dropblock_size, ) self.avgpool = nn.AvgPool2d(5, stride=1) self.embedding_dropout = embedding_dropout self.keep_avg_pool = avg_pool self.dropout = nn.Dropout(p=self.embedding_dropout, inplace=False) self.dropblock_dropout = dropblock_dropout for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.kaiming_normal_( m.weight, mode='fan_out', nonlinearity='leaky_relu', ) elif isinstance(m, nn.BatchNorm2d): nn.init.constant_(m.weight, 1) nn.init.constant_(m.bias, 0) def _make_layer( self, block, planes, stride=1, dropblock_dropout=0.0, drop_block=False, block_size=1, ): downsample = None if stride != 1 or self.inplanes != planes * block.expansion: downsample = nn.Sequential( nn.Conv2d(self.inplanes, planes * block.expansion, kernel_size=1, stride=1, bias=False), nn.BatchNorm2d(planes * block.expansion), ) layers = [] layers.append(block( self.inplanes, planes, stride, downsample, dropblock_dropout, drop_block, block_size) ) self.inplanes = planes * block.expansion return nn.Sequential(*layers) def forward(self, x): x = self.layer1(x) x = self.layer2(x) x = self.layer3(x) x = self.layer4(x) x = self.avgpool(x) x = self.flatten(x) x = self.dropout(x) return x for more details, please see: https://github.com/WangJingyao07/MetaLearning-Lab","title":"For example"},{"location":"3%20Examples/2%20rl/","text":"Reinforcement Learning Examples (MAML) Dependency python: 3.x Pytorch: 0.4+ Usage python maml_rl.py or python main.py --zero_order --approx_delta=0.3 Improve it Based Paper: Multi-Step Model-Agnostic Meta-Learning: Convergence and Improved Algorithms Rank-One Matrix Factorization matrix_rank_train.py: The training file of rank-one matrix factorization problem meta_matrix_rank.py: The meta configure file of rank-one matrix factorization problem linear_matrix_rank.py: linear network file python matrix_rank_train.py --approx_method=zero_order --approx_delta=1e-4 Regression regression_train.py: The training file of regression problem meta_regression.py: The meta configure file of regression problem MLP.py: MLP network file python regression_train.py --approx_method=first_approx --approx_delta=1e-7","title":"Reinforcement Learning"},{"location":"3%20Examples/2%20rl/#reinforcement-learning","text":"","title":"Reinforcement Learning"},{"location":"3%20Examples/2%20rl/#examples-maml","text":"","title":"Examples (MAML)"},{"location":"3%20Examples/2%20rl/#dependency","text":"python: 3.x Pytorch: 0.4+","title":"Dependency"},{"location":"3%20Examples/2%20rl/#usage","text":"python maml_rl.py or python main.py --zero_order --approx_delta=0.3","title":"Usage"},{"location":"3%20Examples/2%20rl/#improve-it","text":"Based Paper: Multi-Step Model-Agnostic Meta-Learning: Convergence and Improved Algorithms Rank-One Matrix Factorization matrix_rank_train.py: The training file of rank-one matrix factorization problem meta_matrix_rank.py: The meta configure file of rank-one matrix factorization problem linear_matrix_rank.py: linear network file python matrix_rank_train.py --approx_method=zero_order --approx_delta=1e-4 Regression regression_train.py: The training file of regression problem meta_regression.py: The meta configure file of regression problem MLP.py: MLP network file python regression_train.py --approx_method=first_approx --approx_delta=1e-7","title":"Improve it"},{"location":"4%20Papers/1%20Papers%20and%20Code/","text":"Papers & CODE Zero-Shot / One-Shot / Few-Shot / Low-Shot Learning Siamese Neural Networks for One-shot Image Recognition , (2015), Gregory Koch, Richard Zemel, Ruslan Salakhutdinov . [pdf] [code] Prototypical Networks for Few-shot Learning , (2017), Jake Snell, Kevin Swersky, Richard S. Zemel . [pdf] [code] Gaussian Prototypical Networks for Few-Shot Learning on Omniglot (2017), Stanislav Fort . [pdf] [code] Matching Networks for One Shot Learning , (2017), Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Koray Kavukcuoglu, Daan Wierstra . [pdf] [code] Learning to Compare: Relation Network for Few-Shot Learning , (2017), Flood Sung, Yongxin Yang, Li Zhang, Tao Xiang, Philip H.S. Torr, Timothy M. Hospedales . [pdf] [code] One-shot Learning with Memory-Augmented Neural Networks , (2016), Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, Timothy Lillicrap . [pdf] [code] Optimization as a Model for Few-Shot Learning , (2016), Sachin Ravi and Hugo Larochelle . [pdf] [code] An embarrassingly simple approach to zero-shot learning , (2015), B Romera-Paredes, Philip H. S. Torr . [pdf] [code] Low-shot Learning by Shrinking and Hallucinating Features , (2017), Bharath Hariharan, Ross Girshick . [pdf] [code] Low-shot learning with large-scale diffusion , (2018), Matthijs Douze, Arthur Szlam, Bharath Hariharan, Herv\u00e9 J\u00e9gou . [pdf] [code] Low-Shot Learning with Imprinted Weights , (2018), Hang Qi, Matthew Brown, David G. Lowe . [pdf] [code] One-Shot Video Object Segmentation , (2017), S. Caelles and K.K. Maninis and J. Pont-Tuset and L. Leal-Taixe' and D. Cremers and L. Van Gool . [pdf] [code] One-Shot Learning for Semantic Segmentation , (2017), Amirreza Shaban, Shray Bansal, Zhen Liu, Irfan Essa, Byron Boots . [pdf] [code] Few-Shot Segmentation Propagation with Guided Networks , (2018), Kate Rakelly, Evan Shelhamer, Trevor Darrell, Alexei A. Efros, Sergey Levine . [pdf] [code] Few-Shot Semantic Segmentation with Prototype Learning , (2018), Nanqing Dong and Eric P. Xing . [pdf] Dynamic Few-Shot Visual Learning without Forgetting , (2018), Spyros Gidaris, Nikos Komodakis . [pdf] [code] Feature Generating Networks for Zero-Shot Learning , (2017), Yongqin Xian, Tobias Lorenz, Bernt Schiele, Zeynep Akata . [pdf] Meta-Learning Deep Visual Words for Fast Video Object Segmentation , (2019), Harkirat Singh Behl, Mohammad Najafi, Anurag Arnab, Philip H.S. Torr . [pdf] Model Agnostic Meta Learning Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks , (2017), Chelsea Finn, Pieter Abbeel, Sergey Levine . [pdf] [code] Adversarial Meta-Learning , (2018), Chengxiang Yin, Jian Tang, Zhiyuan Xu, Yanzhi Wang . [pdf] [code] On First-Order Meta-Learning Algorithms , (2018), Alex Nichol, Joshua Achiam, John Schulman . [pdf] [code] Meta-SGD: Learning to Learn Quickly for Few-Shot Learning , (2017), Zhenguo Li, Fengwei Zhou, Fei Chen, Hang Li . [pdf] [code] Gradient Agreement as an Optimization Objective for Meta-Learning , (2018), Amir Erfan Eshratifar, David Eigen, Massoud Pedram . [pdf] [code] Gradient-Based Meta-Learning with Learned Layerwise Metric and Subspace , (2018), Yoonho Lee, Seungjin Choi . [pdf] [code] A Simple Neural Attentive Meta-Learner , (2018), Nikhil Mishra, Mostafa Rohaninejad, Xi Chen, Pieter Abbeel . [pdf] [code] Personalizing Dialogue Agents via Meta-Learning , (2019), Zhaojiang Lin, Andrea Madotto, Chien-Sheng Wu, Pascale Fung . [pdf] [code] How to train your MAML , (2019), Antreas Antoniou, Harrison Edwards, Amos Storkey . [pdf] [code] Learning to learn by gradient descent by gradient descent , (206), Marcin Andrychowicz, Misha Denil, Sergio Gomez, Matthew W. Hoffman, David Pfau, Tom Schaul, Brendan Shillingford, Nando de Freitas . [pdf] [code] Unsupervised Learning via Meta-Learning , (2019), Kyle Hsu, Sergey Levine, Chelsea Finn . [pdf] [code] Few-Shot Image Recognition by Predicting Parameters from Activations , (2018), Siyuan Qiao, Chenxi Liu, Wei Shen, Alan Yuille . [pdf] [code] One-Shot Imitation from Observing Humans via Domain-Adaptive Meta-Learning , (2018), Tianhe Yu, Chelsea Finn, Annie Xie, Sudeep Dasari, Pieter Abbeel, Sergey Levine , [pdf] [code] MetaGAN: An Adversarial Approach to Few-Shot Learning , (2018), ZHANG, Ruixiang and Che, Tong and Ghahramani, Zoubin and Bengio, Yoshua and Song, Yangqiu . [pdf] Fast Parameter Adaptation for Few-shot Image Captioning and Visual Question Answering ,(2018), Xuanyi Dong, Linchao Zhu, De Zhang, Yi Yang, Fei Wu . [pdf] CAML: Fast Context Adaptation via Meta-Learning , (2019), Luisa M Zintgraf, Kyriacos Shiarlis, Vitaly Kurin, Katja Hofmann, Shimon Whiteson . [pdf] Meta-Learning for Low-resource Natural Language Generation in Task-oriented Dialogue Systems , (2019), Fei Mi, Minlie Huang, Jiyong Zhang, Boi Faltings . [pdf] MIND: Model Independent Neural Decoder , (2019), Yihan Jiang, Hyeji Kim, Himanshu Asnani, Sreeram Kannan . [pdf] Toward Multimodal Model-Agnostic Meta-Learning , (2018), Risto Vuorio, Shao-Hua Sun, Hexiang Hu, Joseph J. Lim . [pdf] Alpha MAML: Adaptive Model-Agnostic Meta-Learning , (2019), Harkirat Singh Behl, At\u0131l\u0131m G\u00fcne\u015f Baydin, Philip H. S. Torr. [pdf] Online Meta-Learning , (2019), Chelsea Finn, Aravind Rajeswaran, Sham Kakade, Sergey Levine . [pdf] Meta Reinforcement Learning Generalizing Skills with Semi-Supervised Reinforcement Learning , (2017), Chelsea Finn, Tianhe Yu, Justin Fu, Pieter Abbeel, Sergey Levine . [pdf] [code] Guided Meta-Policy Search , (2019), Russell Mendonca, Abhishek Gupta, Rosen Kralev, Pieter Abbeel, Sergey Levine, Chelsea Finn . [pdf] [code] End-to-End Robotic Reinforcement Learning without Reward Engineering , (2019), Avi Singh, Larry Yang, Kristian Hartikainen, Chelsea Finn, Sergey Levine . [pdf] [code] Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables , (2019), Kate Rakelly, Aurick Zhou, Deirdre Quillen, Chelsea Finn, Sergey Levine . [pdf] [code] Meta-Gradient Reinforcement Learning , (2018), Zhongwen Xu, Hado van Hasselt,David Silver . [pdf] Task-Agnostic Dynamics Priors for Deep Reinforcement Learning , (2019), Yilun Du, Karthik Narasimhan . [pdf] Meta Reinforcement Learning with Task Embedding and Shared Policy ,(2019), Lin Lan, Zhenguo Li, Xiaohong Guan, Pinghui Wang . [pdf] NoRML: No-Reward Meta Learning , (2019), Yuxiang Yang, Ken Caluwaerts, Atil Iscen, Jie Tan, Chelsea Finn . [pdf] Actor-Critic Algorithms for Constrained Multi-agent Reinforcement Learning , (2019), Raghuram Bharadwaj Diddigi, Sai Koti Reddy Danda, Prabuchandran K. J., Shalabh Bhatnagar . [pdf] Adaptive Guidance and Integrated Navigation with Reinforcement Meta-Learning , (2019), Brian Gaudet, Richard Linares, Roberto Furfaro . [pdf] Watch, Try, Learn: Meta-Learning from Demonstrations and Reward , (2019), Allan Zhou, Eric Jang, Daniel Kappler, Alex Herzog, Mohi Khansari, Paul Wohlhart, Yunfei Bai, Mrinal Kalakrishnan, Sergey Levine, Chelsea Finn . [pdf] Options as responses: Grounding behavioural hierarchies in multi-agent RL , (2019), Alexander Sasha Vezhnevets, Yuhuai Wu, Remi Leblond, Joel Z. Leibo . [pdf] Learning latent state representation for speeding up exploration , (2019), Giulia Vezzani, Abhishek Gupta, Lorenzo Natale, Pieter Abbeel . [pdf] Beyond Exponentially Discounted Sum: Automatic Learning of Return Function , (2019), Yufei Wang, Qiwei Ye, Tie-Yan Liu . [pdf] Learning Efficient and Effective Exploration Policies with Counterfactual Meta Policy , (2019), Ruihan Yang, Qiwei Ye, Tie-Yan Liu . [pdf] Dealing with Non-Stationarity in Multi-Agent Deep Reinforcement Learning , (2019), Georgios Papoudakis, Filippos Christianos, Arrasy Rahman, Stefano V. Albrecht . [pdf] Learning to Discretize: Solving 1D Scalar Conservation Laws via Deep Reinforcement Learning , (2019), Yufei Wang, Ziju Shen, Zichao Long, Bin Dong . [[pdf]] Other & Uncategorized Grounded Language Learning Fast and Slow by Hill, Felix and Tieleman, Olivier and von Glehn, Tamara and Wong, Nathaniel and Merzic, Hamza and Clark, Stephen http://arxiv.org/abs/2009.01719 Sparse Meta Networks for Sequential Adaptation and its Application to Adaptive Language Modelling by Munkhdalai, Tsendsuren http://arxiv.org/abs/2009.01803 Learning with Differentiable Perturbed Optimizers by Berthet, Quentin and Blondel, Mathieu and Teboul, Olivier and Cuturi, Marco and Vert, Jean-Philippe and Bach, Francis http://arxiv.org/abs/2002.08676 What is being transferred in transfer learning? by Neyshabur, Behnam and Sedghi, Hanie and Zhang, Chiyuan http://arxiv.org/abs/2008.11687 On modulating the gradient for meta-learning by Simon, Christian and Koniusz, Piotr and Nock, Richard and Harandi, Mehrtash https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123530545.pdf Meta-Learning with Shared Amortized Variational Inference by Iakovleva, Ekaterina and Verbeek, Jakob and Alahari, Karteek http://arxiv.org/abs/2008.12037 learn2learn: A Library for Meta-Learning Research by Arnold, S\u00e9bastien M R and Mahajan, Praateek and Datta, Debajyoti and Bunner, Ian and Zarkias, Konstantinos Saitas http://arxiv.org/abs/2008.12284 A Universal Representation Transformer Layer for Few-Shot Image Classification by Liu, Lu and Hamilton, William and Long, Guodong and Jiang, Jing and Larochelle, Hugo http://arxiv.org/abs/2006.11702 Safe Model-Based Meta-Reinforcement Learning: A Sequential Exploration-Exploitation Framework by Lew, Thomas and Sharma, Apoorva and Harrison, James and Pavone, Marco http://arxiv.org/abs/2008.11700 Learning to Learn in a Semi-Supervised Fashion by Chen, Yun-Chun and Chou, Chao-Te and Wang, Yu-Chiang Frank http://arxiv.org/abs/2008.11203 The Advantage of Conditional Meta-Learning for Biased Regularization and Fine-Tuning by Denevi, Giulia and Pontil, Massimiliano and Ciliberto, Carlo http://arxiv.org/abs/2008.10857 Adaptive Multi-level Hyper-gradient Descent by Jie, Renlong and Gao, Junbin and Vasnev, Andrey and Tran, Minh-Ngoc http://arxiv.org/abs/2008.07277 Few-Shot Image Classification via Contrastive Self-Supervised Learning by Li, Jianyi and Liu, Guizhong http://arxiv.org/abs/2008.09942 Does MAML really want feature reuse only? by Oh, Jaehoon and Yoo, Hyungjun and Kim, Changhwan and Yun, Se-Young http://arxiv.org/abs/2008.08882 Meta Learning MPC using Finite-Dimensional Gaussian Process Approximations by Arcari, Elena and Carron, Andrea and Zeilinger, Melanie N http://arxiv.org/abs/2008.05984 Offline Meta-Reinforcement Learning with Advantage Weighting by Mitchell, Eric and Rafailov, Rafael and Peng, Xue Bin and Levine, Sergey and Finn, Chelsea http://arxiv.org/abs/2008.06043 Explore then Execute: Adapting without Rewards via Factorized Meta-Reinforcement Learning by Liu, Evan Zheran and Raghunathan, Aditi and Liang, Percy and Finn, Chelsea http://arxiv.org/abs/2008.02790 Offline Meta Reinforcement Learning by Dorfman, Ron and Tamar, Aviv http://arxiv.org/abs/2008.02598 Few-Shot Learning via Learning the Representation, Provably by Du, Simon S and Hu, Wei and Kakade, Sham M and Lee, Jason D and Lei, Qi http://arxiv.org/abs/2002.09434 Multi-Task Reinforcement Learning as a Hidden-Parameter Block MDP by Zhang, Amy and Sodhani, Shagun and Khetarpal, Khimya and Pineau, Joelle http://arxiv.org/abs/2007.07206 CAMPs: Learning Context-Specific Abstractions for Efficient Planning in Factored MDPs by Chitnis, Rohan and Silver, Tom and Kim, Beomjoon and Kaelbling, Leslie Pack and Lozano-Perez, Tomas http://arxiv.org/abs/2007.13202 Unsupervised Learning of Visual Features by Contrasting Cluster Assignments by Caron, Mathilde and Misra, Ishan and Mairal, Julien and Goyal, Priya and Bojanowski, Piotr and Joulin, Armand http://arxiv.org/abs/2006.09882 MiCo: Mixup Co-Training for Semi-Supervised Domain Adaptation by Yang, Luyu and Wang, Yan and Gao, Mingfei and Shrivastava, Abhinav and Weinberger, Kilian Q and Chao, Wei-Lun and Lim, Ser-Nam http://arxiv.org/abs/2007.12684 Adaptive Task Sampling for Meta-Learning by Liu, Chenghao and Wang, Zhihao and Sahoo, Doyen and Fang, Yuan and Zhang, Kun and Hoi, Steven C H http://arxiv.org/abs/2007.08735 Discovering Reinforcement Learning Algorithms by Oh, Junhyuk and Hessel, Matteo and Czarnecki, Wojciech M and Xu, Zhongwen and van Hasselt, Hado and Singh, Satinder and Silver, David http://arxiv.org/abs/2007.08794 On the Outsized Importance of Learning Rates in Local Update Methods by Charles, Zachary and Kone{\\v c}n{\\'y}, Jakub http://arxiv.org/abs/2007.00878 Global Convergence and Induced Kernels of Gradient-Based Meta-Learning with Neural Nets by Wang, Haoxiang and Sun, Ruoyu and Li, Bo http://arxiv.org/abs/2006.14606 On the Iteration Complexity of Hypergradient Computation by Grazzi, Riccardo and Franceschi, Luca and Pontil, Massimiliano and Salzo, Saverio http://arxiv.org/abs/2006.16218 On the Outsized Importance of Learning Rates in Local Update Methods by Charles, Zachary and Kone{\\v c}n{\\'y}, Jakub http://arxiv.org/abs/2007.00878 Meta-SAC: Auto-tune the Entropy Temperature of Soft Actor-Critic via Metagradient by Wang, Yufei and Ni, Tianwei http://arxiv.org/abs/2007.01932 Meta Learning in the Continuous Time Limit by Xu, Ruitu and Chen, Lin and Karbasi, Amin http://arxiv.org/abs/2006.10921 Expert Training: Task Hardness Aware Meta-Learning for Few-Shot Classification by Zhou, Yucan and Wang, Yu and Cai, Jianfei and Zhou, Yu and Hu, Qinghua and Wang, Weiping http://arxiv.org/abs/2007.06240 MTL2L: A Context Aware Neural Optimiser by Kuo, Nicholas I-Hsien and Harandi, Mehrtash and Fourrier, Nicolas and Walder, Christian and Ferraro, Gabriela and Suominen, Hanna http://arxiv.org/abs/2007.09343 Navigating the Trade-Off between Multi-Task Learning and Learning to Multitask in Deep Neural Networks by Ravi, Sachin and Musslick, Sebastian and Hamin, Maia and Willke, Theodore L and Cohen, Jonathan D http://arxiv.org/abs/2007.10527 Balanced Meta-Softmax for Long-Tailed Visual Recognition by Ren, Jiawei and Yu, Cunjun and Sheng, Shunan and Ma, Xiao and Zhao, Haiyu and Yi, Shuai and Li, Hongsheng http://arxiv.org/abs/2007.10740 CrossTransformers: spatially-aware few-shot transfer by Doersch, Carl and Gupta, Ankush and Zisserman, Andrew http://arxiv.org/abs/2007.11498 Meta-Learning a Dynamical Language Model by Wolf, Thomas and Chaumond, Julien and Delangue, Clement http://arxiv.org/abs/1803.10631 Meta-Learning Requires Meta-Augmentation by Rajendran, Janarthanan and Irpan, Alex and Jang, Eric http://arxiv.org/abs/2007.05549 Adaptive Risk Minimization: A Meta-Learning Approach for Tackling Group Shift by Zhang, Marvin and Marklund, Henrik and Gupta, Abhishek and Levine, Sergey and Finn, Chelsea http://arxiv.org/abs/2007.02931 Meta-Learning Symmetries by Reparameterization by Zhou, Allan and Knowles, Tom and Finn, Chelsea http://arxiv.org/abs/2007.02933 Adaptive Risk Minimization: A Meta-Learning Approach for Tackling Group Shift by Zhang, Marvin and Marklund, Henrik and Gupta, Abhishek and Levine, Sergey and Finn, Chelsea http://arxiv.org/abs/2007.02931 A Brief Look at Generalization in Visual Meta-Reinforcement Learning by Alver, Safa and Precup, Doina http://arxiv.org/abs/2006.07262 Learning Representations by Stochastic Meta-Gradient Descent in Neural Networks by Veeriah, Vivek and Zhang, Shangtong and Sutton, Richard S http://arxiv.org/abs/1612.02879 PACOH: Bayes-Optimal Meta-Learning with PAC-Guarantees by Rothfuss, Jonas and Fortuin, Vincent and Krause, Andreas http://arxiv.org/abs/2002.05551 Meta-Meta-Classification for One-Shot Learning by Chowdhury, Arkabandhu and Chaudhari, Dipak and Chaudhuri, Swarat and Jermaine, Chris http://arxiv.org/abs/2004.08083 Relatedness Measures to Aid the Transfer of Building Blocks among Multiple Tasks by Nguyen, Trung B and Browne, Will N and Zhang, Mengjie http://arxiv.org/abs/2005.03947 Information-Theoretic Generalization Bounds for Meta-Learning and Applications by Jose, Sharu Theresa and Simeone, Osvaldo http://arxiv.org/abs/2005.04372 On Learning Intrinsic Rewards for Policy Gradient Methods by Zheng, Zeyu and Oh, Junhyuk and Singh, Satinder http://arxiv.org/abs/1804.06459 A Sample Complexity Separation between Non-Convex and Convex Meta-Learning by Saunshi, Nikunj and Zhang, Yi and Khodak, Mikhail and Arora, Sanjeev http://arxiv.org/abs/2002.11172 Bayesian Online Meta-Learning with Laplace Approximation by Yap, Pau Ching and Ritter, Hippolyt and Barber, David http://arxiv.org/abs/2005.00146 Meta-Reinforcement Learning for Robotic Industrial Insertion Tasks by Schoettler, Gerrit and Nair, Ashvin and Ojea, Juan Aparicio and Levine, Sergey and Solowjow, Eugen http://arxiv.org/abs/2004.14404 Continual Deep Learning by Functional Regularisation of Memorable Past by Pan, Pingbo and Swaroop, Siddharth and Immer, Alexander and Eschenhagen, Runa and Turner, Richard E and Khan, Mohammad Emtiyaz http://arxiv.org/abs/2004.14070 Jelly Bean World: A Testbed for Never-Ending Learning by Platanios, Emmanouil Antonios and Saparov, Abulhair and Mitchell, Tom https://openreview.net/pdf?id=Byx_YAVYPH Encouraging behavioral diversity in evolutionary robotics: an empirical study by Mouret, J-B and Doncieux, S http://dx.doi.org/10.1162/EVCO_a_00048 Defining Benchmarks for Continual Few-Shot Learning by Antoniou, Antreas and Patacchiola, Massimiliano and Ochal, Mateusz and Storkey, Amos http://arxiv.org/abs/2004.11967 Emergent Real-World Robotic Skills via Unsupervised Off-Policy Reinforcement Learning by Sharma, Archit and Ahn, Michael and Levine, Sergey and Kumar, Vikash and Hausman, Karol and Gu, Shixiang http://arxiv.org/abs/2004.12974 Empirical Bayes Transductive Meta-Learning with Synthetic Gradients by Hu, Shell Xu and Moreno, Pablo G and Xiao, Yang and Shen, Xi and Obozinski, Guillaume and Lawrence, Neil D and Damianou, Andreas http://arxiv.org/abs/2004.12696 Evolving Inborn Knowledge For Fast Adaptation in Dynamic POMDP Problems by Ben-Iwhiwhu, Eseoghene and Ladosz, Pawel and Dick, Jeffery and Chen, Wen-Hua and Pilly, Praveen and Soltoggio, Andrea http://arxiv.org/abs/2004.12846 Meta-World: A Benchmark and Evaluation for Multi-Task and Meta Reinforcement Learning by Yu, Tianhe and Quillen, Deirdre and He, Zhanpeng and Julian, Ryan and Hausman, Karol and Finn, Chelsea and Levine, Sergey http://arxiv.org/abs/1910.10897 Meta reinforcement learning as task inference by Humplik, Jan and Galashov, Alexandre and Hasenclever, Leonard and Ortega, Pedro A and Teh, Yee Whye and Heess, Nicolas http://arxiv.org/abs/1905.06424 Meta-Gradient Reinforcement Learning by Xu, Zhongwen and van Hasselt, Hado and Silver, David http://arxiv.org/abs/1805.09801 Self-Paced Deep Reinforcement Learning by Klink, Pascal and D'Eramo, Carlo and Peters, Jan and Pajarinen, Joni http://arxiv.org/abs/2004.11812 Scheduling the Learning Rate Via Hypergradients: New Insights and a New Algorithm by Donini, Michele and Franceschi, Luca and Majumder, Orchid and Pontil, Massimiliano and Frasconi, Paolo https://openreview.net/pdf?id=Ske6qJSKPH Learning Stabilizable Nonlinear Dynamics with Contraction-Based Regularization by Singh, Sumeet and Richards, Spencer M and Sindhwani, Vikas and Slotine, Jean-Jacques E and Pavone, Marco http://arxiv.org/abs/1907.13122 A Comprehensive Overview and Survey of Recent Advances in Meta-Learning by Peng, Huimin http://arxiv.org/abs/2004.11149 Learning a Formula of Interpretability to Learn Interpretable Formulas by Virgolin, Marco and De Lorenzo, Andrea and Medvet, Eric and Randone, Francesca http://arxiv.org/abs/2004.11170 Model-Based Meta-Reinforcement Learning for Flight with Suspended Payloads by Belkhale, Suneel and Li, Rachel and Kahn, Gregory and McAllister, Rowan and Calandra, Roberto and Levine, Sergey http://arxiv.org/abs/2004.11345 Frustratingly Simple Few-Shot Object Detection by Wang, Xin and Huang, Thomas E and Darrell, Trevor and Gonzalez, Joseph E and Yu, Fisher http://arxiv.org/abs/2003.06957 Meta Pseudo Labels by Pham, Hieu and Xie, Qizhe and Dai, Zihang and Le, Quoc V http://arxiv.org/abs/2003.10580 0e56da12-a2f0-4288-b745-c15deec9183a by Unknown http://learn2learn.net Finding online neural update rules by learning to remember by Gregor, Karol http://arxiv.org/abs/2003.03124 A New Meta-Baseline for Few-Shot Learning by Chen, Yinbo and Wang, Xiaolong and Liu, Zhuang and Xu, Huijuan and Darrell, Trevor http://arxiv.org/abs/2003.04390 Learning to be Global Optimizer by Zhang, Haotian and Sun, Jianyong and Xu, Zongben http://arxiv.org/abs/2003.04521 Scalable Multi-Task Imitation Learning with Autonomous Improvement by Singh, Avi and Jang, Eric and Irpan, Alexander and Kappler, Daniel and Dalal, Murtaza and Levine, Sergey and Khansari, Mohi and Finn, Chelsea http://arxiv.org/abs/2003.02636 Meta-learning for mixed linear regression by Kong, Weihao and Somani, Raghav and Song, Zhao and Kakade, Sham and Oh, Sewoong http://arxiv.org/abs/2002.08936 Provable Meta-Learning of Linear Representations by Tripuraneni, Nilesh and Jin, Chi and Jordan, Michael I http://arxiv.org/abs/2002.11684 Learning to Continually Learn by Beaulieu, Shawn and Frati, Lapo and Miconi, Thomas and Lehman, Joel and Stanley, Kenneth O and Clune, Jeff and Cheney, Nick http://arxiv.org/abs/2002.09571 PACOH: Bayes-Optimal Meta-Learning with PAC-Guarantees by Rothfuss, Jonas and Fortuin, Vincent and Krause, Andreas http://arxiv.org/abs/2002.05551 Incremental Learning for Metric-Based Meta-Learners by Liu, Qing and Majumder, Orchid and Ravichandran, Avinash and Bhotika, Rahul and Soatto, Stefano http://arxiv.org/abs/2002.04162 Hyper-Meta Reinforcement Learning with Sparse Reward by Hua, Yun and Wang, Xiangfeng and Jin, Bo and Li, Wenhao and Yan, Junchi and He, Xiaofeng and Zha, Hongyuan http://arxiv.org/abs/2002.04238 Meta-Learning across Meta-Tasks for Few-Shot Learning by Fei, Nanyi and Lu, Zhiwu and Gao, Yizhao and Tian, Jia and Xiang, Tao and Wen, Ji-Rong http://arxiv.org/abs/2002.04274 Distribution-Agnostic Model-Agnostic Meta-Learning by Collins, Liam and Mokhtari, Aryan and Shakkottai, Sanjay http://arxiv.org/abs/2002.04766 Provably Convergent Policy Gradient Methods for Model-Agnostic Meta-Reinforcement Learning by Fallah, Alireza and Mokhtari, Aryan and Ozdaglar, Asuman http://arxiv.org/abs/2002.05135 Meta-learning framework with applications to zero-shot time-series forecasting by Oreshkin, Boris N and Carpov, Dmitri and Chapados, Nicolas and Bengio, Yoshua http://arxiv.org/abs/2002.02887 A Loss-Function for Causal Machine-Learning by Yang, I-Sheng http://arxiv.org/abs/2001.00629 Self-Tuning Deep Reinforcement Learning by Zahavy, Tom and Xu, Zhongwen and Veeriah, Vivek and Hessel, Matteo and Van Hasslet, Hado and Silver, David and Singh, Satinder http://arxiv.org/abs/2002.12928 Learning Adaptive Loss for Robust Learning with Noisy Labels by Shu, Jun and Zhao, Qian and Chen, Keyu and Xu, Zongben and Meng, Deyu http://arxiv.org/abs/2002.06482 A Structured Prediction Approach for Conditional Meta-Learning by Wang, Ruohan and Demiris, Yiannis and Ciliberto, Carlo http://arxiv.org/abs/2002.08799 Curriculum in Gradient-Based Meta-Reinforcement Learning by Mehta, Bhairav and Deleu, Tristan and Raparthy, Sharath Chandra and Pal, Chris J and Paull, Liam http://arxiv.org/abs/2002.07956 Multi-Step Model-Agnostic Meta-Learning: Convergence and Improved Algorithms by Ji, Kaiyi and Yang, Junjie and Liang, Yingbin http://arxiv.org/abs/2002.07836 Local Nonparametric Meta-Learning by Goo, Wonjoon and Niekum, Scott http://arxiv.org/abs/2002.03272 Revisiting Meta-Learning as Supervised Learning by Chao, Wei-Lun and Ye, Han-Jia and Zhan, De-Chuan and Campbell, Mark and Weinberger, Kilian Q http://arxiv.org/abs/2002.00573 SimpleShot: Revisiting Nearest-Neighbor Classification for Few-Shot Learning by Wang, Yan and Chao, Wei-Lun and Weinberger, Kilian Q and van der Maaten, Laurens http://arxiv.org/abs/1911.04623 Fast and Generalized Adaptation for Few-Shot Learning by Song, Liang and Liu, Jinlu and Qin, Yongqiang http://arxiv.org/abs/1911.10807 Meta-Learning without Memorization by Yin, Mingzhang and Tucker, George and Zhou, Mingyuan and Levine, Sergey and Finn, Chelsea http://arxiv.org/abs/1912.03820 Your Classifier is Secretly an Energy Based Model and You Should Treat it Like One by Grathwohl, Will and Wang, Kuan-Chieh and Jacobsen, J{\\\"o}rn-Henrik and Duvenaud, David and Norouzi, Mohammad and Swersky, Kevin http://arxiv.org/abs/1912.03263 MAME : Model-Agnostic Meta-Exploration by Gurumurthy, Swaminathan and Kumar, Sumit and Sycara, Katia http://arxiv.org/abs/1911.04024 Constructing Multiple Tasks for Augmentation: Improving Neural Image Classification With K-means Features by Gui, Tao and Qing, Lizhi and Zhang, Qi and Ye, Jiacheng and Yan, Hang and Fei, Zichu and Huang, Xuanjing http://arxiv.org/abs/1911.07518 Meta Adaptation using Importance Weighted Demonstrations by Lekkala, Kiran and Abu-El-Haija, Sami and Itti, Laurent http://arxiv.org/abs/1911.10322 VIABLE: Fast Adaptation via Backpropagating Learned Loss by Feng, Leo and Zintgraf, Luisa and Peng, Bei and Whiteson, Shimon http://arxiv.org/abs/1911.13159 Decoupling Adaptation from Modeling with Meta-Optimizers for Meta Learning by Arnold, S{\\'e}bastien M R and Iqbal, Shariq and Sha, Fei http://arxiv.org/abs/1910.13603 TADAM: Task dependent adaptive metric for improved few-shot learning by Oreshkin, Boris and Rodr{\\'\\i}guez L{\\'o}pez, Pau and Lacoste, Alexandre http://papers.nips.cc/paper/7352-tadam-task-dependent-adaptive-metric-for-improved-few-shot-learning.pdf Learning to Few-Shot Learn Across Diverse Natural Language Classification Tasks by Bansal, Trapit and Jha, Rishikesh and McCallum, Andrew http://arxiv.org/abs/1911.03863 Optimizing Millions of Hyperparameters by Implicit Differentiation by Lorraine, Jonathan and Vicol, Paul and Duvenaud, David http://arxiv.org/abs/1911.02590 Meta-data: Characterization of Input Features for Meta-learning by Castiello, Ciro and Castellano, Giovanna and Fanelli, Anna Maria http://dx.doi.org/10.1007/11526018_45 Meta-Learning for Low-resource Natural Language Generation in Task-oriented Dialogue Systems by Mi, Fei and Huang, Minlie and Zhang, Jiyong and Faltings, Boi http://arxiv.org/abs/1905.05644 Domain Generalization via Model-Agnostic Learning of Semantic Features by Dou, Qi and Castro, Daniel C and Kamnitsas, Konstantinos and Glocker, Ben http://arxiv.org/abs/1910.13580 Hierarchical Expert Networks for Meta-Learning by Hihn, Heinke and Braun, Daniel A http://arxiv.org/abs/1911.00348 Online Meta-Learning on Non-convex Setting by Zhuang, Zhenxun and Wang, Yunlong and Yu, Kezi and Lu, Songtao http://arxiv.org/abs/1910.10196 Learning-to-Learn Stochastic Gradient Descent with Biased Regularization by Denevi, Giulia and Ciliberto, Carlo and Grazzi, Riccardo and Pontil, Massimiliano http://arxiv.org/abs/1903.10399 Provable Guarantees for Gradient-Based Meta-Learning by Khodak, Mikhail and Balcan, Maria-Florina and Talwalkar, Ameet http://arxiv.org/abs/1902.10644 The TCGA Meta-Dataset Clinical Benchmark by Samiei, Mandana and W{\\\"u}rfl, Tobias and Deleu, Tristan and Weiss, Martin and Dutil, Francis and Fevens, Thomas and Boucher, Genevi{`e}ve and Lemieux, Sebastien and Cohen, Joseph Paul http://arxiv.org/abs/1910.08636 VariBAD: A Very Good Method for Bayes-Adaptive Deep RL via Meta-Learning by Zintgraf, Luisa and Shiarlis, Kyriacos and Igl, Maximilian and Schulze, Sebastian and Gal, Yarin and Hofmann, Katja and Whiteson, Shimon http://arxiv.org/abs/1910.08348 Meta-Transfer Learning through Hard Tasks by Sun, Qianru and Liu, Yaoyao and Chen, Zhaozheng and Chua, Tat-Seng and Schiele, Bernt http://arxiv.org/abs/1910.03648 Model-Agnostic Meta-Learning using Runge-Kutta Methods by Im, Daniel Jiwoong and Jiang, Yibo and Verma, Nakul http://arxiv.org/abs/1910.07368 Improving Generalization in Meta Reinforcement Learning using Learned Objectives by Kirsch, Louis and van Steenkiste, Sjoerd and Schmidhuber, J{\\\"u}rgen http://arxiv.org/abs/1910.04098 Generalized Inner Loop Meta-Learning by Grefenstette, Edward and Amos, Brandon and Yarats, Denis and Htut, Phu Mon and Molchanov, Artem and Meier, Franziska and Kiela, Douwe and Cho, Kyunghyun and Chintala, Soumith http://arxiv.org/abs/1910.01727 Is Fast Adaptation All You Need? by Javed, Khurram and Yao, Hengshuai and White, Martha http://arxiv.org/abs/1910.01705 Deep Reinforcement Learning for Single-Shot Diagnosis and Adaptation in Damaged Robots by Verma, Shresth and Nair, Haritha S and Agarwal, Gaurav and Dhar, Joydip and Shukla, Anupam http://arxiv.org/abs/1910.01240 ES-MAML: Simple Hessian-Free Meta Learning by Song, Xingyou and Gao, Wenbo and Yang, Yuxiang and Choromanski, Krzysztof and Pacchiano, Aldo and Tang, Yunhao http://arxiv.org/abs/1910.01215 Meta-Q-Learning by Fakoor, Rasool and Chaudhari, Pratik and Soatto, Stefano and Smola, Alexander J http://arxiv.org/abs/1910.00125 Efficient meta reinforcement learning via meta goal generation by Fu, Haotian and Tang, Hongyao and Hao, Jianye http://arxiv.org/abs/1909.13607 Chameleon: Learning Model Initializations Across Tasks With Different Schemas by Brinkmeyer, Lukas and Drumond, Rafael Rego and Scholz, Randolf and Grabocka, Josif and Schmidt-Thieme, Lars http://arxiv.org/abs/1909.13576 Learning Fast Adaptation with Meta Strategy Optimization by Yu, Wenhao and Tan, Jie and Bai, Yunfei and Coumans, Erwin and Ha, Sehoon http://arxiv.org/abs/1909.12995 Meta-Inverse Reinforcement Learning with Probabilistic Context Variables by Yu, Lantao and Yu, Tianhe and Finn, Chelsea and Ermon, Stefano http://arxiv.org/abs/1909.09314 Modular Meta-Learning with Shrinkage by Chen, Yutian and Friesen, Abram L and Behbahani, Feryal and Budden, David and Hoffman, Matthew W and Doucet, Arnaud and de Freitas, Nando http://arxiv.org/abs/1909.05557 Loaded DiCE: Trading off Bias and Variance in Any-Order Score Function Estimators for Reinforcement Learning by Farquhar, Gregory and Whiteson, Shimon and Foerster, Jakob http://arxiv.org/abs/1909.10549 Rapid Learning or Feature Reuse? Towards Understanding the Effectiveness of MAML by Raghu, Aniruddh and Raghu, Maithra and Bengio, Samy and Vinyals, Oriol http://arxiv.org/abs/1909.09157 Meta-Learning by Vanschoren, Joaquin https://doi.org/10.1007/978-3-030-05318-5_2 Understanding Short-Horizon Bias in Stochastic Meta-Optimization by Wu, Yuhuai and Ren, Mengye and Liao, Renjie and Grosse, Roger http://arxiv.org/abs/1803.02021 On First-Order Meta-Learning Algorithms by Nichol, Alex and Achiam, Joshua and Schulman, John http://arxiv.org/abs/1803.02999 Towards Understanding Generalization in Gradient-Based Meta-Learning by Guiroy, Simon and Verma, Vikas and Pal, Christopher http://arxiv.org/abs/1907.07287 They empirically study the landscape of fast-adaptation in MAML. The most interesting claim is that when meta-overfitting, the loss landscape becomes flatter on test tasks. On the Convergence Theory of Gradient-Based Model-Agnostic Meta-Learning Algorithms by Fallah, Alireza and Mokhtari, Aryan and Ozdaglar, Asuman http://arxiv.org/abs/1908.10400 Learning to Learn with Gradients by Finn, Chelsea http://learn2learn.net Acetylcholine and memory by Hasselmo, M E and Bower, J M https://www.ncbi.nlm.nih.gov/pubmed/7688162 A THEORY OF META-LEARNING AND PRINCIPLES OF FACILITATION: AN ORGANISMIC PERSPECTIVE by Maudsley, Donald B https://uosc.primo.exlibrisgroup.com/discovery/fulldisplay?docid=proquest302999651&context=PC&vid=01USC_INST:01USC&lang=en&search_scope=MyInst_and_CI&adaptor=Primo%20Central&tab=Everything&mode=Basic THE ROLE OF METALEARNING IN STUDY PROCESSES by Biggs, J B http://doi.wiley.com/10.1111/j.2044-8279.1985.tb02625.x Understanding and correcting pathologies in the training of learned optimizers by Metz, Luke and Maheswaranathan, Niru and Nixon, Jeremy and Daniel Freeman, C and Sohl-Dickstein, Jascha http://arxiv.org/abs/1810.10180 Provides many tricks (e.g. split train batch for model \\& opt, average gradient estimators) for training differentiable optimizers online. They also have a couple of interesting observations specific to recurrent optimizers. Learned Optimizers that Scale and Generalize by Wichrowska, Olga and Maheswaranathan, Niru and Hoffman, Matthew W and Colmenarejo, Sergio Gomez and Denil, Misha and de Freitas, Nando and Sohl-Dickstein, Jascha http://arxiv.org/abs/1703.04813 Using learned optimizers to make models robust to input noise by Metz, Luke and Maheswaranathan, Niru and Shlens, Jonathon and Sohl-Dickstein, Jascha and Cubuk, Ekin D http://arxiv.org/abs/1906.03367 Learning to Optimize Neural Nets by Li, Ke and Malik, Jitendra http://arxiv.org/abs/1703.00441 Meta-Learning Update Rules for Unsupervised Representation Learning by Metz, Luke and Maheswaranathan, Niru and Cheung, Brian and Sohl-Dickstein, Jascha http://arxiv.org/abs/1804.00222 Learning to Optimize by Li, Ke and Malik, Jitendra http://arxiv.org/abs/1606.01885 Learning to learn by gradient descent by gradient descent by Andrychowicz, M and Denil, M and Gomez, S http://learn2learn.net Online Learning Rate Adaptation with Hypergradient Descent by Baydin, Atilim Gunes and Cornish, Robert and Rubio, David Martinez and Schmidt, Mark and Wood, Frank http://arxiv.org/abs/1703.04782 They adapt the learning rate of SGD by differentiating the loss of the next parameters w.r.t. the learning rate. They observe that the gradient of the learning rate is simply the inner product of the last two gradients. Adapting Bias by Gradient Descent: An Incremental Version of Delta-Bar-Delta by Sutton, Richard S http://dx.doi.org/ What's mostly interesting in this paper is the adaptation of delta-bar-delta to the online scenario. The idea of representing the learning rate as an exponential is nice. Also nice to see that the derivation suggests a full-matrix adaptive case. Gain adaptation beats least squares by Sutton, Richard S https://pdfs.semanticscholar.org/7ec8/876f219b3b3d5c894a3f395c89c382029cc5.pdf This paper extends IDBD as algorithms K1 and K2, but from my quick read, it isn't clear what's the motivation for those modifications. (Seems to work in a `normalized space'', {\\ a} la natural gradient ?)They do work better. Local Gain Adaptation in Stochastic Gradient Descent by Schraudolph, Nicol N https://pdfs.semanticscholar.org/31a0/b86c3cd04e6539626f34b80db7ff79d23f40.pdf This algorithm extends IDBD (Sutton) to the non-linear setting. Interestingly, they have a few brief discussionson the difficulties to optimize at the meta-level. (c.f. Meta-level conditioning section.) Overall, it shines light on the ground idea behind IDBD. TIDBD: Adapting Temporal-difference Step-sizes Through Stochastic Meta-descent by Kearney, Alex and Veeriah, Vivek and Travnik, Jaden B and Sutton, Richard S and Pilarski, Patrick M http://arxiv.org/abs/1804.03334 Increased rates of convergence through learning rate adaptation by Jacobs, Robert A http://www.sciencedirect.com/science/article/pii/0893608088900032 This paper argues that we need (at least) four ingredients to improve optimization of connectionist networks: 1. each parameter has its own stepsize, 2. stepsizes vary over time, 3. if consecutive gradients of a stepsize have the same sign, the stepsize should be increased, 4. conversely, if the stepsize should be decreased if its gradients have opposite signs. It also proposes to use two improvements: 1. Momentum (i.e. Polyak's heavyball), 2. delta-bar-delta (i.e. learning the stepsize). It has an interesting comment on the difficulty of learning the stepsize, and therefore comes up with a ``hack'' that outperforms momentum. Meta-descent for Online, Continual Prediction by Jacobsen, Andrew and Schlegel, Matthew and Linke, Cameron and Degris, Thomas and White, Adam and White, Martha http://arxiv.org/abs/1907.07751 The idea is to learn the learning rate so as to minimize the norm of the gradient. They argue that for the continual learning setting, this forces the algorithm to stay ``as stable as possible''. No theorems, small-scale (but interesting) experiments. Adaptation of learning rate parameters by Sutton, Rich http://learn2learn.net Gradient-Based Meta-Learning with Learned Layerwise Metric and Subspace by Lee, Yoonho and Choi, Seungjin http://arxiv.org/abs/1801.05558 Meta-Learning with Warped Gradient Descent by Flennerhag, Sebastian and Rusu, Andrei A and Pascanu, Razvan and Yin, Hujun and Hadsell, Raia http://arxiv.org/abs/1909.00025 Meta-Learning via Learned Loss by Chebotar, Yevgen and Molchanov, Artem and Bechtle, Sarah and Righetti, Ludovic and Meier, Franziska and Sukhatme, Gaurav http://arxiv.org/abs/1906.05374 They learn the loss as a NN, and that loss's objective is to maximize the sum of rewards. It is provided a bunch of things, including inputs, outputs, goals. Meta-Curvature by Park, Eunbyung and Oliva, Junier B http://arxiv.org/abs/1902.03356 Alpha MAML: Adaptive Model-Agnostic Meta-Learning by Behl, Harkirat Singh and Baydin, At{\\i}l{\\i}m G{\\\"u}ne{\\c s} and Torr, Philip H S http://arxiv.org/abs/1905.07435 They combine hypergradient and MAML: adapt all learning rates at all times. Meta-SGD: Learning to Learn Quickly for Few-Shot Learning by Li, Zhenguo and Zhou, Fengwei and Chen, Fei and Li, Hang http://arxiv.org/abs/1707.09835 ProMP: Proximal Meta-Policy Search by Rothfuss, Jonas and Lee, Dennis and Clavera, Ignasi and Asfour, Tamim and Abbeel, Pieter http://arxiv.org/abs/1810.06784 Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks by Finn, Chelsea and Abbeel, Pieter and Levine, Sergey http://learn2learn.net Optimization as a model for few-shot learning by Ravi, Sachin and Larochelle, Hugo https://openreview.net/pdf?id=rJY0-Kcll Fast Context Adaptation via Meta-Learning by Zintgraf, Luisa M and Shiarlis, Kyriacos and Kurin, Vitaly and Hofmann, Katja and Whiteson, Shimon http://arxiv.org/abs/1810.03642 Meta-Learning with Implicit Gradients by Rajeswaran, Aravind and Finn, Chelsea and Kakade, Sham and Levine, Sergey http://arxiv.org/abs/1909.04630 Natural Neural Networks by Desjardins, Guillaume and Simonyan, Karen and Pascanu, Razvan and Kavukcuoglu, Koray http://dl.acm.org/citation.cfm?id=2969442.2969471 A Baseline for Few-Shot Image Classification by Dhillon, Guneet S and Chaudhari, Pratik and Ravichandran, Avinash and Soatto, Stefano http://arxiv.org/abs/1909.02729 A CLOSER LOOK AT FEW-SHOT CLASSIFICATION by Chen, Wei-Yu and Liu, Yen-Cheng and Kira, Zsolt https://openreview.net/pdf?id=HkxLXnAcFQ Suggests that meta-learning papers haven't been tested against classical baselines. When considering those baselines, they perform better than many of the recent meta-learning techniques. Meta-learning with differentiable closed-form solvers by Bertinetto, Luca and Henriques, Joao F and Torr, Philip and Vedaldi, Andrea https://openreview.net/forum?id=HyxnZh0ct7 Uncertainty in Model-Agnostic Meta-Learning using Variational Inference by Nguyen, Cuong and Do, Thanh-Toan and Carneiro, Gustavo http://arxiv.org/abs/1907.11864 Meta-Reinforcement Learning of Structured Exploration Strategies by Gupta, Abhishek and Mendonca, Russell and Liu, Yuxuan and Abbeel, Pieter and Levine, Sergey http://arxiv.org/abs/1802.07245 Metalearned Neural Memory by Munkhdalai, Tsendsuren and Sordoni, Alessandro and Wang, Tong and Trischler, Adam http://arxiv.org/abs/1907.09720 Accelerated Stochastic Approximation by Kesten, Harry https://projecteuclid.org/euclid.aoms/1177706705 Meta-Learning for Black-box Optimization by Vishnu, T V and Malhotra, Pankaj and Narwariya, Jyoti and Vig, Lovekesh and Shroff, Gautam http://arxiv.org/abs/1907.06901 They essentially extend the recurrent meta-learning framework in a few ways: 1. Use regret instead of objective improvement as meta-learning objective. 2. Normalize the objective so as to make it play nice with LSTMs. 3. Incorporate domain-constraints, so that the LSTM always outputs feasible solutions. All are described in page 3. Task Agnostic Continual Learning via Meta Learning by He, Xu and Sygnowski, Jakub and Galashov, Alexandre and Rusu, Andrei A and Teh, Yee Whye and Pascanu, Razvan http://arxiv.org/abs/1906.05201 Watch, Try, Learn: Meta-Learning from Demonstrations and Reward by Zhou, Allan and Jang, Eric and Kappler, Daniel and Herzog, Alex and Khansari, Mohi and Wohlhart, Paul and Bai, Yunfei and Kalakrishnan, Mrinal and Levine, Sergey and Finn, Chelsea http://arxiv.org/abs/1906.03352 Meta-Learning Representations for Continual Learning by Javed, Khurram and White, Martha http://arxiv.org/abs/1905.12588 TapNet: Neural Network Augmented with Task-Adaptive Projection for Few-Shot Learning by Yoon, Sung Whan and Seo, Jun and Moon, Jaekyun http://arxiv.org/abs/1905.06549 Meta Reinforcement Learning with Task Embedding and Shared Policy by Lan, Lin and Li, Zhenguo and Guan, Xiaohong and Wang, Pinghui http://arxiv.org/abs/1905.06527 Hierarchically Structured Meta-learning by Yao, Huaxiu and Wei, Ying and Huang, Junzhou and Li, Zhenhui http://arxiv.org/abs/1905.05301 Curious Meta-Controller: Adaptive Alternation between Model-Based and Model-Free Control in Deep Reinforcement Learning by Hafez, Muhammad Burhan and Weber, Cornelius and Kerzel, Matthias and Wermter, Stefan http://arxiv.org/abs/1905.01718 Learning to Learn in Simulation by Teng, Ervin and Iannucci, Bob http://arxiv.org/abs/1902.01569 Meta-Learning with Differentiable Convex Optimization by Lee, Kwonjoon and Maji, Subhransu and Ravichandran, Avinash and Soatto, Stefano http://arxiv.org/abs/1904.03758 Functional Regularisation for Continual Learning by Titsias, Michalis K and Schwarz, Jonathan and de G. Matthews, Alexander G and Pascanu, Razvan and Teh, Yee Whye http://arxiv.org/abs/1901.11356 Learning to Forget for Meta-Learning by Baik, Sungyong and Hong, Seokil and Lee, Kyoung Mu http://arxiv.org/abs/1906.05895 Meta-learning of Sequential Strategies by Ortega, Pedro A and Wang, Jane X and Rowland, Mark and Genewein, Tim and Kurth-Nelson, Zeb and Pascanu, Razvan and Heess, Nicolas and Veness, Joel and Pritzel, Alex and Sprechmann, Pablo and Jayakumar, Siddhant M and McGrath, Tom and Miller, Kevin and Azar, Mohammad and Osband, Ian and Rabinowitz, Neil and Gy{\\\"o}rgy, Andr{\\'a}s and Chiappa, Silvia and Osindero, Simon and Teh, Yee Whye and van Hasselt, Hado and de Freitas, Nando and Botvinick, Matthew and Legg, Shane http://arxiv.org/abs/1905.03030 This paper essentially provides a theoretical framework to ground the fact that recurrent meta-learning (RL^2, LLGD^2) performs Bayesian inference during adaptation. Auto-Meta: Automated Gradient Based Meta Learner Search by Kim, Jaehong and Lee, Sangyeul and Kim, Sungwan and Cha, Moonsu and Lee, Jung Kwon and Choi, Youngduck and Choi, Yongseok and Cho, Dong-Yeon and Kim, Jiwon http://arxiv.org/abs/1806.06927 Adaptive Gradient-Based Meta-Learning Methods by Khodak, Mikhail and Florina-Balcan, Maria and Talwalkar, Ameet http://arxiv.org/abs/1906.02717 Embedded Meta-Learning: Toward more flexible deep-learning models by Lampinen, Andrew K and McClelland, James L http://arxiv.org/abs/1905.09950 Modular meta-learning by Alet, Ferran and Lozano-P{\\'e}rez, Tom{\\'a}s and Kaelbling, Leslie P http://arxiv.org/abs/1806.10166 MetaPred: Meta-Learning for Clinical Risk Prediction with Limited Patient Electronic Health Records by Zhang, Xi Sheryl and Tang, Fengyi and Dodge, Hiroko and Zhou, Jiayu and Wang, Fei http://arxiv.org/abs/1905.03218 Prototypical Networks for Few-shot Learning by Snell, Jake and Swersky, Kevin and Zemel, Richard S http://arxiv.org/abs/1703.05175 Meta-learners' learning dynamics are unlike learners' by Rabinowitz, Neil C http://arxiv.org/abs/1905.01320 Backpropamine: training self-modifying neural networks with differentiable neuromodulated plasticity by Miconi, Thomas and Rawal, Aditya and Clune, Jeff and Stanley, Kenneth O https://openreview.net/forum?id=r1lrAiA5Ym Reinforcement Learning, Fast and Slow by Botvinick, Matthew and Ritter, Sam and Wang, Jane X and Kurth-Nelson, Zeb and Blundell, Charles and Hassabis, Demis http://dx.doi.org/10.1016/j.tics.2019.02.006 Been There, Done That: Meta-Learning with Episodic Recall by Ritter, Samuel and Wang, Jane X and Kurth-Nelson, Zeb and Jayakumar, Siddhant M and Blundell, Charles and Pascanu, Razvan and Botvinick, Matthew http://arxiv.org/abs/1805.09692 Guided Meta-Policy Search by Mendonca, Russell and Gupta, Abhishek and Kralev, Rosen and Abbeel, Pieter and Levine, Sergey and Finn, Chelsea http://arxiv.org/abs/1904.00956 Hierarchical Meta Learning by Zou, Yingtian and Feng, Jiashi http://arxiv.org/abs/1904.09081 A Meta-Transfer Objective for Learning to Disentangle Causal Mechanisms by Bengio, Yoshua and Deleu, Tristan and Rahaman, Nasim and Ke, Rosemary and Lachapelle, S{\\'e}bastien and Bilaniuk, Olexa and Goyal, Anirudh and Pal, Christopher http://arxiv.org/abs/1901.10912 Generalize Across Tasks: Efficient Algorithms for Linear Representation Learning by Bullins, Brian and Hazan, Elad and Kalai, Adam and Livni, Roi http://proceedings.mlr.press/v98/bullins19a.html Incremental Learning-to-Learn with Statistical Guarantees by Denevi, Giulia and Ciliberto, Carlo and Stamos, Dimitris and Pontil, Massimiliano http://arxiv.org/abs/1803.08089 A Model of Inductive Bias Learning by Baxter, J http://arxiv.org/abs/1106.0245 Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables by Rakelly, Kate and Zhou, Aurick and Quillen, Deirdre and Finn, Chelsea and Levine, Sergey http://arxiv.org/abs/1903.08254 Continual Learning with Tiny Episodic Memories by Chaudhry, Arslan and Rohrbach, Marcus and Elhoseiny, Mohamed and Ajanthan, Thalaiyasingam and Dokania, Puneet K and Torr, Philip H S and Ranzato, Marc'aurelio http://arxiv.org/abs/1902.10486 Online Meta-Learning by Finn, Chelsea and Rajeswaran, Aravind and Kakade, Sham and Levine, Sergey http://arxiv.org/abs/1902.08438 Modulating transfer between tasks in gradient-based meta-learning by Grant, Erin and Jerfel, Ghassen and Heller, Katherine and Griffiths, Thomas L https://openreview.net/pdf?id=HyxpNnRcFX Learning to Adapt in Dynamic, Real-World Environments Through Meta-Reinforcement Learning by Nagabandi, Anusha and Clavera, Ignasi and Liu, Simin and Fearing, Ronald S and Abbeel, Pieter and Levine, Sergey and Finn, Chelsea http://arxiv.org/abs/1803.11347 Meta-Learning with Latent Embedding Optimization by Rusu, Andrei A and Rao, Dushyant and Sygnowski, Jakub and Vinyals, Oriol and Pascanu, Razvan and Osindero, Simon and Hadsell, Raia http://arxiv.org/abs/1807.05960 Learning to Generalize: Meta-Learning for Domain Generalization by Li, Da and Yang, Yongxin and Song, Yi-Zhe and Hospedales, Timothy M http://arxiv.org/abs/1710.03463 Some Considerations on Learning to Explore via Meta-Reinforcement Learning by Stadie, Bradly C and Yang, Ge and Houthooft, Rein and Chen, Xi and Duan, Yan and Wu, Yuhuai and Abbeel, Pieter and Sutskever, Ilya http://arxiv.org/abs/1803.01118 How to train your MAML by Antoniou, Antreas and Edwards, Harrison and Storkey, Amos http://arxiv.org/abs/1810.09502 Bayesian Model-Agnostic Meta-Learning by Kim, Taesup and Yoon, Jaesik and Dia, Ousmane and Kim, Sungwoong and Bengio, Yoshua and Ahn, Sungjin http://arxiv.org/abs/1806.03836 Probabilistic Model-Agnostic Meta-Learning by Finn, Chelsea and Xu, Kelvin and Levine, Sergey http://arxiv.org/abs/1806.02817 The effects of negative adaptation in Model-Agnostic Meta-Learning by Deleu, Tristan and Bengio, Yoshua http://arxiv.org/abs/1812.02159 Memory-based Parameter Adaptation by Sprechmann, Pablo and Jayakumar, Siddhant M and Rae, Jack W and Pritzel, Alexander and Badia, Adri{`a} Puigdom{`e}nech and Uria, Benigno and Vinyals, Oriol and Hassabis, Demis and Pascanu, Razvan and Blundell, Charles http://arxiv.org/abs/1802.10542 Deep Meta-Learning: Learning to Learn in the Concept Space by Zhou, Fengwei and Wu, Bin and Li, Zhenguo http://arxiv.org/abs/1802.03596 Deep Prior by Lacoste, Alexandre and Boquet, Thomas and Rostamzadeh, Negar and Oreshkin, Boris and Chung, Wonchang and Krueger, David http://arxiv.org/abs/1712.05016 Recasting Gradient-Based Meta-Learning as Hierarchical Bayes by Grant, Erin and Finn, Chelsea and Levine, Sergey and Darrell, Trevor and Griffiths, Thomas http://arxiv.org/abs/1801.08930 WNGrad: Learn the Learning Rate in Gradient Descent by Wu, Xiaoxia and Ward, Rachel and Bottou, L{\\'e}on http://arxiv.org/abs/1803.02865 Learning to Learn by Finn, Chelsea http://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/","title":"Papers & CODE"},{"location":"4%20Papers/1%20Papers%20and%20Code/#papers-code","text":"","title":"Papers &amp; CODE"},{"location":"4%20Papers/1%20Papers%20and%20Code/#zero-shot-one-shot-few-shot-low-shot-learning","text":"Siamese Neural Networks for One-shot Image Recognition , (2015), Gregory Koch, Richard Zemel, Ruslan Salakhutdinov . [pdf] [code] Prototypical Networks for Few-shot Learning , (2017), Jake Snell, Kevin Swersky, Richard S. Zemel . [pdf] [code] Gaussian Prototypical Networks for Few-Shot Learning on Omniglot (2017), Stanislav Fort . [pdf] [code] Matching Networks for One Shot Learning , (2017), Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Koray Kavukcuoglu, Daan Wierstra . [pdf] [code] Learning to Compare: Relation Network for Few-Shot Learning , (2017), Flood Sung, Yongxin Yang, Li Zhang, Tao Xiang, Philip H.S. Torr, Timothy M. Hospedales . [pdf] [code] One-shot Learning with Memory-Augmented Neural Networks , (2016), Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, Timothy Lillicrap . [pdf] [code] Optimization as a Model for Few-Shot Learning , (2016), Sachin Ravi and Hugo Larochelle . [pdf] [code] An embarrassingly simple approach to zero-shot learning , (2015), B Romera-Paredes, Philip H. S. Torr . [pdf] [code] Low-shot Learning by Shrinking and Hallucinating Features , (2017), Bharath Hariharan, Ross Girshick . [pdf] [code] Low-shot learning with large-scale diffusion , (2018), Matthijs Douze, Arthur Szlam, Bharath Hariharan, Herv\u00e9 J\u00e9gou . [pdf] [code] Low-Shot Learning with Imprinted Weights , (2018), Hang Qi, Matthew Brown, David G. Lowe . [pdf] [code] One-Shot Video Object Segmentation , (2017), S. Caelles and K.K. Maninis and J. Pont-Tuset and L. Leal-Taixe' and D. Cremers and L. Van Gool . [pdf] [code] One-Shot Learning for Semantic Segmentation , (2017), Amirreza Shaban, Shray Bansal, Zhen Liu, Irfan Essa, Byron Boots . [pdf] [code] Few-Shot Segmentation Propagation with Guided Networks , (2018), Kate Rakelly, Evan Shelhamer, Trevor Darrell, Alexei A. Efros, Sergey Levine . [pdf] [code] Few-Shot Semantic Segmentation with Prototype Learning , (2018), Nanqing Dong and Eric P. Xing . [pdf] Dynamic Few-Shot Visual Learning without Forgetting , (2018), Spyros Gidaris, Nikos Komodakis . [pdf] [code] Feature Generating Networks for Zero-Shot Learning , (2017), Yongqin Xian, Tobias Lorenz, Bernt Schiele, Zeynep Akata . [pdf] Meta-Learning Deep Visual Words for Fast Video Object Segmentation , (2019), Harkirat Singh Behl, Mohammad Najafi, Anurag Arnab, Philip H.S. Torr . [pdf]","title":"Zero-Shot / One-Shot / Few-Shot / Low-Shot Learning"},{"location":"4%20Papers/1%20Papers%20and%20Code/#model-agnostic-meta-learning","text":"Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks , (2017), Chelsea Finn, Pieter Abbeel, Sergey Levine . [pdf] [code] Adversarial Meta-Learning , (2018), Chengxiang Yin, Jian Tang, Zhiyuan Xu, Yanzhi Wang . [pdf] [code] On First-Order Meta-Learning Algorithms , (2018), Alex Nichol, Joshua Achiam, John Schulman . [pdf] [code] Meta-SGD: Learning to Learn Quickly for Few-Shot Learning , (2017), Zhenguo Li, Fengwei Zhou, Fei Chen, Hang Li . [pdf] [code] Gradient Agreement as an Optimization Objective for Meta-Learning , (2018), Amir Erfan Eshratifar, David Eigen, Massoud Pedram . [pdf] [code] Gradient-Based Meta-Learning with Learned Layerwise Metric and Subspace , (2018), Yoonho Lee, Seungjin Choi . [pdf] [code] A Simple Neural Attentive Meta-Learner , (2018), Nikhil Mishra, Mostafa Rohaninejad, Xi Chen, Pieter Abbeel . [pdf] [code] Personalizing Dialogue Agents via Meta-Learning , (2019), Zhaojiang Lin, Andrea Madotto, Chien-Sheng Wu, Pascale Fung . [pdf] [code] How to train your MAML , (2019), Antreas Antoniou, Harrison Edwards, Amos Storkey . [pdf] [code] Learning to learn by gradient descent by gradient descent , (206), Marcin Andrychowicz, Misha Denil, Sergio Gomez, Matthew W. Hoffman, David Pfau, Tom Schaul, Brendan Shillingford, Nando de Freitas . [pdf] [code] Unsupervised Learning via Meta-Learning , (2019), Kyle Hsu, Sergey Levine, Chelsea Finn . [pdf] [code] Few-Shot Image Recognition by Predicting Parameters from Activations , (2018), Siyuan Qiao, Chenxi Liu, Wei Shen, Alan Yuille . [pdf] [code] One-Shot Imitation from Observing Humans via Domain-Adaptive Meta-Learning , (2018), Tianhe Yu, Chelsea Finn, Annie Xie, Sudeep Dasari, Pieter Abbeel, Sergey Levine , [pdf] [code] MetaGAN: An Adversarial Approach to Few-Shot Learning , (2018), ZHANG, Ruixiang and Che, Tong and Ghahramani, Zoubin and Bengio, Yoshua and Song, Yangqiu . [pdf] Fast Parameter Adaptation for Few-shot Image Captioning and Visual Question Answering ,(2018), Xuanyi Dong, Linchao Zhu, De Zhang, Yi Yang, Fei Wu . [pdf] CAML: Fast Context Adaptation via Meta-Learning , (2019), Luisa M Zintgraf, Kyriacos Shiarlis, Vitaly Kurin, Katja Hofmann, Shimon Whiteson . [pdf] Meta-Learning for Low-resource Natural Language Generation in Task-oriented Dialogue Systems , (2019), Fei Mi, Minlie Huang, Jiyong Zhang, Boi Faltings . [pdf] MIND: Model Independent Neural Decoder , (2019), Yihan Jiang, Hyeji Kim, Himanshu Asnani, Sreeram Kannan . [pdf] Toward Multimodal Model-Agnostic Meta-Learning , (2018), Risto Vuorio, Shao-Hua Sun, Hexiang Hu, Joseph J. Lim . [pdf] Alpha MAML: Adaptive Model-Agnostic Meta-Learning , (2019), Harkirat Singh Behl, At\u0131l\u0131m G\u00fcne\u015f Baydin, Philip H. S. Torr. [pdf] Online Meta-Learning , (2019), Chelsea Finn, Aravind Rajeswaran, Sham Kakade, Sergey Levine . [pdf]","title":"Model Agnostic Meta Learning"},{"location":"4%20Papers/1%20Papers%20and%20Code/#meta-reinforcement-learning","text":"Generalizing Skills with Semi-Supervised Reinforcement Learning , (2017), Chelsea Finn, Tianhe Yu, Justin Fu, Pieter Abbeel, Sergey Levine . [pdf] [code] Guided Meta-Policy Search , (2019), Russell Mendonca, Abhishek Gupta, Rosen Kralev, Pieter Abbeel, Sergey Levine, Chelsea Finn . [pdf] [code] End-to-End Robotic Reinforcement Learning without Reward Engineering , (2019), Avi Singh, Larry Yang, Kristian Hartikainen, Chelsea Finn, Sergey Levine . [pdf] [code] Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables , (2019), Kate Rakelly, Aurick Zhou, Deirdre Quillen, Chelsea Finn, Sergey Levine . [pdf] [code] Meta-Gradient Reinforcement Learning , (2018), Zhongwen Xu, Hado van Hasselt,David Silver . [pdf] Task-Agnostic Dynamics Priors for Deep Reinforcement Learning , (2019), Yilun Du, Karthik Narasimhan . [pdf] Meta Reinforcement Learning with Task Embedding and Shared Policy ,(2019), Lin Lan, Zhenguo Li, Xiaohong Guan, Pinghui Wang . [pdf] NoRML: No-Reward Meta Learning , (2019), Yuxiang Yang, Ken Caluwaerts, Atil Iscen, Jie Tan, Chelsea Finn . [pdf] Actor-Critic Algorithms for Constrained Multi-agent Reinforcement Learning , (2019), Raghuram Bharadwaj Diddigi, Sai Koti Reddy Danda, Prabuchandran K. J., Shalabh Bhatnagar . [pdf] Adaptive Guidance and Integrated Navigation with Reinforcement Meta-Learning , (2019), Brian Gaudet, Richard Linares, Roberto Furfaro . [pdf] Watch, Try, Learn: Meta-Learning from Demonstrations and Reward , (2019), Allan Zhou, Eric Jang, Daniel Kappler, Alex Herzog, Mohi Khansari, Paul Wohlhart, Yunfei Bai, Mrinal Kalakrishnan, Sergey Levine, Chelsea Finn . [pdf] Options as responses: Grounding behavioural hierarchies in multi-agent RL , (2019), Alexander Sasha Vezhnevets, Yuhuai Wu, Remi Leblond, Joel Z. Leibo . [pdf] Learning latent state representation for speeding up exploration , (2019), Giulia Vezzani, Abhishek Gupta, Lorenzo Natale, Pieter Abbeel . [pdf] Beyond Exponentially Discounted Sum: Automatic Learning of Return Function , (2019), Yufei Wang, Qiwei Ye, Tie-Yan Liu . [pdf] Learning Efficient and Effective Exploration Policies with Counterfactual Meta Policy , (2019), Ruihan Yang, Qiwei Ye, Tie-Yan Liu . [pdf] Dealing with Non-Stationarity in Multi-Agent Deep Reinforcement Learning , (2019), Georgios Papoudakis, Filippos Christianos, Arrasy Rahman, Stefano V. Albrecht . [pdf] Learning to Discretize: Solving 1D Scalar Conservation Laws via Deep Reinforcement Learning , (2019), Yufei Wang, Ziju Shen, Zichao Long, Bin Dong . [[pdf]]","title":"Meta Reinforcement Learning"},{"location":"4%20Papers/1%20Papers%20and%20Code/#other-uncategorized","text":"Grounded Language Learning Fast and Slow by Hill, Felix and Tieleman, Olivier and von Glehn, Tamara and Wong, Nathaniel and Merzic, Hamza and Clark, Stephen http://arxiv.org/abs/2009.01719 Sparse Meta Networks for Sequential Adaptation and its Application to Adaptive Language Modelling by Munkhdalai, Tsendsuren http://arxiv.org/abs/2009.01803 Learning with Differentiable Perturbed Optimizers by Berthet, Quentin and Blondel, Mathieu and Teboul, Olivier and Cuturi, Marco and Vert, Jean-Philippe and Bach, Francis http://arxiv.org/abs/2002.08676 What is being transferred in transfer learning? by Neyshabur, Behnam and Sedghi, Hanie and Zhang, Chiyuan http://arxiv.org/abs/2008.11687 On modulating the gradient for meta-learning by Simon, Christian and Koniusz, Piotr and Nock, Richard and Harandi, Mehrtash https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123530545.pdf Meta-Learning with Shared Amortized Variational Inference by Iakovleva, Ekaterina and Verbeek, Jakob and Alahari, Karteek http://arxiv.org/abs/2008.12037 learn2learn: A Library for Meta-Learning Research by Arnold, S\u00e9bastien M R and Mahajan, Praateek and Datta, Debajyoti and Bunner, Ian and Zarkias, Konstantinos Saitas http://arxiv.org/abs/2008.12284 A Universal Representation Transformer Layer for Few-Shot Image Classification by Liu, Lu and Hamilton, William and Long, Guodong and Jiang, Jing and Larochelle, Hugo http://arxiv.org/abs/2006.11702 Safe Model-Based Meta-Reinforcement Learning: A Sequential Exploration-Exploitation Framework by Lew, Thomas and Sharma, Apoorva and Harrison, James and Pavone, Marco http://arxiv.org/abs/2008.11700 Learning to Learn in a Semi-Supervised Fashion by Chen, Yun-Chun and Chou, Chao-Te and Wang, Yu-Chiang Frank http://arxiv.org/abs/2008.11203 The Advantage of Conditional Meta-Learning for Biased Regularization and Fine-Tuning by Denevi, Giulia and Pontil, Massimiliano and Ciliberto, Carlo http://arxiv.org/abs/2008.10857 Adaptive Multi-level Hyper-gradient Descent by Jie, Renlong and Gao, Junbin and Vasnev, Andrey and Tran, Minh-Ngoc http://arxiv.org/abs/2008.07277 Few-Shot Image Classification via Contrastive Self-Supervised Learning by Li, Jianyi and Liu, Guizhong http://arxiv.org/abs/2008.09942 Does MAML really want feature reuse only? by Oh, Jaehoon and Yoo, Hyungjun and Kim, Changhwan and Yun, Se-Young http://arxiv.org/abs/2008.08882 Meta Learning MPC using Finite-Dimensional Gaussian Process Approximations by Arcari, Elena and Carron, Andrea and Zeilinger, Melanie N http://arxiv.org/abs/2008.05984 Offline Meta-Reinforcement Learning with Advantage Weighting by Mitchell, Eric and Rafailov, Rafael and Peng, Xue Bin and Levine, Sergey and Finn, Chelsea http://arxiv.org/abs/2008.06043 Explore then Execute: Adapting without Rewards via Factorized Meta-Reinforcement Learning by Liu, Evan Zheran and Raghunathan, Aditi and Liang, Percy and Finn, Chelsea http://arxiv.org/abs/2008.02790 Offline Meta Reinforcement Learning by Dorfman, Ron and Tamar, Aviv http://arxiv.org/abs/2008.02598 Few-Shot Learning via Learning the Representation, Provably by Du, Simon S and Hu, Wei and Kakade, Sham M and Lee, Jason D and Lei, Qi http://arxiv.org/abs/2002.09434 Multi-Task Reinforcement Learning as a Hidden-Parameter Block MDP by Zhang, Amy and Sodhani, Shagun and Khetarpal, Khimya and Pineau, Joelle http://arxiv.org/abs/2007.07206 CAMPs: Learning Context-Specific Abstractions for Efficient Planning in Factored MDPs by Chitnis, Rohan and Silver, Tom and Kim, Beomjoon and Kaelbling, Leslie Pack and Lozano-Perez, Tomas http://arxiv.org/abs/2007.13202 Unsupervised Learning of Visual Features by Contrasting Cluster Assignments by Caron, Mathilde and Misra, Ishan and Mairal, Julien and Goyal, Priya and Bojanowski, Piotr and Joulin, Armand http://arxiv.org/abs/2006.09882 MiCo: Mixup Co-Training for Semi-Supervised Domain Adaptation by Yang, Luyu and Wang, Yan and Gao, Mingfei and Shrivastava, Abhinav and Weinberger, Kilian Q and Chao, Wei-Lun and Lim, Ser-Nam http://arxiv.org/abs/2007.12684 Adaptive Task Sampling for Meta-Learning by Liu, Chenghao and Wang, Zhihao and Sahoo, Doyen and Fang, Yuan and Zhang, Kun and Hoi, Steven C H http://arxiv.org/abs/2007.08735 Discovering Reinforcement Learning Algorithms by Oh, Junhyuk and Hessel, Matteo and Czarnecki, Wojciech M and Xu, Zhongwen and van Hasselt, Hado and Singh, Satinder and Silver, David http://arxiv.org/abs/2007.08794 On the Outsized Importance of Learning Rates in Local Update Methods by Charles, Zachary and Kone{\\v c}n{\\'y}, Jakub http://arxiv.org/abs/2007.00878 Global Convergence and Induced Kernels of Gradient-Based Meta-Learning with Neural Nets by Wang, Haoxiang and Sun, Ruoyu and Li, Bo http://arxiv.org/abs/2006.14606 On the Iteration Complexity of Hypergradient Computation by Grazzi, Riccardo and Franceschi, Luca and Pontil, Massimiliano and Salzo, Saverio http://arxiv.org/abs/2006.16218 On the Outsized Importance of Learning Rates in Local Update Methods by Charles, Zachary and Kone{\\v c}n{\\'y}, Jakub http://arxiv.org/abs/2007.00878 Meta-SAC: Auto-tune the Entropy Temperature of Soft Actor-Critic via Metagradient by Wang, Yufei and Ni, Tianwei http://arxiv.org/abs/2007.01932 Meta Learning in the Continuous Time Limit by Xu, Ruitu and Chen, Lin and Karbasi, Amin http://arxiv.org/abs/2006.10921 Expert Training: Task Hardness Aware Meta-Learning for Few-Shot Classification by Zhou, Yucan and Wang, Yu and Cai, Jianfei and Zhou, Yu and Hu, Qinghua and Wang, Weiping http://arxiv.org/abs/2007.06240 MTL2L: A Context Aware Neural Optimiser by Kuo, Nicholas I-Hsien and Harandi, Mehrtash and Fourrier, Nicolas and Walder, Christian and Ferraro, Gabriela and Suominen, Hanna http://arxiv.org/abs/2007.09343 Navigating the Trade-Off between Multi-Task Learning and Learning to Multitask in Deep Neural Networks by Ravi, Sachin and Musslick, Sebastian and Hamin, Maia and Willke, Theodore L and Cohen, Jonathan D http://arxiv.org/abs/2007.10527 Balanced Meta-Softmax for Long-Tailed Visual Recognition by Ren, Jiawei and Yu, Cunjun and Sheng, Shunan and Ma, Xiao and Zhao, Haiyu and Yi, Shuai and Li, Hongsheng http://arxiv.org/abs/2007.10740 CrossTransformers: spatially-aware few-shot transfer by Doersch, Carl and Gupta, Ankush and Zisserman, Andrew http://arxiv.org/abs/2007.11498 Meta-Learning a Dynamical Language Model by Wolf, Thomas and Chaumond, Julien and Delangue, Clement http://arxiv.org/abs/1803.10631 Meta-Learning Requires Meta-Augmentation by Rajendran, Janarthanan and Irpan, Alex and Jang, Eric http://arxiv.org/abs/2007.05549 Adaptive Risk Minimization: A Meta-Learning Approach for Tackling Group Shift by Zhang, Marvin and Marklund, Henrik and Gupta, Abhishek and Levine, Sergey and Finn, Chelsea http://arxiv.org/abs/2007.02931 Meta-Learning Symmetries by Reparameterization by Zhou, Allan and Knowles, Tom and Finn, Chelsea http://arxiv.org/abs/2007.02933 Adaptive Risk Minimization: A Meta-Learning Approach for Tackling Group Shift by Zhang, Marvin and Marklund, Henrik and Gupta, Abhishek and Levine, Sergey and Finn, Chelsea http://arxiv.org/abs/2007.02931 A Brief Look at Generalization in Visual Meta-Reinforcement Learning by Alver, Safa and Precup, Doina http://arxiv.org/abs/2006.07262 Learning Representations by Stochastic Meta-Gradient Descent in Neural Networks by Veeriah, Vivek and Zhang, Shangtong and Sutton, Richard S http://arxiv.org/abs/1612.02879 PACOH: Bayes-Optimal Meta-Learning with PAC-Guarantees by Rothfuss, Jonas and Fortuin, Vincent and Krause, Andreas http://arxiv.org/abs/2002.05551 Meta-Meta-Classification for One-Shot Learning by Chowdhury, Arkabandhu and Chaudhari, Dipak and Chaudhuri, Swarat and Jermaine, Chris http://arxiv.org/abs/2004.08083 Relatedness Measures to Aid the Transfer of Building Blocks among Multiple Tasks by Nguyen, Trung B and Browne, Will N and Zhang, Mengjie http://arxiv.org/abs/2005.03947 Information-Theoretic Generalization Bounds for Meta-Learning and Applications by Jose, Sharu Theresa and Simeone, Osvaldo http://arxiv.org/abs/2005.04372 On Learning Intrinsic Rewards for Policy Gradient Methods by Zheng, Zeyu and Oh, Junhyuk and Singh, Satinder http://arxiv.org/abs/1804.06459 A Sample Complexity Separation between Non-Convex and Convex Meta-Learning by Saunshi, Nikunj and Zhang, Yi and Khodak, Mikhail and Arora, Sanjeev http://arxiv.org/abs/2002.11172 Bayesian Online Meta-Learning with Laplace Approximation by Yap, Pau Ching and Ritter, Hippolyt and Barber, David http://arxiv.org/abs/2005.00146 Meta-Reinforcement Learning for Robotic Industrial Insertion Tasks by Schoettler, Gerrit and Nair, Ashvin and Ojea, Juan Aparicio and Levine, Sergey and Solowjow, Eugen http://arxiv.org/abs/2004.14404 Continual Deep Learning by Functional Regularisation of Memorable Past by Pan, Pingbo and Swaroop, Siddharth and Immer, Alexander and Eschenhagen, Runa and Turner, Richard E and Khan, Mohammad Emtiyaz http://arxiv.org/abs/2004.14070 Jelly Bean World: A Testbed for Never-Ending Learning by Platanios, Emmanouil Antonios and Saparov, Abulhair and Mitchell, Tom https://openreview.net/pdf?id=Byx_YAVYPH Encouraging behavioral diversity in evolutionary robotics: an empirical study by Mouret, J-B and Doncieux, S http://dx.doi.org/10.1162/EVCO_a_00048 Defining Benchmarks for Continual Few-Shot Learning by Antoniou, Antreas and Patacchiola, Massimiliano and Ochal, Mateusz and Storkey, Amos http://arxiv.org/abs/2004.11967 Emergent Real-World Robotic Skills via Unsupervised Off-Policy Reinforcement Learning by Sharma, Archit and Ahn, Michael and Levine, Sergey and Kumar, Vikash and Hausman, Karol and Gu, Shixiang http://arxiv.org/abs/2004.12974 Empirical Bayes Transductive Meta-Learning with Synthetic Gradients by Hu, Shell Xu and Moreno, Pablo G and Xiao, Yang and Shen, Xi and Obozinski, Guillaume and Lawrence, Neil D and Damianou, Andreas http://arxiv.org/abs/2004.12696 Evolving Inborn Knowledge For Fast Adaptation in Dynamic POMDP Problems by Ben-Iwhiwhu, Eseoghene and Ladosz, Pawel and Dick, Jeffery and Chen, Wen-Hua and Pilly, Praveen and Soltoggio, Andrea http://arxiv.org/abs/2004.12846 Meta-World: A Benchmark and Evaluation for Multi-Task and Meta Reinforcement Learning by Yu, Tianhe and Quillen, Deirdre and He, Zhanpeng and Julian, Ryan and Hausman, Karol and Finn, Chelsea and Levine, Sergey http://arxiv.org/abs/1910.10897 Meta reinforcement learning as task inference by Humplik, Jan and Galashov, Alexandre and Hasenclever, Leonard and Ortega, Pedro A and Teh, Yee Whye and Heess, Nicolas http://arxiv.org/abs/1905.06424 Meta-Gradient Reinforcement Learning by Xu, Zhongwen and van Hasselt, Hado and Silver, David http://arxiv.org/abs/1805.09801 Self-Paced Deep Reinforcement Learning by Klink, Pascal and D'Eramo, Carlo and Peters, Jan and Pajarinen, Joni http://arxiv.org/abs/2004.11812 Scheduling the Learning Rate Via Hypergradients: New Insights and a New Algorithm by Donini, Michele and Franceschi, Luca and Majumder, Orchid and Pontil, Massimiliano and Frasconi, Paolo https://openreview.net/pdf?id=Ske6qJSKPH Learning Stabilizable Nonlinear Dynamics with Contraction-Based Regularization by Singh, Sumeet and Richards, Spencer M and Sindhwani, Vikas and Slotine, Jean-Jacques E and Pavone, Marco http://arxiv.org/abs/1907.13122 A Comprehensive Overview and Survey of Recent Advances in Meta-Learning by Peng, Huimin http://arxiv.org/abs/2004.11149 Learning a Formula of Interpretability to Learn Interpretable Formulas by Virgolin, Marco and De Lorenzo, Andrea and Medvet, Eric and Randone, Francesca http://arxiv.org/abs/2004.11170 Model-Based Meta-Reinforcement Learning for Flight with Suspended Payloads by Belkhale, Suneel and Li, Rachel and Kahn, Gregory and McAllister, Rowan and Calandra, Roberto and Levine, Sergey http://arxiv.org/abs/2004.11345 Frustratingly Simple Few-Shot Object Detection by Wang, Xin and Huang, Thomas E and Darrell, Trevor and Gonzalez, Joseph E and Yu, Fisher http://arxiv.org/abs/2003.06957 Meta Pseudo Labels by Pham, Hieu and Xie, Qizhe and Dai, Zihang and Le, Quoc V http://arxiv.org/abs/2003.10580 0e56da12-a2f0-4288-b745-c15deec9183a by Unknown http://learn2learn.net Finding online neural update rules by learning to remember by Gregor, Karol http://arxiv.org/abs/2003.03124 A New Meta-Baseline for Few-Shot Learning by Chen, Yinbo and Wang, Xiaolong and Liu, Zhuang and Xu, Huijuan and Darrell, Trevor http://arxiv.org/abs/2003.04390 Learning to be Global Optimizer by Zhang, Haotian and Sun, Jianyong and Xu, Zongben http://arxiv.org/abs/2003.04521 Scalable Multi-Task Imitation Learning with Autonomous Improvement by Singh, Avi and Jang, Eric and Irpan, Alexander and Kappler, Daniel and Dalal, Murtaza and Levine, Sergey and Khansari, Mohi and Finn, Chelsea http://arxiv.org/abs/2003.02636 Meta-learning for mixed linear regression by Kong, Weihao and Somani, Raghav and Song, Zhao and Kakade, Sham and Oh, Sewoong http://arxiv.org/abs/2002.08936 Provable Meta-Learning of Linear Representations by Tripuraneni, Nilesh and Jin, Chi and Jordan, Michael I http://arxiv.org/abs/2002.11684 Learning to Continually Learn by Beaulieu, Shawn and Frati, Lapo and Miconi, Thomas and Lehman, Joel and Stanley, Kenneth O and Clune, Jeff and Cheney, Nick http://arxiv.org/abs/2002.09571 PACOH: Bayes-Optimal Meta-Learning with PAC-Guarantees by Rothfuss, Jonas and Fortuin, Vincent and Krause, Andreas http://arxiv.org/abs/2002.05551 Incremental Learning for Metric-Based Meta-Learners by Liu, Qing and Majumder, Orchid and Ravichandran, Avinash and Bhotika, Rahul and Soatto, Stefano http://arxiv.org/abs/2002.04162 Hyper-Meta Reinforcement Learning with Sparse Reward by Hua, Yun and Wang, Xiangfeng and Jin, Bo and Li, Wenhao and Yan, Junchi and He, Xiaofeng and Zha, Hongyuan http://arxiv.org/abs/2002.04238 Meta-Learning across Meta-Tasks for Few-Shot Learning by Fei, Nanyi and Lu, Zhiwu and Gao, Yizhao and Tian, Jia and Xiang, Tao and Wen, Ji-Rong http://arxiv.org/abs/2002.04274 Distribution-Agnostic Model-Agnostic Meta-Learning by Collins, Liam and Mokhtari, Aryan and Shakkottai, Sanjay http://arxiv.org/abs/2002.04766 Provably Convergent Policy Gradient Methods for Model-Agnostic Meta-Reinforcement Learning by Fallah, Alireza and Mokhtari, Aryan and Ozdaglar, Asuman http://arxiv.org/abs/2002.05135 Meta-learning framework with applications to zero-shot time-series forecasting by Oreshkin, Boris N and Carpov, Dmitri and Chapados, Nicolas and Bengio, Yoshua http://arxiv.org/abs/2002.02887 A Loss-Function for Causal Machine-Learning by Yang, I-Sheng http://arxiv.org/abs/2001.00629 Self-Tuning Deep Reinforcement Learning by Zahavy, Tom and Xu, Zhongwen and Veeriah, Vivek and Hessel, Matteo and Van Hasslet, Hado and Silver, David and Singh, Satinder http://arxiv.org/abs/2002.12928 Learning Adaptive Loss for Robust Learning with Noisy Labels by Shu, Jun and Zhao, Qian and Chen, Keyu and Xu, Zongben and Meng, Deyu http://arxiv.org/abs/2002.06482 A Structured Prediction Approach for Conditional Meta-Learning by Wang, Ruohan and Demiris, Yiannis and Ciliberto, Carlo http://arxiv.org/abs/2002.08799 Curriculum in Gradient-Based Meta-Reinforcement Learning by Mehta, Bhairav and Deleu, Tristan and Raparthy, Sharath Chandra and Pal, Chris J and Paull, Liam http://arxiv.org/abs/2002.07956 Multi-Step Model-Agnostic Meta-Learning: Convergence and Improved Algorithms by Ji, Kaiyi and Yang, Junjie and Liang, Yingbin http://arxiv.org/abs/2002.07836 Local Nonparametric Meta-Learning by Goo, Wonjoon and Niekum, Scott http://arxiv.org/abs/2002.03272 Revisiting Meta-Learning as Supervised Learning by Chao, Wei-Lun and Ye, Han-Jia and Zhan, De-Chuan and Campbell, Mark and Weinberger, Kilian Q http://arxiv.org/abs/2002.00573 SimpleShot: Revisiting Nearest-Neighbor Classification for Few-Shot Learning by Wang, Yan and Chao, Wei-Lun and Weinberger, Kilian Q and van der Maaten, Laurens http://arxiv.org/abs/1911.04623 Fast and Generalized Adaptation for Few-Shot Learning by Song, Liang and Liu, Jinlu and Qin, Yongqiang http://arxiv.org/abs/1911.10807 Meta-Learning without Memorization by Yin, Mingzhang and Tucker, George and Zhou, Mingyuan and Levine, Sergey and Finn, Chelsea http://arxiv.org/abs/1912.03820 Your Classifier is Secretly an Energy Based Model and You Should Treat it Like One by Grathwohl, Will and Wang, Kuan-Chieh and Jacobsen, J{\\\"o}rn-Henrik and Duvenaud, David and Norouzi, Mohammad and Swersky, Kevin http://arxiv.org/abs/1912.03263 MAME : Model-Agnostic Meta-Exploration by Gurumurthy, Swaminathan and Kumar, Sumit and Sycara, Katia http://arxiv.org/abs/1911.04024 Constructing Multiple Tasks for Augmentation: Improving Neural Image Classification With K-means Features by Gui, Tao and Qing, Lizhi and Zhang, Qi and Ye, Jiacheng and Yan, Hang and Fei, Zichu and Huang, Xuanjing http://arxiv.org/abs/1911.07518 Meta Adaptation using Importance Weighted Demonstrations by Lekkala, Kiran and Abu-El-Haija, Sami and Itti, Laurent http://arxiv.org/abs/1911.10322 VIABLE: Fast Adaptation via Backpropagating Learned Loss by Feng, Leo and Zintgraf, Luisa and Peng, Bei and Whiteson, Shimon http://arxiv.org/abs/1911.13159 Decoupling Adaptation from Modeling with Meta-Optimizers for Meta Learning by Arnold, S{\\'e}bastien M R and Iqbal, Shariq and Sha, Fei http://arxiv.org/abs/1910.13603 TADAM: Task dependent adaptive metric for improved few-shot learning by Oreshkin, Boris and Rodr{\\'\\i}guez L{\\'o}pez, Pau and Lacoste, Alexandre http://papers.nips.cc/paper/7352-tadam-task-dependent-adaptive-metric-for-improved-few-shot-learning.pdf Learning to Few-Shot Learn Across Diverse Natural Language Classification Tasks by Bansal, Trapit and Jha, Rishikesh and McCallum, Andrew http://arxiv.org/abs/1911.03863 Optimizing Millions of Hyperparameters by Implicit Differentiation by Lorraine, Jonathan and Vicol, Paul and Duvenaud, David http://arxiv.org/abs/1911.02590 Meta-data: Characterization of Input Features for Meta-learning by Castiello, Ciro and Castellano, Giovanna and Fanelli, Anna Maria http://dx.doi.org/10.1007/11526018_45 Meta-Learning for Low-resource Natural Language Generation in Task-oriented Dialogue Systems by Mi, Fei and Huang, Minlie and Zhang, Jiyong and Faltings, Boi http://arxiv.org/abs/1905.05644 Domain Generalization via Model-Agnostic Learning of Semantic Features by Dou, Qi and Castro, Daniel C and Kamnitsas, Konstantinos and Glocker, Ben http://arxiv.org/abs/1910.13580 Hierarchical Expert Networks for Meta-Learning by Hihn, Heinke and Braun, Daniel A http://arxiv.org/abs/1911.00348 Online Meta-Learning on Non-convex Setting by Zhuang, Zhenxun and Wang, Yunlong and Yu, Kezi and Lu, Songtao http://arxiv.org/abs/1910.10196 Learning-to-Learn Stochastic Gradient Descent with Biased Regularization by Denevi, Giulia and Ciliberto, Carlo and Grazzi, Riccardo and Pontil, Massimiliano http://arxiv.org/abs/1903.10399 Provable Guarantees for Gradient-Based Meta-Learning by Khodak, Mikhail and Balcan, Maria-Florina and Talwalkar, Ameet http://arxiv.org/abs/1902.10644 The TCGA Meta-Dataset Clinical Benchmark by Samiei, Mandana and W{\\\"u}rfl, Tobias and Deleu, Tristan and Weiss, Martin and Dutil, Francis and Fevens, Thomas and Boucher, Genevi{`e}ve and Lemieux, Sebastien and Cohen, Joseph Paul http://arxiv.org/abs/1910.08636 VariBAD: A Very Good Method for Bayes-Adaptive Deep RL via Meta-Learning by Zintgraf, Luisa and Shiarlis, Kyriacos and Igl, Maximilian and Schulze, Sebastian and Gal, Yarin and Hofmann, Katja and Whiteson, Shimon http://arxiv.org/abs/1910.08348 Meta-Transfer Learning through Hard Tasks by Sun, Qianru and Liu, Yaoyao and Chen, Zhaozheng and Chua, Tat-Seng and Schiele, Bernt http://arxiv.org/abs/1910.03648 Model-Agnostic Meta-Learning using Runge-Kutta Methods by Im, Daniel Jiwoong and Jiang, Yibo and Verma, Nakul http://arxiv.org/abs/1910.07368 Improving Generalization in Meta Reinforcement Learning using Learned Objectives by Kirsch, Louis and van Steenkiste, Sjoerd and Schmidhuber, J{\\\"u}rgen http://arxiv.org/abs/1910.04098 Generalized Inner Loop Meta-Learning by Grefenstette, Edward and Amos, Brandon and Yarats, Denis and Htut, Phu Mon and Molchanov, Artem and Meier, Franziska and Kiela, Douwe and Cho, Kyunghyun and Chintala, Soumith http://arxiv.org/abs/1910.01727 Is Fast Adaptation All You Need? by Javed, Khurram and Yao, Hengshuai and White, Martha http://arxiv.org/abs/1910.01705 Deep Reinforcement Learning for Single-Shot Diagnosis and Adaptation in Damaged Robots by Verma, Shresth and Nair, Haritha S and Agarwal, Gaurav and Dhar, Joydip and Shukla, Anupam http://arxiv.org/abs/1910.01240 ES-MAML: Simple Hessian-Free Meta Learning by Song, Xingyou and Gao, Wenbo and Yang, Yuxiang and Choromanski, Krzysztof and Pacchiano, Aldo and Tang, Yunhao http://arxiv.org/abs/1910.01215 Meta-Q-Learning by Fakoor, Rasool and Chaudhari, Pratik and Soatto, Stefano and Smola, Alexander J http://arxiv.org/abs/1910.00125 Efficient meta reinforcement learning via meta goal generation by Fu, Haotian and Tang, Hongyao and Hao, Jianye http://arxiv.org/abs/1909.13607 Chameleon: Learning Model Initializations Across Tasks With Different Schemas by Brinkmeyer, Lukas and Drumond, Rafael Rego and Scholz, Randolf and Grabocka, Josif and Schmidt-Thieme, Lars http://arxiv.org/abs/1909.13576 Learning Fast Adaptation with Meta Strategy Optimization by Yu, Wenhao and Tan, Jie and Bai, Yunfei and Coumans, Erwin and Ha, Sehoon http://arxiv.org/abs/1909.12995 Meta-Inverse Reinforcement Learning with Probabilistic Context Variables by Yu, Lantao and Yu, Tianhe and Finn, Chelsea and Ermon, Stefano http://arxiv.org/abs/1909.09314 Modular Meta-Learning with Shrinkage by Chen, Yutian and Friesen, Abram L and Behbahani, Feryal and Budden, David and Hoffman, Matthew W and Doucet, Arnaud and de Freitas, Nando http://arxiv.org/abs/1909.05557 Loaded DiCE: Trading off Bias and Variance in Any-Order Score Function Estimators for Reinforcement Learning by Farquhar, Gregory and Whiteson, Shimon and Foerster, Jakob http://arxiv.org/abs/1909.10549 Rapid Learning or Feature Reuse? Towards Understanding the Effectiveness of MAML by Raghu, Aniruddh and Raghu, Maithra and Bengio, Samy and Vinyals, Oriol http://arxiv.org/abs/1909.09157 Meta-Learning by Vanschoren, Joaquin https://doi.org/10.1007/978-3-030-05318-5_2 Understanding Short-Horizon Bias in Stochastic Meta-Optimization by Wu, Yuhuai and Ren, Mengye and Liao, Renjie and Grosse, Roger http://arxiv.org/abs/1803.02021 On First-Order Meta-Learning Algorithms by Nichol, Alex and Achiam, Joshua and Schulman, John http://arxiv.org/abs/1803.02999 Towards Understanding Generalization in Gradient-Based Meta-Learning by Guiroy, Simon and Verma, Vikas and Pal, Christopher http://arxiv.org/abs/1907.07287 They empirically study the landscape of fast-adaptation in MAML. The most interesting claim is that when meta-overfitting, the loss landscape becomes flatter on test tasks. On the Convergence Theory of Gradient-Based Model-Agnostic Meta-Learning Algorithms by Fallah, Alireza and Mokhtari, Aryan and Ozdaglar, Asuman http://arxiv.org/abs/1908.10400 Learning to Learn with Gradients by Finn, Chelsea http://learn2learn.net Acetylcholine and memory by Hasselmo, M E and Bower, J M https://www.ncbi.nlm.nih.gov/pubmed/7688162 A THEORY OF META-LEARNING AND PRINCIPLES OF FACILITATION: AN ORGANISMIC PERSPECTIVE by Maudsley, Donald B https://uosc.primo.exlibrisgroup.com/discovery/fulldisplay?docid=proquest302999651&context=PC&vid=01USC_INST:01USC&lang=en&search_scope=MyInst_and_CI&adaptor=Primo%20Central&tab=Everything&mode=Basic THE ROLE OF METALEARNING IN STUDY PROCESSES by Biggs, J B http://doi.wiley.com/10.1111/j.2044-8279.1985.tb02625.x Understanding and correcting pathologies in the training of learned optimizers by Metz, Luke and Maheswaranathan, Niru and Nixon, Jeremy and Daniel Freeman, C and Sohl-Dickstein, Jascha http://arxiv.org/abs/1810.10180 Provides many tricks (e.g. split train batch for model \\& opt, average gradient estimators) for training differentiable optimizers online. They also have a couple of interesting observations specific to recurrent optimizers. Learned Optimizers that Scale and Generalize by Wichrowska, Olga and Maheswaranathan, Niru and Hoffman, Matthew W and Colmenarejo, Sergio Gomez and Denil, Misha and de Freitas, Nando and Sohl-Dickstein, Jascha http://arxiv.org/abs/1703.04813 Using learned optimizers to make models robust to input noise by Metz, Luke and Maheswaranathan, Niru and Shlens, Jonathon and Sohl-Dickstein, Jascha and Cubuk, Ekin D http://arxiv.org/abs/1906.03367 Learning to Optimize Neural Nets by Li, Ke and Malik, Jitendra http://arxiv.org/abs/1703.00441 Meta-Learning Update Rules for Unsupervised Representation Learning by Metz, Luke and Maheswaranathan, Niru and Cheung, Brian and Sohl-Dickstein, Jascha http://arxiv.org/abs/1804.00222 Learning to Optimize by Li, Ke and Malik, Jitendra http://arxiv.org/abs/1606.01885 Learning to learn by gradient descent by gradient descent by Andrychowicz, M and Denil, M and Gomez, S http://learn2learn.net Online Learning Rate Adaptation with Hypergradient Descent by Baydin, Atilim Gunes and Cornish, Robert and Rubio, David Martinez and Schmidt, Mark and Wood, Frank http://arxiv.org/abs/1703.04782 They adapt the learning rate of SGD by differentiating the loss of the next parameters w.r.t. the learning rate. They observe that the gradient of the learning rate is simply the inner product of the last two gradients. Adapting Bias by Gradient Descent: An Incremental Version of Delta-Bar-Delta by Sutton, Richard S http://dx.doi.org/ What's mostly interesting in this paper is the adaptation of delta-bar-delta to the online scenario. The idea of representing the learning rate as an exponential is nice. Also nice to see that the derivation suggests a full-matrix adaptive case. Gain adaptation beats least squares by Sutton, Richard S https://pdfs.semanticscholar.org/7ec8/876f219b3b3d5c894a3f395c89c382029cc5.pdf This paper extends IDBD as algorithms K1 and K2, but from my quick read, it isn't clear what's the motivation for those modifications. (Seems to work in a `normalized space'', {\\ a} la natural gradient ?)They do work better. Local Gain Adaptation in Stochastic Gradient Descent by Schraudolph, Nicol N https://pdfs.semanticscholar.org/31a0/b86c3cd04e6539626f34b80db7ff79d23f40.pdf This algorithm extends IDBD (Sutton) to the non-linear setting. Interestingly, they have a few brief discussionson the difficulties to optimize at the meta-level. (c.f. Meta-level conditioning section.) Overall, it shines light on the ground idea behind IDBD. TIDBD: Adapting Temporal-difference Step-sizes Through Stochastic Meta-descent by Kearney, Alex and Veeriah, Vivek and Travnik, Jaden B and Sutton, Richard S and Pilarski, Patrick M http://arxiv.org/abs/1804.03334 Increased rates of convergence through learning rate adaptation by Jacobs, Robert A http://www.sciencedirect.com/science/article/pii/0893608088900032 This paper argues that we need (at least) four ingredients to improve optimization of connectionist networks: 1. each parameter has its own stepsize, 2. stepsizes vary over time, 3. if consecutive gradients of a stepsize have the same sign, the stepsize should be increased, 4. conversely, if the stepsize should be decreased if its gradients have opposite signs. It also proposes to use two improvements: 1. Momentum (i.e. Polyak's heavyball), 2. delta-bar-delta (i.e. learning the stepsize). It has an interesting comment on the difficulty of learning the stepsize, and therefore comes up with a ``hack'' that outperforms momentum. Meta-descent for Online, Continual Prediction by Jacobsen, Andrew and Schlegel, Matthew and Linke, Cameron and Degris, Thomas and White, Adam and White, Martha http://arxiv.org/abs/1907.07751 The idea is to learn the learning rate so as to minimize the norm of the gradient. They argue that for the continual learning setting, this forces the algorithm to stay ``as stable as possible''. No theorems, small-scale (but interesting) experiments. Adaptation of learning rate parameters by Sutton, Rich http://learn2learn.net Gradient-Based Meta-Learning with Learned Layerwise Metric and Subspace by Lee, Yoonho and Choi, Seungjin http://arxiv.org/abs/1801.05558 Meta-Learning with Warped Gradient Descent by Flennerhag, Sebastian and Rusu, Andrei A and Pascanu, Razvan and Yin, Hujun and Hadsell, Raia http://arxiv.org/abs/1909.00025 Meta-Learning via Learned Loss by Chebotar, Yevgen and Molchanov, Artem and Bechtle, Sarah and Righetti, Ludovic and Meier, Franziska and Sukhatme, Gaurav http://arxiv.org/abs/1906.05374 They learn the loss as a NN, and that loss's objective is to maximize the sum of rewards. It is provided a bunch of things, including inputs, outputs, goals. Meta-Curvature by Park, Eunbyung and Oliva, Junier B http://arxiv.org/abs/1902.03356 Alpha MAML: Adaptive Model-Agnostic Meta-Learning by Behl, Harkirat Singh and Baydin, At{\\i}l{\\i}m G{\\\"u}ne{\\c s} and Torr, Philip H S http://arxiv.org/abs/1905.07435 They combine hypergradient and MAML: adapt all learning rates at all times. Meta-SGD: Learning to Learn Quickly for Few-Shot Learning by Li, Zhenguo and Zhou, Fengwei and Chen, Fei and Li, Hang http://arxiv.org/abs/1707.09835 ProMP: Proximal Meta-Policy Search by Rothfuss, Jonas and Lee, Dennis and Clavera, Ignasi and Asfour, Tamim and Abbeel, Pieter http://arxiv.org/abs/1810.06784 Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks by Finn, Chelsea and Abbeel, Pieter and Levine, Sergey http://learn2learn.net Optimization as a model for few-shot learning by Ravi, Sachin and Larochelle, Hugo https://openreview.net/pdf?id=rJY0-Kcll Fast Context Adaptation via Meta-Learning by Zintgraf, Luisa M and Shiarlis, Kyriacos and Kurin, Vitaly and Hofmann, Katja and Whiteson, Shimon http://arxiv.org/abs/1810.03642 Meta-Learning with Implicit Gradients by Rajeswaran, Aravind and Finn, Chelsea and Kakade, Sham and Levine, Sergey http://arxiv.org/abs/1909.04630 Natural Neural Networks by Desjardins, Guillaume and Simonyan, Karen and Pascanu, Razvan and Kavukcuoglu, Koray http://dl.acm.org/citation.cfm?id=2969442.2969471 A Baseline for Few-Shot Image Classification by Dhillon, Guneet S and Chaudhari, Pratik and Ravichandran, Avinash and Soatto, Stefano http://arxiv.org/abs/1909.02729 A CLOSER LOOK AT FEW-SHOT CLASSIFICATION by Chen, Wei-Yu and Liu, Yen-Cheng and Kira, Zsolt https://openreview.net/pdf?id=HkxLXnAcFQ Suggests that meta-learning papers haven't been tested against classical baselines. When considering those baselines, they perform better than many of the recent meta-learning techniques. Meta-learning with differentiable closed-form solvers by Bertinetto, Luca and Henriques, Joao F and Torr, Philip and Vedaldi, Andrea https://openreview.net/forum?id=HyxnZh0ct7 Uncertainty in Model-Agnostic Meta-Learning using Variational Inference by Nguyen, Cuong and Do, Thanh-Toan and Carneiro, Gustavo http://arxiv.org/abs/1907.11864 Meta-Reinforcement Learning of Structured Exploration Strategies by Gupta, Abhishek and Mendonca, Russell and Liu, Yuxuan and Abbeel, Pieter and Levine, Sergey http://arxiv.org/abs/1802.07245 Metalearned Neural Memory by Munkhdalai, Tsendsuren and Sordoni, Alessandro and Wang, Tong and Trischler, Adam http://arxiv.org/abs/1907.09720 Accelerated Stochastic Approximation by Kesten, Harry https://projecteuclid.org/euclid.aoms/1177706705 Meta-Learning for Black-box Optimization by Vishnu, T V and Malhotra, Pankaj and Narwariya, Jyoti and Vig, Lovekesh and Shroff, Gautam http://arxiv.org/abs/1907.06901 They essentially extend the recurrent meta-learning framework in a few ways: 1. Use regret instead of objective improvement as meta-learning objective. 2. Normalize the objective so as to make it play nice with LSTMs. 3. Incorporate domain-constraints, so that the LSTM always outputs feasible solutions. All are described in page 3. Task Agnostic Continual Learning via Meta Learning by He, Xu and Sygnowski, Jakub and Galashov, Alexandre and Rusu, Andrei A and Teh, Yee Whye and Pascanu, Razvan http://arxiv.org/abs/1906.05201 Watch, Try, Learn: Meta-Learning from Demonstrations and Reward by Zhou, Allan and Jang, Eric and Kappler, Daniel and Herzog, Alex and Khansari, Mohi and Wohlhart, Paul and Bai, Yunfei and Kalakrishnan, Mrinal and Levine, Sergey and Finn, Chelsea http://arxiv.org/abs/1906.03352 Meta-Learning Representations for Continual Learning by Javed, Khurram and White, Martha http://arxiv.org/abs/1905.12588 TapNet: Neural Network Augmented with Task-Adaptive Projection for Few-Shot Learning by Yoon, Sung Whan and Seo, Jun and Moon, Jaekyun http://arxiv.org/abs/1905.06549 Meta Reinforcement Learning with Task Embedding and Shared Policy by Lan, Lin and Li, Zhenguo and Guan, Xiaohong and Wang, Pinghui http://arxiv.org/abs/1905.06527 Hierarchically Structured Meta-learning by Yao, Huaxiu and Wei, Ying and Huang, Junzhou and Li, Zhenhui http://arxiv.org/abs/1905.05301 Curious Meta-Controller: Adaptive Alternation between Model-Based and Model-Free Control in Deep Reinforcement Learning by Hafez, Muhammad Burhan and Weber, Cornelius and Kerzel, Matthias and Wermter, Stefan http://arxiv.org/abs/1905.01718 Learning to Learn in Simulation by Teng, Ervin and Iannucci, Bob http://arxiv.org/abs/1902.01569 Meta-Learning with Differentiable Convex Optimization by Lee, Kwonjoon and Maji, Subhransu and Ravichandran, Avinash and Soatto, Stefano http://arxiv.org/abs/1904.03758 Functional Regularisation for Continual Learning by Titsias, Michalis K and Schwarz, Jonathan and de G. Matthews, Alexander G and Pascanu, Razvan and Teh, Yee Whye http://arxiv.org/abs/1901.11356 Learning to Forget for Meta-Learning by Baik, Sungyong and Hong, Seokil and Lee, Kyoung Mu http://arxiv.org/abs/1906.05895 Meta-learning of Sequential Strategies by Ortega, Pedro A and Wang, Jane X and Rowland, Mark and Genewein, Tim and Kurth-Nelson, Zeb and Pascanu, Razvan and Heess, Nicolas and Veness, Joel and Pritzel, Alex and Sprechmann, Pablo and Jayakumar, Siddhant M and McGrath, Tom and Miller, Kevin and Azar, Mohammad and Osband, Ian and Rabinowitz, Neil and Gy{\\\"o}rgy, Andr{\\'a}s and Chiappa, Silvia and Osindero, Simon and Teh, Yee Whye and van Hasselt, Hado and de Freitas, Nando and Botvinick, Matthew and Legg, Shane http://arxiv.org/abs/1905.03030 This paper essentially provides a theoretical framework to ground the fact that recurrent meta-learning (RL^2, LLGD^2) performs Bayesian inference during adaptation. Auto-Meta: Automated Gradient Based Meta Learner Search by Kim, Jaehong and Lee, Sangyeul and Kim, Sungwan and Cha, Moonsu and Lee, Jung Kwon and Choi, Youngduck and Choi, Yongseok and Cho, Dong-Yeon and Kim, Jiwon http://arxiv.org/abs/1806.06927 Adaptive Gradient-Based Meta-Learning Methods by Khodak, Mikhail and Florina-Balcan, Maria and Talwalkar, Ameet http://arxiv.org/abs/1906.02717 Embedded Meta-Learning: Toward more flexible deep-learning models by Lampinen, Andrew K and McClelland, James L http://arxiv.org/abs/1905.09950 Modular meta-learning by Alet, Ferran and Lozano-P{\\'e}rez, Tom{\\'a}s and Kaelbling, Leslie P http://arxiv.org/abs/1806.10166 MetaPred: Meta-Learning for Clinical Risk Prediction with Limited Patient Electronic Health Records by Zhang, Xi Sheryl and Tang, Fengyi and Dodge, Hiroko and Zhou, Jiayu and Wang, Fei http://arxiv.org/abs/1905.03218 Prototypical Networks for Few-shot Learning by Snell, Jake and Swersky, Kevin and Zemel, Richard S http://arxiv.org/abs/1703.05175 Meta-learners' learning dynamics are unlike learners' by Rabinowitz, Neil C http://arxiv.org/abs/1905.01320 Backpropamine: training self-modifying neural networks with differentiable neuromodulated plasticity by Miconi, Thomas and Rawal, Aditya and Clune, Jeff and Stanley, Kenneth O https://openreview.net/forum?id=r1lrAiA5Ym Reinforcement Learning, Fast and Slow by Botvinick, Matthew and Ritter, Sam and Wang, Jane X and Kurth-Nelson, Zeb and Blundell, Charles and Hassabis, Demis http://dx.doi.org/10.1016/j.tics.2019.02.006 Been There, Done That: Meta-Learning with Episodic Recall by Ritter, Samuel and Wang, Jane X and Kurth-Nelson, Zeb and Jayakumar, Siddhant M and Blundell, Charles and Pascanu, Razvan and Botvinick, Matthew http://arxiv.org/abs/1805.09692 Guided Meta-Policy Search by Mendonca, Russell and Gupta, Abhishek and Kralev, Rosen and Abbeel, Pieter and Levine, Sergey and Finn, Chelsea http://arxiv.org/abs/1904.00956 Hierarchical Meta Learning by Zou, Yingtian and Feng, Jiashi http://arxiv.org/abs/1904.09081 A Meta-Transfer Objective for Learning to Disentangle Causal Mechanisms by Bengio, Yoshua and Deleu, Tristan and Rahaman, Nasim and Ke, Rosemary and Lachapelle, S{\\'e}bastien and Bilaniuk, Olexa and Goyal, Anirudh and Pal, Christopher http://arxiv.org/abs/1901.10912 Generalize Across Tasks: Efficient Algorithms for Linear Representation Learning by Bullins, Brian and Hazan, Elad and Kalai, Adam and Livni, Roi http://proceedings.mlr.press/v98/bullins19a.html Incremental Learning-to-Learn with Statistical Guarantees by Denevi, Giulia and Ciliberto, Carlo and Stamos, Dimitris and Pontil, Massimiliano http://arxiv.org/abs/1803.08089 A Model of Inductive Bias Learning by Baxter, J http://arxiv.org/abs/1106.0245 Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables by Rakelly, Kate and Zhou, Aurick and Quillen, Deirdre and Finn, Chelsea and Levine, Sergey http://arxiv.org/abs/1903.08254 Continual Learning with Tiny Episodic Memories by Chaudhry, Arslan and Rohrbach, Marcus and Elhoseiny, Mohamed and Ajanthan, Thalaiyasingam and Dokania, Puneet K and Torr, Philip H S and Ranzato, Marc'aurelio http://arxiv.org/abs/1902.10486 Online Meta-Learning by Finn, Chelsea and Rajeswaran, Aravind and Kakade, Sham and Levine, Sergey http://arxiv.org/abs/1902.08438 Modulating transfer between tasks in gradient-based meta-learning by Grant, Erin and Jerfel, Ghassen and Heller, Katherine and Griffiths, Thomas L https://openreview.net/pdf?id=HyxpNnRcFX Learning to Adapt in Dynamic, Real-World Environments Through Meta-Reinforcement Learning by Nagabandi, Anusha and Clavera, Ignasi and Liu, Simin and Fearing, Ronald S and Abbeel, Pieter and Levine, Sergey and Finn, Chelsea http://arxiv.org/abs/1803.11347 Meta-Learning with Latent Embedding Optimization by Rusu, Andrei A and Rao, Dushyant and Sygnowski, Jakub and Vinyals, Oriol and Pascanu, Razvan and Osindero, Simon and Hadsell, Raia http://arxiv.org/abs/1807.05960 Learning to Generalize: Meta-Learning for Domain Generalization by Li, Da and Yang, Yongxin and Song, Yi-Zhe and Hospedales, Timothy M http://arxiv.org/abs/1710.03463 Some Considerations on Learning to Explore via Meta-Reinforcement Learning by Stadie, Bradly C and Yang, Ge and Houthooft, Rein and Chen, Xi and Duan, Yan and Wu, Yuhuai and Abbeel, Pieter and Sutskever, Ilya http://arxiv.org/abs/1803.01118 How to train your MAML by Antoniou, Antreas and Edwards, Harrison and Storkey, Amos http://arxiv.org/abs/1810.09502 Bayesian Model-Agnostic Meta-Learning by Kim, Taesup and Yoon, Jaesik and Dia, Ousmane and Kim, Sungwoong and Bengio, Yoshua and Ahn, Sungjin http://arxiv.org/abs/1806.03836 Probabilistic Model-Agnostic Meta-Learning by Finn, Chelsea and Xu, Kelvin and Levine, Sergey http://arxiv.org/abs/1806.02817 The effects of negative adaptation in Model-Agnostic Meta-Learning by Deleu, Tristan and Bengio, Yoshua http://arxiv.org/abs/1812.02159 Memory-based Parameter Adaptation by Sprechmann, Pablo and Jayakumar, Siddhant M and Rae, Jack W and Pritzel, Alexander and Badia, Adri{`a} Puigdom{`e}nech and Uria, Benigno and Vinyals, Oriol and Hassabis, Demis and Pascanu, Razvan and Blundell, Charles http://arxiv.org/abs/1802.10542 Deep Meta-Learning: Learning to Learn in the Concept Space by Zhou, Fengwei and Wu, Bin and Li, Zhenguo http://arxiv.org/abs/1802.03596 Deep Prior by Lacoste, Alexandre and Boquet, Thomas and Rostamzadeh, Negar and Oreshkin, Boris and Chung, Wonchang and Krueger, David http://arxiv.org/abs/1712.05016 Recasting Gradient-Based Meta-Learning as Hierarchical Bayes by Grant, Erin and Finn, Chelsea and Levine, Sergey and Darrell, Trevor and Griffiths, Thomas http://arxiv.org/abs/1801.08930 WNGrad: Learn the Learning Rate in Gradient Descent by Wu, Xiaoxia and Ward, Rachel and Bottou, L{\\'e}on http://arxiv.org/abs/1803.02865 Learning to Learn by Finn, Chelsea http://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/","title":"Other &amp; Uncategorized"},{"location":"4%20Papers/2%20Books/","text":"Books Hands-On Meta Learning with Python: Meta learning using one-shot learning, MAML, Reptile, and Meta-SGD with TensorFlow , (2019), Sudharsan Ravichandiran . [pdf] [code] Meta learning is an exciting research trend in machine learning, which enables a model to understand the learning process. Unlike other ML paradigms, with meta learning you can learn from small datasets faster. Hands-On Meta Learning with Python starts by explaining the fundamentals of meta learning and helps you understand the concept of learning to learn. You will delve into various one-shot learning algorithms, like siamese, prototypical, relation and memory-augmented networks by implementing them in TensorFlow and Keras. As you make your way through the book, you will dive into state-of-the-art meta learning algorithms such as MAML, Reptile, and CAML. You will then explore how to learn quickly with Meta-SGD and discover how you can perform unsupervised learning using meta learning with CACTUs. In the concluding chapters, you will work through recent trends in meta learning such as adversarial meta learning, task agnostic meta learning, and meta imitation learning. By the end of this book, you will be familiar with state-of-the-art meta learning algorithms and able to enable human-like cognition for your machine learning models. Table of contents 1. Introduction to Meta Learning 1.1. What is Meta Learning? 1.2. Meta Learning and Few-Shot 1.3. Types of Meta Learning 1.4. Learning to Learn Gradient Descent by Gradient Descent 1.5. Optimization As a Model for Few-Shot Learning 2. Face and Audio Recognition using Siamese Network 2.1. What are Siamese Networks? 2.2. Architecture of Siamese Networks 2.3. Applications of Siamese Networks 2.4. Face Recognition Using Siamese Networks 2.5. Audio Recognition Using Siamese Networks 3. Prototypical Network and its variants 3.1. Prototypical Network 3.2. Algorithm of Prototypical Network 3.3. Omniglot character set classification using prototypical network 3.4. Gaussian Prototypical Network 3.5. Algorithm 3.6. Semi prototypical Network 4. Relation and Matching Networks Using Tensorflow 4.1. Relation Networks 4.2. Relation Networks in One-Shot Learning 4.3. Relation Networks in Few-Shot Learning 4.4. Relation Networks in Zero-Shot Learning 4.5. Building Relation Networks using Tensorflow 4.6. Matching Networks 4.7. Embedding Functions 4.8. Architecture of Matching Networks 4.9. Matching Networks in Tensorflow 5. Memory Augmented Networks 5.1. Neural Turing Machine 5.2. Reading and Writing in NTM 5.3. Addressing Mechansims 5.4. Copy Task using NTM 5.5. Memory Augmented Neural Networks 5.6. Reading and Writing in MANN 5.7. Building MANN in Tensorflow 6. MAML and its variants 6.1. Model Agnostic Meta Learning 6.2. MAML Algorithm 6.3. MAML in Supervised Learning 6.4. MAML in Reinforcement Learning 6.5. Building MAML from Scratch 6.6. Adversarial Meta Learning 6.7. Building ADML from Scratch 6.8. CAML 6.9. CAML Algorithm 7. Meta-SGD and Reptile Algorithms 7.1. Meta-SGD 7.2. Meta-SGD in Supervised Learning 7.3. Meta-SGD in Reinforcement Learning 7.4. Building Meta-SGD from Scratch 7.5. Reptile 7.6. Reptile Algorithm 7.7. Sine Wave Regression Using Reptile 8. Gradient Agreement as an Optimization Objective 8.1. Gradient Agreement 8.2. Weight Calculation 8.3. Gradient Agreement Algorithm 8.4. Building Gradient Agreement with MAML from scratch 9. Recent Advancements and Next Steps 9.1. Task Agnostic Meta Learning 9.2. TAML Algorithm 9.3. Meta Imitation Learning 9.4. MIL Algorithm 9.5. CACTUs 9.6. Task Generation using CACTUs 9.7. Learning to Learn in the Concept Space","title":"Books"},{"location":"4%20Papers/2%20Books/#books","text":"Hands-On Meta Learning with Python: Meta learning using one-shot learning, MAML, Reptile, and Meta-SGD with TensorFlow , (2019), Sudharsan Ravichandiran . [pdf] [code]","title":"Books"},{"location":"4%20Papers/2%20Books/#_1","text":"Meta learning is an exciting research trend in machine learning, which enables a model to understand the learning process. Unlike other ML paradigms, with meta learning you can learn from small datasets faster. Hands-On Meta Learning with Python starts by explaining the fundamentals of meta learning and helps you understand the concept of learning to learn. You will delve into various one-shot learning algorithms, like siamese, prototypical, relation and memory-augmented networks by implementing them in TensorFlow and Keras. As you make your way through the book, you will dive into state-of-the-art meta learning algorithms such as MAML, Reptile, and CAML. You will then explore how to learn quickly with Meta-SGD and discover how you can perform unsupervised learning using meta learning with CACTUs. In the concluding chapters, you will work through recent trends in meta learning such as adversarial meta learning, task agnostic meta learning, and meta imitation learning. By the end of this book, you will be familiar with state-of-the-art meta learning algorithms and able to enable human-like cognition for your machine learning models.","title":""},{"location":"4%20Papers/2%20Books/#table-of-contents","text":"","title":"Table of contents"},{"location":"4%20Papers/2%20Books/#1-introduction-to-meta-learning","text":"1.1. What is Meta Learning? 1.2. Meta Learning and Few-Shot 1.3. Types of Meta Learning 1.4. Learning to Learn Gradient Descent by Gradient Descent 1.5. Optimization As a Model for Few-Shot Learning","title":"1. Introduction to Meta Learning"},{"location":"4%20Papers/2%20Books/#2-face-and-audio-recognition-using-siamese-network","text":"2.1. What are Siamese Networks? 2.2. Architecture of Siamese Networks 2.3. Applications of Siamese Networks 2.4. Face Recognition Using Siamese Networks 2.5. Audio Recognition Using Siamese Networks","title":"2. Face and Audio Recognition using Siamese Network"},{"location":"4%20Papers/2%20Books/#3-prototypical-network-and-its-variants","text":"3.1. Prototypical Network 3.2. Algorithm of Prototypical Network 3.3. Omniglot character set classification using prototypical network 3.4. Gaussian Prototypical Network 3.5. Algorithm 3.6. Semi prototypical Network","title":"3. Prototypical Network and its variants"},{"location":"4%20Papers/2%20Books/#4-relation-and-matching-networks-using-tensorflow","text":"4.1. Relation Networks 4.2. Relation Networks in One-Shot Learning 4.3. Relation Networks in Few-Shot Learning 4.4. Relation Networks in Zero-Shot Learning 4.5. Building Relation Networks using Tensorflow 4.6. Matching Networks 4.7. Embedding Functions 4.8. Architecture of Matching Networks 4.9. Matching Networks in Tensorflow","title":"4. Relation and Matching Networks Using Tensorflow"},{"location":"4%20Papers/2%20Books/#5-memory-augmented-networks","text":"5.1. Neural Turing Machine 5.2. Reading and Writing in NTM 5.3. Addressing Mechansims 5.4. Copy Task using NTM 5.5. Memory Augmented Neural Networks 5.6. Reading and Writing in MANN 5.7. Building MANN in Tensorflow","title":"5. Memory Augmented Networks"},{"location":"4%20Papers/2%20Books/#6-maml-and-its-variants","text":"6.1. Model Agnostic Meta Learning 6.2. MAML Algorithm 6.3. MAML in Supervised Learning 6.4. MAML in Reinforcement Learning 6.5. Building MAML from Scratch 6.6. Adversarial Meta Learning 6.7. Building ADML from Scratch 6.8. CAML 6.9. CAML Algorithm","title":"6. MAML and its variants"},{"location":"4%20Papers/2%20Books/#7-meta-sgd-and-reptile-algorithms","text":"7.1. Meta-SGD 7.2. Meta-SGD in Supervised Learning 7.3. Meta-SGD in Reinforcement Learning 7.4. Building Meta-SGD from Scratch 7.5. Reptile 7.6. Reptile Algorithm 7.7. Sine Wave Regression Using Reptile","title":"7. Meta-SGD and Reptile Algorithms"},{"location":"4%20Papers/2%20Books/#8-gradient-agreement-as-an-optimization-objective","text":"8.1. Gradient Agreement 8.2. Weight Calculation 8.3. Gradient Agreement Algorithm 8.4. Building Gradient Agreement with MAML from scratch","title":"8. Gradient Agreement as an Optimization Objective"},{"location":"4%20Papers/2%20Books/#9-recent-advancements-and-next-steps","text":"9.1. Task Agnostic Meta Learning 9.2. TAML Algorithm 9.3. Meta Imitation Learning 9.4. MIL Algorithm 9.5. CACTUs 9.6. Task Generation using CACTUs 9.7. Learning to Learn in the Concept Space","title":"9. Recent Advancements and Next Steps"},{"location":"4%20Papers/3%20Libraries/","text":"Libraries Higher by Facebook research TorchMeta Learn2learn","title":"Libraries"},{"location":"4%20Papers/3%20Libraries/#libraries","text":"Higher by Facebook research TorchMeta Learn2learn","title":"Libraries"},{"location":"4%20Papers/4%20Blogs/","text":"Blogs EN Berkeley Artificial Intelligence Research blog Meta-Learning: Learning to Learn Fast Meta-Reinforcement Learning How to train your MAML: A step by step approach An Introduction to Meta-Learning From zero to research\u200a\u2014\u200aAn introduction to Meta-learning What\u2019s New in Deep Learning Research: Understanding Meta-Learning CN \u3010\u8bba\u6587\u7b14\u8bb0\u3011Meta-Learning in Neural Networks: A Survey - \u77e5\u4e4e (zhihu.com) \u4e00\u6587\u5165\u95e8\u5143\u5b66\u4e60\uff08Meta-Learning\uff09\uff08\u9644\u4ee3\u7801\uff09 - \u77e5\u4e4e (zhihu.com) Meta-learning\u6838\u5fc3\u601d\u60f3\u53ca\u8fd1\u5e74\u9876\u4f1a3\u4e2a\u4f18\u5316\u65b9\u5411 - \u77e5\u4e4e (zhihu.com) \u5143\u5b66\u4e60\uff08meta learning\uff09\u5728\u5de5\u4e1a\u754c\u6709\u54ea\u4e9b\u843d\u5730\u5e94\u7528\uff1f - \u77e5\u4e4e (zhihu.com) (59\u6761\u6d88\u606f) \u5143\u5b66\u4e60\u6982\u8ff0\uff08Meta-Learning\uff09_\u4e00\u53ea\u5de5\u7a0b\u72ee\u7684\u535a\u5ba2-CSDN\u535a\u5ba2_meta-learning \u5143\u5b66\u4e60\uff08Meta Learning\uff09\u4e0e\u8fc1\u79fb\u5b66\u4e60\uff08Transfer Learning\uff09\u7684\u533a\u522b\u8054\u7cfb\u662f\u4ec0\u4e48\uff1f - \u77e5\u4e4e (zhihu.com) \u6700\u524d\u6cbf\uff1a\u767e\u5bb6\u4e89\u9e23\u7684Meta Learning/Learning to learn - \u77e5\u4e4e (zhihu.com)","title":"Blogs"},{"location":"4%20Papers/4%20Blogs/#blogs","text":"","title":"Blogs"},{"location":"4%20Papers/4%20Blogs/#en","text":"Berkeley Artificial Intelligence Research blog Meta-Learning: Learning to Learn Fast Meta-Reinforcement Learning How to train your MAML: A step by step approach An Introduction to Meta-Learning From zero to research\u200a\u2014\u200aAn introduction to Meta-learning What\u2019s New in Deep Learning Research: Understanding Meta-Learning","title":"EN"},{"location":"4%20Papers/4%20Blogs/#cn","text":"\u3010\u8bba\u6587\u7b14\u8bb0\u3011Meta-Learning in Neural Networks: A Survey - \u77e5\u4e4e (zhihu.com) \u4e00\u6587\u5165\u95e8\u5143\u5b66\u4e60\uff08Meta-Learning\uff09\uff08\u9644\u4ee3\u7801\uff09 - \u77e5\u4e4e (zhihu.com) Meta-learning\u6838\u5fc3\u601d\u60f3\u53ca\u8fd1\u5e74\u9876\u4f1a3\u4e2a\u4f18\u5316\u65b9\u5411 - \u77e5\u4e4e (zhihu.com) \u5143\u5b66\u4e60\uff08meta learning\uff09\u5728\u5de5\u4e1a\u754c\u6709\u54ea\u4e9b\u843d\u5730\u5e94\u7528\uff1f - \u77e5\u4e4e (zhihu.com) (59\u6761\u6d88\u606f) \u5143\u5b66\u4e60\u6982\u8ff0\uff08Meta-Learning\uff09_\u4e00\u53ea\u5de5\u7a0b\u72ee\u7684\u535a\u5ba2-CSDN\u535a\u5ba2_meta-learning \u5143\u5b66\u4e60\uff08Meta Learning\uff09\u4e0e\u8fc1\u79fb\u5b66\u4e60\uff08Transfer Learning\uff09\u7684\u533a\u522b\u8054\u7cfb\u662f\u4ec0\u4e48\uff1f - \u77e5\u4e4e (zhihu.com) \u6700\u524d\u6cbf\uff1a\u767e\u5bb6\u4e89\u9e23\u7684Meta Learning/Learning to learn - \u77e5\u4e4e (zhihu.com)","title":"CN"},{"location":"4%20Papers/5%20Lecture%20Videos/","text":"Lecture Videos EN Stanford CS330: Multi-Task and Meta-Learning, 2019 by Chelsea Finn Meta Learning lecture by Soheil Feizi Chelsea Finn: Building Unsupervised Versatile Agents with Meta-Learning Sam Ritter: Meta-Learning to Make Smart Inferences from Small Data Model Agnostic Meta Learning by Siavash Khodadadeh Meta Learning by Siraj Raval Meta Learning by Hugo Larochelle Meta Learning and One-Shot Learning CN \u3010\u6a5f\u5668\u5b78\u7fd22021\u3011\u5143\u5b78\u7fd2 Meta Learning Meta Learning \u2013 MAML \u3010\u674e\u5b8f\u6bc5-\u5143\u5b66\u4e60\u3011\u5c11\u6837\u672c&\u5143\u5b66\u4e60Meta Learning_MAML\u6700\u65b0\u673a\u5668\u5b66\u4e60\u8bfe\u7a0b\uff01\uff01\uff01_\u54d4\u54e9\u54d4\u54e9_bilibili \u30102022\u5e74\u6700\u65b0\u3011\u65af\u5766\u798f\u6700\u65b0\u8bfe\u7a0b\uff1a\u6df1\u5ea6\u591a\u4efb\u52a1\u548c\u5143\u5b66\u4e60\uff0c\u4eba\u5de5\u667a\u80fd\u7edd\u5bf9\u4e0d\u80fd\u9519\u8fc7\u7684\u8bfe\u7a0b\u4e4b\u4e00\uff01_\u54d4\u54e9\u54d4\u54e9_bilibili \u5c0f\u6837\u672c\u5b66\u4e60\u548c\u5143\u5b66\u4e60\uff08\u4e2d\u6587\u8bfe\u7a0b\uff09 - Shusen Wang_\u54d4\u54e9\u54d4\u54e9_bilibili","title":"Lecture Videos"},{"location":"4%20Papers/5%20Lecture%20Videos/#lecture-videos","text":"","title":"Lecture Videos"},{"location":"4%20Papers/5%20Lecture%20Videos/#en","text":"Stanford CS330: Multi-Task and Meta-Learning, 2019 by Chelsea Finn Meta Learning lecture by Soheil Feizi Chelsea Finn: Building Unsupervised Versatile Agents with Meta-Learning Sam Ritter: Meta-Learning to Make Smart Inferences from Small Data Model Agnostic Meta Learning by Siavash Khodadadeh Meta Learning by Siraj Raval Meta Learning by Hugo Larochelle Meta Learning and One-Shot Learning","title":"EN"},{"location":"4%20Papers/5%20Lecture%20Videos/#cn","text":"\u3010\u6a5f\u5668\u5b78\u7fd22021\u3011\u5143\u5b78\u7fd2 Meta Learning Meta Learning \u2013 MAML \u3010\u674e\u5b8f\u6bc5-\u5143\u5b66\u4e60\u3011\u5c11\u6837\u672c&\u5143\u5b66\u4e60Meta Learning_MAML\u6700\u65b0\u673a\u5668\u5b66\u4e60\u8bfe\u7a0b\uff01\uff01\uff01_\u54d4\u54e9\u54d4\u54e9_bilibili \u30102022\u5e74\u6700\u65b0\u3011\u65af\u5766\u798f\u6700\u65b0\u8bfe\u7a0b\uff1a\u6df1\u5ea6\u591a\u4efb\u52a1\u548c\u5143\u5b66\u4e60\uff0c\u4eba\u5de5\u667a\u80fd\u7edd\u5bf9\u4e0d\u80fd\u9519\u8fc7\u7684\u8bfe\u7a0b\u4e4b\u4e00\uff01_\u54d4\u54e9\u54d4\u54e9_bilibili \u5c0f\u6837\u672c\u5b66\u4e60\u548c\u5143\u5b66\u4e60\uff08\u4e2d\u6587\u8bfe\u7a0b\uff09 - Shusen Wang_\u54d4\u54e9\u54d4\u54e9_bilibili","title":"CN"},{"location":"4%20Papers/6%20Workshops/","text":"Workshops MetaLearn 2017 MetaLearn 2018 MetaLearn 2019 MetaLearn 2020 MetaLearn 2021 MetaLearn 2022 NeurIPS 5th Workshop on Meta-Learning Youtube","title":"Workshops"},{"location":"4%20Papers/6%20Workshops/#workshops","text":"MetaLearn 2017 MetaLearn 2018 MetaLearn 2019 MetaLearn 2020 MetaLearn 2021 MetaLearn 2022 NeurIPS 5th Workshop on Meta-Learning Youtube","title":"Workshops"},{"location":"5%20Datasets/Datasets/","text":"Datasets Most popularly used datasets: Omniglot mini-ImageNet ILSVRC FGVC aircraft Caltech-UCSD Birds-200-2011 CIFAR-FS FC100 Check several other datasets by Google here. 1FAIpQLSeKPfYEttRKN3Lk317cxcNbU454yCTRktXpxMiK_O6PgFq22A/viewform?embedded=true\" width=\"640\" height=\"1200\" frameborder=\"0\" marginheight=\"0\" marginwidth=\"0\">Loading\u2026","title":"Datasets"},{"location":"5%20Datasets/Datasets/#datasets","text":"Most popularly used datasets: Omniglot mini-ImageNet ILSVRC FGVC aircraft Caltech-UCSD Birds-200-2011 CIFAR-FS FC100 Check several other datasets by Google here. 1FAIpQLSeKPfYEttRKN3Lk317cxcNbU454yCTRktXpxMiK_O6PgFq22A/viewform?embedded=true\" width=\"640\" height=\"1200\" frameborder=\"0\" marginheight=\"0\" marginwidth=\"0\">Loading\u2026","title":"Datasets"},{"location":"6%20Community/Community/","text":"Community Awesome META+ is built by myself for now , and there are many things worth adding and thinking about. For individual contributions, please refer to Changelog . Researchers Chelsea Finn , UC Berkeley Pieter Abbeel , UC Berkeley Erin Grant , UC Berkeley Raia Hadsell , DeepMind Misha Denil , DeepMind Adam Santoro , DeepMind Sachin Ravi , Princeton University David Abel , Brown University Brenden Lake , Facebook AI Research Institution Cloudera Fast Forward Zitnik Lab Meta Immersive Learning \u6f14\u7b97\u6cd5\uff1a Learning to learn Meta learning - BIIC LAB","title":"Community"},{"location":"6%20Community/Community/#community","text":"Awesome META+ is built by myself for now , and there are many things worth adding and thinking about. For individual contributions, please refer to Changelog .","title":"Community"},{"location":"6%20Community/Community/#researchers","text":"Chelsea Finn , UC Berkeley Pieter Abbeel , UC Berkeley Erin Grant , UC Berkeley Raia Hadsell , DeepMind Misha Denil , DeepMind Adam Santoro , DeepMind Sachin Ravi , Princeton University David Abel , Brown University Brenden Lake , Facebook AI Research","title":"Researchers"},{"location":"6%20Community/Community/#institution","text":"Cloudera Fast Forward Zitnik Lab Meta Immersive Learning \u6f14\u7b97\u6cd5\uff1a Learning to learn Meta learning - BIIC LAB","title":"Institution"},{"location":"7%20Changelog/Changelog/","text":"Changelog [Unreleased] @Jingyao Wang (UCAS) Added New vision example: MAML++. (@ DubiousCactus ) \"Demystifying Task Transforms\", ( Varad Pimpalkhute ) Model: Reptile, ANIL Fixed Example for detach_module . ( Nimish Sanghi ) Loading duplicate FGVC Aircraft images. v0.1.1 @Jingyao Wang (UCAS) Added Bounding box cropping for Aircraft and CUB200. Model: ES-MAML,MetaDropout Fixed Fix train_loss logging in LightningModule implementations with PyTorch-Lightning 1.5. v0.1.2 @Jingyao Wang (UCAS) Added Datasets: CIFAR-FS, FC100 Model: CNAP, SNAIL Fixed Fix the distributed computing process in MAML v0.1.6 @Jingyao Wang (UCAS) Added Multi-task migration: CV, NLP, RL Tensorflow version of the project Fixed NA","title":"Changelog"},{"location":"7%20Changelog/Changelog/#changelog","text":"","title":"Changelog"},{"location":"7%20Changelog/Changelog/#unreleased","text":"@Jingyao Wang (UCAS)","title":"[Unreleased]"},{"location":"7%20Changelog/Changelog/#added","text":"New vision example: MAML++. (@ DubiousCactus ) \"Demystifying Task Transforms\", ( Varad Pimpalkhute ) Model: Reptile, ANIL","title":"Added"},{"location":"7%20Changelog/Changelog/#fixed","text":"Example for detach_module . ( Nimish Sanghi ) Loading duplicate FGVC Aircraft images.","title":"Fixed"},{"location":"7%20Changelog/Changelog/#v011","text":"@Jingyao Wang (UCAS)","title":"v0.1.1"},{"location":"7%20Changelog/Changelog/#added_1","text":"Bounding box cropping for Aircraft and CUB200. Model: ES-MAML,MetaDropout","title":"Added"},{"location":"7%20Changelog/Changelog/#fixed_1","text":"Fix train_loss logging in LightningModule implementations with PyTorch-Lightning 1.5.","title":"Fixed"},{"location":"7%20Changelog/Changelog/#v012","text":"@Jingyao Wang (UCAS)","title":"v0.1.2"},{"location":"7%20Changelog/Changelog/#added_2","text":"Datasets: CIFAR-FS, FC100 Model: CNAP, SNAIL","title":"Added"},{"location":"7%20Changelog/Changelog/#fixed_2","text":"Fix the distributed computing process in MAML","title":"Fixed"},{"location":"7%20Changelog/Changelog/#v016","text":"@Jingyao Wang (UCAS)","title":"v0.1.6"},{"location":"7%20Changelog/Changelog/#added_3","text":"Multi-task migration: CV, NLP, RL Tensorflow version of the project","title":"Added"},{"location":"7%20Changelog/Changelog/#fixed_3","text":"NA","title":"Fixed"}]}